[{"path":"index.html","id":"antes-de-comenzar","chapter":"Antes de comenzar","heading":"Antes de comenzar","text":"La simulación es una de las herramientas de modelización probabilística más utilizadas en la industria. Se utiliza para el análisis de sistemas existentes y para la selección de sistemas óptimos partir del planteamiento y comparación de diversos escenarios plausibles.Ejemplo 0.1  Por ejemplo, supongamos que un gran supermercado ha estado recibiendo quejas de los clientes sobre el tiempo que pasan en la cola esperando una caja disponible para pagar. La dirección ha decidido añadir algunas cajas más, pero ha de decidir cuántas añadir. Los modelos de simulación pueden ayudar la dirección determinar el número de cajas necesarias para dar un servicio adecuado sus clientes.Aunque el enfoque principal de la Estadística es la construcción de modelos analíticos que describan el funcionamiento de los procesos en función de variables que les afecten, en ocasiones nos puede resultar menos costoso proceder mediante simulación para obtener una predicción razonable de cómo se va comportar el sistema o proceso ante distintas configuraciones de esas variables condicionantes. La simulación permitirá obtener una aproximación del comportamiento del sistema ante distintos escenarios.Ejemplo 0.2  La forma de dar una solución al problema del supermercado mediante simulación podría consistir en escribir un programa informático que genere clientes que lleguen aleatoriamente (con la frecuencia habitual con que lo hacen, o con otras), simular también unos tiempos de permanencia en caja (para realizar los pagos) y evaluar los tiempos de espera para distintas configuraciones del número de cajas abiertas. Se podría así determinar el efecto de tener varias cajas abiertas en función del tráfico de clientes, y así mismo dimensionar con antelación su plantilla, quizás incluso adaptándola diferentes épocas o días, para tener suficientes cajeros ubicados en las cajas.Una razón importante para justificar el uso de la simulación es que puede utilizarse para aumentar la comprensión de un proceso. Es imposible construir un modelo de simulación de un proceso que se entiende cómo funciona, con lo que el mero hecho de desarrollar un modelo de simulación de un proceso especíﬁco forzará comprenderlo.Sin embargo, el aspecto más relevante tener en cuenta al construir un modelo de simulación es que este reproduzca la realidad fielmente, o al menos de la forma más precisa posible. En problemas sencillos, como los que veremos al inicio de este manual, resulta fácil comprobar si los algoritmos de simulación dan buenas soluciones; sin embargo, en sistemas más complejos es trivial asegurar la calidad de las simulaciones obtenidas al reproducir el funcionamiento del sistema que simulan, por lo que será necesario establecer medidas de validación.Para poder abordar sistemas de simulación es necesario tener previamente unos conocimientos básicos de probabilidad, que desarrollamos en la Unidad 1 Conceptos básicos, y partir de los que damos la definición de ‘proceso estocástico.’ Seguimos el camino en la Unidad 2 Cadenas de Markov de Tiempo Discreto con el estudio de las cadenas de Markov de tiempo discreto, los procesos de Poisson en la Unidad 3 Proceso de Poisson, las cadenas de Markov de tiempo continuo en la Unidad 4 Cadenas de Markov de Tiempo Contínuo, y finalizamos con las colas de espera en la Unidad 5 Sistemas de colas.Al final de todas las unidades se proporciona una colección de ejercicios relacionados con los procedimientos estudiados en dicha unidad, para practicar los conceptos estudiados resolviendo problemas generalmente relacionados la realidad. Los ejercicios aparecen etiquetados como B (Básicos), de aplicación directa de conceptos o técnicas, o como (Avanzados), si requieren de una modelización concreta y más tiempo para resolverlos.Todos los ejercicios deben resolverse mediante simulación. Se recomienda identificar las variables involucradas y sus distribuciones, así como construir el algoritmo de simulación (5000 simulaciones y semilla=12), con suficiente detalle y comentarios. El algoritmo de simulación es conveniente que venga desarrollado en función de los parámetros de entrada del problema, de forma que resulte útil para responder las preguntas formuladas y otras que se puedan plantear ante variaciones de las condiciones iniciales.Parte de los contenidos de este curso se han obtenido de la documentación de las diferentes librerías de R utilizadas, y de los libros Mayoral et al.1 Richard M. Feldman Ciriaco Valdez-Flores,2 V. G. Kulkarni3 y Christian P.Robert George Casella.4 Buena parte de los ejercicios y ejemplos propuestos se han obtenido también de los manuales de JosÃ© Pedro GarcÃ­Sabater5 y Ricardo Cao Abad.6","code":""},{"path":"software.html","id":"software","chapter":"Software","heading":"Software","text":"Para poder utilizar el código expuesto en estos materiales es necesario la instalación de los programas R,7 que actúa como lenguaje de programación, y RStudio.8 que actúa como interfaz, y que se pueden descargar desde:R: https://cran.r-project.org/RStudio: https://rstudio.com/Para crear informes directos partir del código utilizado al programar en R con RStudio se recomienda RMarkdown.9A continuación se detallan brevemente las librerías especifícas de R utilizadas en este manual. Conviene tenerlas instaladas y actualizadas todas ellas. El conjunto de librerías útiles en Simulación de Procesos y Sistemas son:tidyverse, en Hadley Wickham et al.10 y Hadley Wickham:11 Es una colección de librerías en R para la ciencia de datos, que comparten una misma filosofía, gramática y estructuras de datos y facilita el tratamiento de datos. Para aprender utilizar estas librerías es recomendable el libro R Data Science de Hadley Wickham Garret Grolemund,12 así como el manual de Malte Grosser.13tidyverse, en Hadley Wickham et al.10 y Hadley Wickham:11 Es una colección de librerías en R para la ciencia de datos, que comparten una misma filosofía, gramática y estructuras de datos y facilita el tratamiento de datos. Para aprender utilizar estas librerías es recomendable el libro R Data Science de Hadley Wickham Garret Grolemund,12 así como el manual de Malte Grosser.13simmer, en Iñaki Ucar, Bart Smeets, Arturo Azcorra,14 IÃ±aki Ucar Bart Smeets,15 Iñaki Ucar Bart Smeets:16 Es una librería R para la simulación de eventos discretos (DES) orientada procesos. Diseñado para ser un marco genérico como SimPy o SimJulia, aprovecha la potencia de Rcpp para aumentar el rendimiento y hacer factible el DES en R. Como característica destacable, simmer explota el concepto de trayectoria: un camino común en el modelo de simulación para entidades del mismo tipo. Es bastante flexible y sencillo de utilizar, y aprovecha el flujo de trabajo de encadenamiento/conducción introducido por el paquete magrittr (Stefan Milton Bache Hadley Wickham17). También utilizaremos las librerías vinculadas simmer.plot, simmer.optim, simmer.json, y simmer.mom.simmer, en Iñaki Ucar, Bart Smeets, Arturo Azcorra,14 IÃ±aki Ucar Bart Smeets,15 Iñaki Ucar Bart Smeets:16 Es una librería R para la simulación de eventos discretos (DES) orientada procesos. Diseñado para ser un marco genérico como SimPy o SimJulia, aprovecha la potencia de Rcpp para aumentar el rendimiento y hacer factible el DES en R. Como característica destacable, simmer explota el concepto de trayectoria: un camino común en el modelo de simulación para entidades del mismo tipo. Es bastante flexible y sencillo de utilizar, y aprovecha el flujo de trabajo de encadenamiento/conducción introducido por el paquete magrittr (Stefan Milton Bache Hadley Wickham17). También utilizaremos las librerías vinculadas simmer.plot, simmer.optim, simmer.json, y simmer.mom.markovchain:18 Librería de R que proporciona clases, métodos y funciones para manejar fácilmente las Cadenas de Markov de Tiempo Discreto (DTMC), realizando análisis probabilísticos y ajustes.markovchain:18 Librería de R que proporciona clases, métodos y funciones para manejar fácilmente las Cadenas de Markov de Tiempo Discreto (DTMC), realizando análisis probabilísticos y ajustes.queueing:19 Proporciona una herramienta versátil para el análisis de los modelos de colas markovianos basados en el nacimiento y la muerte y de las redes de colas monoclase y multiclase.queueing:19 Proporciona una herramienta versátil para el análisis de los modelos de colas markovianos basados en el nacimiento y la muerte y de las redes de colas monoclase y multiclase.queuecomputer, en Anthony Ebert et al.20 y Anthony Ebert:21 Implementación de un método computacionalmente eficiente para simular colas con tiempos de llegada y servicio arbitrarios.queuecomputer, en Anthony Ebert et al.20 y Anthony Ebert:21 Implementación de un método computacionalmente eficiente para simular colas con tiempos de llegada y servicio arbitrarios.Las versiones de las librerías de R utilizadas son las siguientes:Cargamos las librerías de interés que utilizaremos en este manual.Configuramos además el tema de los gráficos para que tengan un aspecto más limpio y más fácil de exportar en formato pdf o word. Para ellos utilizamos la función theme_set().Manuales de referenciaSe recomiendan los siguientes manuales para trabajar con R, RStudio y las librerías proporcionadas:APS 135: Introduction Exploratory Data Analysis R.22 Versión electrónica.APS 135: Introduction Exploratory Data Analysis R.22 Versión electrónica.R Data Science.23 Acceso web.R Data Science.23 Acceso web.Advanced R.24 Versión online y Versión en español.Advanced R.24 Versión online y Versión en español.Tidyverse Cookbook.25 Versión online incompleta.Tidyverse Cookbook.25 Versión online incompleta.ggplot2, part tidyverse26 Acceso web.ggplot2, part tidyverse26 Acceso web.RMarkdown básico.27 Acceso web.RMarkdown básico.27 Acceso web.RMarkdown Cookbook28 Versión online.RMarkdown Cookbook28 Versión online.","code":"\nsessionInfo()## R version 4.1.2 (2021-11-01)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Big Sur 10.16\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] es_ES.UTF-8/es_ES.UTF-8/es_ES.UTF-8/C/es_ES.UTF-8/es_ES.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] kableExtra_1.3.4    gridExtra_2.3       sjPlot_2.8.10       rootSolve_1.8.2.3  \n##  [5] queuecomputer_1.1.0 queueing_0.2.12     markovchain_0.8.6   diagram_1.6.5      \n##  [9] shape_1.4.6         simmer.plot_0.1.17  simmer.bricks_0.2.1 simmer_4.4.3       \n## [13] forcats_0.5.1       stringr_1.4.0       dplyr_1.0.7         purrr_0.3.4        \n## [17] readr_2.1.2         tidyr_1.2.0         tibble_3.1.6        ggplot2_3.3.5      \n## [21] tidyverse_1.3.1    \n## \n## loaded via a namespace (and not attached):\n##  [1] minqa_1.2.4          colorspace_2.0-2     ellipsis_0.3.2       sjlabelled_1.1.8    \n##  [5] estimability_1.3     parameters_0.16.0    fs_1.5.2             rstudioapi_0.13     \n##  [9] matlab_1.0.2         fansi_1.0.2          mvtnorm_1.1-3        lubridate_1.8.0     \n## [13] xml2_1.3.3           codetools_0.2-18     splines_4.1.2        downlit_0.4.0       \n## [17] cachem_1.0.6         knitr_1.37           sjmisc_2.8.9         jsonlite_1.7.3      \n## [21] nloptr_2.0.0         ggeffects_1.1.1      broom_0.7.12         dbplyr_2.1.1        \n## [25] effectsize_0.6.0.1   compiler_4.1.2       httr_1.4.2           sjstats_0.18.1      \n## [29] emmeans_1.7.2        backports_1.4.1      assertthat_0.2.1     Matrix_1.3-4        \n## [33] fastmap_1.1.0        cli_3.1.1            htmltools_0.5.2.9000 tools_4.1.2         \n## [37] igraph_1.2.11        coda_0.19-4          gtable_0.3.0         glue_1.6.1          \n## [41] Rcpp_1.0.8           jquerylib_0.1.4      cellranger_1.1.0     vctrs_0.3.8         \n## [45] svglite_2.1.0        nlme_3.1-153         insight_0.15.0       xfun_0.29           \n## [49] lme4_1.1-28          rvest_1.0.2          lifecycle_1.0.1      MASS_7.3-54         \n## [53] scales_1.1.1         hms_1.1.1            parallel_4.1.2       expm_0.999-6        \n## [57] yaml_2.2.2           memoise_2.0.1        sass_0.4.0           stringi_1.7.6       \n## [61] bayestestR_0.11.5    boot_1.3-28          rlang_1.0.1          pkgconfig_2.0.3     \n## [65] systemfonts_1.0.2    evaluate_0.14        lattice_0.20-45      tidyselect_1.1.1    \n## [69] magrittr_2.0.2       bookdown_0.24        R6_2.5.1             generics_0.1.2      \n## [73] DBI_1.1.2            pillar_1.7.0         haven_2.4.3          withr_2.4.3         \n## [77] datawizard_0.2.3     performance_0.8.0    modelr_0.1.8         crayon_1.4.2        \n## [81] utf8_1.2.2           tzdb_0.2.0           rmarkdown_2.11       grid_4.1.2          \n## [85] readxl_1.3.1         reprex_2.0.1         digest_0.6.29        webshot_0.5.2       \n## [89] xtable_1.8-4         RcppParallel_5.1.5   stats4_4.1.2         munsell_0.5.0       \n## [93] viridisLite_0.4.0    bslib_0.3.1\n# librerías\nlibrary(tidyverse)\nlibrary(simmer)\nlibrary(simmer.bricks)\nlibrary(simmer.plot)\nlibrary(diagram)\nlibrary(markovchain)\nlibrary(queueing)\nlibrary(queuecomputer)\nlibrary(rootSolve)\n# Librerías de entorno gráfico\nlibrary(sjPlot)\nlibrary(gridExtra)\nlibrary(kableExtra) # y tablas\ntheme_set(theme_sjplot2())"},{"path":"intro.html","id":"intro","chapter":"Unidad 1 Conceptos básicos","heading":"Unidad 1 Conceptos básicos","text":"En esta unidad repasamos los conceptos básicos de probabilidad relacionados con las variables aleatorias y las distribuciones de probabilidad. Presentamos las distribuciones de probabilidad más relevantes, discretas y continuas, y otras estandarizadas, junto con varios algoritmos y funciones de R útiles para simularlas y realizar cálculos de probabilidad. Resolvemos por simulación múltiples problemas basados en los diferentes tipos de variables presentadas. Por último, introducimos la definición de proceso estocástico, con diversos ejemplos, con el fin de preparar el camino para las unidades siguientes, que ya estarán enfocadas en estudiar en profundidad diferentes tipos de procesos estocásticos. Proponemos al final de la unidad más ejercicios y estudios de caso, para que el alumnado practique los conceptos y algoritmos estudiados.","code":""},{"path":"intro.html","id":"variables-aleatorias","chapter":"Unidad 1 Conceptos básicos","heading":"1.1 Variables aleatorias","text":"Introducimos una serie de conceptos básicos.Definición 1.1  Una variable aleatoria es una función que asigna un número real cada uno de los posibles resultados de un experimento o característica de interés susceptibles de ser observados o medidos en una población objetivo.Las variables aleatorias pueden ser discretas o continuas en función de sus posibles valores. Si los valores o resultados posibles se pueden contar (sin ser infinitos), se dice que la variable aleatoria es ‘discreta’; en caso contrario, se dice que es ‘continua.’ Veamos varios ejemplos.Ejemplo 1.1  Un proveedor vende huevos por cajas que contienen 144 huevos. El proveedor desea estudiar el número de huevos que se suelen romper en cada una de las cajas durante el proceso de distribución. Es de interés pues, la variable aleatoria \\(N\\) que contabiliza el número de huevos rotos en una caja, y cuyos valores posibles son \\(0, 1, 2,..., 144\\). Se trata por tanto de una variable de tipo discreto.Ejemplo 1.2  Se desea realizar un estudio para estimar la estatura de los habitantes de una ciudad. Se define la variable aleatoria \\(X\\) como la altura en cm de cada uno de los habitantes de la ciudad. Dado que los posibles resultados son infinitos, diremos que dicha variable es de tipo continuo.Definición 1.2  Se define el espacio probabilístico \\(S\\) asociado una variable aleatoria como el conjunto de todos los valores posibles o con probabilidad que puede tomar dicha variable.","code":""},{"path":"intro.html","id":"función-de-probabilidad","chapter":"Unidad 1 Conceptos básicos","heading":"1.1.1 Función de probabilidad","text":"Para caracterizar completamente cualquier variable aleatoria es necesario definir la función de distribución, que nos da la probabilidad acumulada por debajo de un valor plausible en el espacio probabilístico \\(S\\) en el que está definida dicha variable.Definición 1.3  La función de distribución para una variable \\(X\\) en un punto \\(\\) del espacio probabilístico \\(S\\) se define como la probabilidad acumulada por debajo de dicho valor:En el caso de variables aleatorias de tipo discreto podemos caracterizar su comportamiento mediante las probabilidades asociadas cada uno de los elementos del espacio probabilístico Esto se hace través de la ‘función puntual de probabilidad’ o ‘función de masa de probabilidad.’Definición 1.4  La función de masa de probabilidad (fmp) para una variable discreta \\(X\\) en un punto \\(\\) del espacio probabilístico \\(S\\) se define como la probabilidad de que la variable \\(X\\) tome dicho valor:En el caso de variables aleatorias de tipo discreto, la función de distribución de probabilidad se puede obtener partir de la función de masa de probabilidad como:\\[\\begin{equation*}\n  F() = \\sum_{k \\leq } f(k) = 1 - \\sum_{k > } f(k).\n\\end{equation*}\\] para cualquier valor de \\(\\) en \\(S\\).Sim embargo, en las variables aleatorias de tipo continuo es posible asignar una probabilidad cada uno de los infinitos valores de la variable, dado que en ese caso la probabilidad del espacio probabilístico íntegro excedería el valor 1 y por lo tanto sería una probabilidad. En estas variables es preciso definir otra función que permita cuantificar cualquier situación que involucre los resultados del espacio probabilístico \\(S\\) asociado la variable aleatoria. Surge la ‘función de densidad de probabilidad.’Definición 1.5  La función de densidad de probabilidad (fdp), \\(f\\), asociada una variable \\(X\\) de tipo continuo permite calcular la probabilidad acumulada en un intervalo cualesquiera \\((,b]\\) del espacio probabilístico \\(S\\) través de la integral en dicho intervalo:De esta forma la ‘función de distribución’ de una variable continua se puede obtener como:donde \\(r_{min}\\) es el valor mínimo de \\(X\\) en el espacio probabilístico \\(S\\).","code":""},{"path":"intro.html","id":"variables-relevantes","chapter":"Unidad 1 Conceptos básicos","heading":"1.1.2 Variables relevantes","text":"Hay muchas funciones de distribución que se utilizan con tanta frecuencia que se conocen con nombres especiales, y que presentamos en las Secciones Distribuciones Discretas y Distribuciones continuas. Para estas variables resulta bastante sencillo realizar cualquier calculo de probabilidad, ya que la mayoría de programas informáticos tienen implementadas sus funciones de distribución. Utilizaremos obstante la simulación para realizar cálculos probabilísticos.En \\(R\\) se puede acceder directamente la función de densidad, función de distribución, quantiles y simulación de valores de cualquiera de las distribuciones que presentamos continuación mediante las funciones:\\(dXXXX(par)\\): función de densidad,\\(pXXXX(par)\\): función de distribución,\\(qXXXX(par)\\): quantiles,\\(rXXXX(par)\\): generación de valores de la variable,donde \\(XXXX\\) identifica la distribución/variable de interés y \\(par\\) son los parámetros que la caracterizan.","code":""},{"path":"intro.html","id":"media-y-varianza","chapter":"Unidad 1 Conceptos básicos","heading":"1.1.3 Media y varianza","text":"Muchas variables aleatorias tienen funciones de distribución complicadas y, por tanto, es difícil obtener una comprensión intuitiva del comportamiento de la variable conociendo simplemente la función de distribución. Dos medidas, la media o valor esperado y la varianza se definen para ayudar describir el comportamiento de una variable aleatoria. El valor esperado equivale la media aritmética de infinitas observaciones de la variable aleatoria y la varianza es una indicación de la variabilidad o dispersión de los valores de dicha variable.Definición 1.6  Dada una variable aleatoria \\(X\\) discreta sobre un espacio probabilístico \\(S\\), se define el valor esperado o esperanza de \\(X\\), \\(E(X)\\), como \\[E(X) = \\sum_{k \\ S} kf(k)\\] donde \\(f\\) es la fmp de \\(X\\).Cuando \\(X\\) es una variable aleatoria continua, su valor esperado se define partir de la fdp de \\(X\\): \\[E(X) = \\int_S xf(x)dx.\\]Esta definición se puede aplicar cualquier función o transformación de una variable aleatoria, \\(h(X)\\), para obtener su valor esperado \\(E[h(X)]\\), y así por ejemplo en el caso continuo tendríamos: \\[E[h(X)]=\\int_S h(x)f(x)dx.\\]El valor esperado nos da una medida de localización para la variable aleatoria \\(X\\), pero es bien sabido que dichas medidas de localización se deben acompañar siempre de una medida de dispersión, como la varianza o desviación típica.Definición 1.7  Dada una variable aleatoria \\(X\\) con valor esperado \\(E(X)\\) se define la varianza de \\(X\\), \\(V(X)\\) como:partir de la varianza se define la desviación típica de la variable \\(X\\) como la raíz cuadrada de su varianza. Las propiedades siguientes se derivan directamente partir de la definición de esperanza y varianza:Si \\(X\\) e \\(Y\\) son dos variables aleatorias y \\(c\\) una constante, entonces:\\(E(c) = c\\)\\(E(cX) = cE(X)\\)\\(E(X+Y) = E(X) + E(Y)\\)\\(V(cX) = c^2 V(X)\\)","code":""},{"path":"intro.html","id":"APMC","chapter":"Unidad 1 Conceptos básicos","heading":"1.2 Aproximación Monte Carlo","text":"Cuando trabajamos con variables aleatorias, es común el problema de querer estimar el valor esperado de cualquier cantidad \\(h(X)\\), siendo \\(X\\) una variable aleatoria. Utilizando la simulación es posible obtener estimaciones de dichos valores de un modo relativamente sencillo: través de la integración Monte Carlo.Ante un problema genérico relativo calcular el valor esperado de cierta función \\(h(X)\\) para una variable aleatoria con fdp \\(X \\sim f(x)\\), \\[\\begin{equation}\nE[h(X)]=\\int_S h(x) f(x) dx\n(\\#eq:problemaestimacionMC)\n\\end{equation}\\] donde \\(S\\) denota el conjunto en el que la variable \\(X\\) toma valores,Definición 1.8  Ante el problema de estimar (??), el procedimiento de estimación Monte Carlo propone simular una muestra aleatoria de la distribución de \\(X\\), \\(x_1,\\ldots,x_n\\) y con ella obtener una aproximación empírica través del promedio de las cantidades \\(h(x_1),\\ldots,h(x_n)\\), \\[\\begin{equation}\n\\bar{h_n}=\\frac{\\sum_{=1}^n h(x_i)}{n}.\n(\\#eq:estimacionMC)\n\\end{equation}\\]Por la Ley de los Grandes Números, \\(\\bar{h_n}\\) converge casi seguro la cantidad de interés \\(E[h(X)]\\). Además, cuando \\(h^2(X)\\) tiene un valor esperado finito, la velocidad de convergencia de \\(\\bar{h_n}\\) se puede calcular y la varianza asintótica de la aproximación es \\[Var(\\bar{h_n})=\\frac{1}{n} \\int_S (h(x)-E[h(X)])^2 f(x) dx,\\] que se puede estimar con la muestra \\(x_1,\\ldots,x_n\\) través de \\[\\begin{equation}\nv_n=\\frac{1}{n^2} \\sum_{=1}^n [h(x_i)-\\bar{h_n}]^2.\n(\\#eq:varianzaMC)\n\\end{equation}\\]Más específicamente, por el Teorema Central del Límite, para \\(n\\) grande tendremos que \\[\\begin{equation}\n\\frac{\\bar{h_n}-E[h(X)]}{\\sqrt{v_n}} \\sim N(0,1),\n(\\#eq:distMC)\n\\end{equation}\\]lo que permitirá además, construir bandas de confianza para la aproximación Monte Carlo, la que en adelante nos referiremos por “aproximación MC.”\\[\\begin{equation}\nIC_{1-\\alpha}[\\bar{h_n}]=[\\bar{h_n}-z_{1-\\alpha/2} \\sqrt{v_n}, \\bar{h_n}+z_{1-\\alpha/2} \\sqrt{v_n}]\n\\tag{1.1}\n\\end{equation}\\] donde \\(z_{1-\\alpha/2}\\) es el cuantil \\(1-\\alpha/2\\) de una normal estándar, asociado al nivel de confianza \\(1-\\alpha\\).","code":""},{"path":"intro.html","id":"mc-y-probabilidad","chapter":"Unidad 1 Conceptos básicos","heading":"1.2.1 MC y probabilidad","text":"Aunque en las situaciones más sencillas se puede evaluar cualquier probabilidad mediante la correspondiente función de distribución, en muchas ocasiones resulta sencillo obtener una muestra simulada de la variable aleatoria y aproximar dicha probabilidad de interés mediante el denominado estimador Monte-Carlo.Se obtiene la estimación Monte-Carlo (MC) de la probabilidad de que una variable aleatoria \\(X\\) tome algún valor en un conjunto \\(\\) de valores dentro de su espacio probabilístico, \\(Pr(X \\)\\), partir de un conjunto de observaciones o simulaciones \\(x_1, x_2,...,x_N\\) de la variable \\(X\\), mediante el cociente entre el número de simulaciones que están en dicha región \\(\\), y el número de datos disponibles,Básicamente esta definición se fundamenta en la interpretación empírica de la probabilidad, través del ratio de casos favorables por casos posibles: \\[probabilidad=\\frac{\\mbox{casos favorables}}{\\mbox{casos posibles}}.\\]La fórmula anterior la podemos expresar en notación similar la utilizada en (??) definiendo una variable dicotómica \\[I_A(X)=1 \\text{,  si } X \\\\] y 0 en otro caso, de manera que el problema de calcular una probabilidad según una distribución de probabilidad para \\(X\\) se convierte en el valor esperado de una distribución Bernouilli para una distribución de \\[Pr(X \\)=\\int_A f(x)dx=\\int_S I_A(X)f(x)dx=E[I_A(X)]\\] y la estimación MC (??) se puede expresar, para un conjunto de \\(n\\) simulaciones \\(x_1,\\ldots,x_n\\), como \\[\\begin{equation}\nPr(X \\)\\approx \\hat{h_n}= \\frac{\\sum_{=1}^n I_A(x_i)}{n},\n(\\#eq:estimacionMCprob)\n\\end{equation}\\] y su varianza con \\[\\begin{equation}\nv_n=\\frac{1}{n^2} \\sum_{=1}^n [I_A(x_i)-\\bar{h_n}]^2.\n(\\#eq:varMCprob)\n\\end{equation}\\]Ejemplo 1.3  En la situación del ejemplo 1.1, supongamos que disponemos de un conjunto de 200 simulaciones del número de huevos defectuosos en 200 cajas distribuídas. Queremos descubrir, utilizando exclusivamente esas simulaciones:La probabilidad de que una caja tenga más de 3 huevos defectuosos, \\(Pr(X>3)\\).La probabilidad de que una caja tenga lo sumo 3 huevos defectuosos, \\(Pr(X\\leq 3)\\).La probabilidad de que una caja tenga ningún huevo defectuoso, \\(Pr(X=0)\\).La probabilidad de que la proporción de huevos defectuosos en una caja sea inferior al 1%, \\(Pr(X/144 < 0.01)=Pr(X<1.44)\\).Y vamos aproximando por Monte-Carlo las probabilidades de interés, estableciendo las condiciones lógicas en cada situación.El error asociado la estimación de la probabilidad anterior, lo calculamos aplicando (??), y también el intervalo de confianza al 95% con (1.1).De esta forma resultará posible estimar cualquier probabilidad asociada una variable aleatoria, aun desconociendo su función de distribución o de probabilidad, siempre que dispongamos de una muestra simulada, y esta estimación será más precisa cuanto mayor sea el tamaño de dicha muestra.","code":"\n# Simulaciones disponibles\ndefectos <- c(2, 2, 0, 0, 0, 2, 1, 2, 1, 4, 1, 0, 0, 2, 4, \n0, 0, 0, 0, 1, 1, 1, 2, 2, 3, 1, 0, 4, 3, 1, 0, \n2, 2, 2, 3, 1, 0, 2, 2, 2, 3, 1, 0, 1, 0, 1, 2, \n0, 0, 2, 3, 2, 3, 2, 4, 4, 0, 1, 1, 3, 0, 0, 3, \n2, 0, 0, 0, 3, 0, 1, 4, 1, 1, 2, 1, 1, 4, 1, 1, \n1, 0, 1, 0, 1, 2, 2, 1, 3, 1, 2, 1, 2, 3, 1, 2, \n5, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 0, 1, 2, 2, \n1, 1, 1, 1, 0, 3, 1, 1, 1, 1, 4, 4, 0, 6, 6, 1, \n1, 1, 0, 2, 3, 1, 0, 0, 2, 0, 2, 1, 1, 1, 2, 1, \n1, 1, 1, 2, 5, 0, 1, 3, 1, 1, 4, 1, 2, 1, 1, 0, \n2, 1, 2, 1, 3, 3, 2, 0, 3, 0, 1, 3, 0, 1, 2, 0, \n1, 0, 0, 2, 2, 1, 2, 0, 0, 0, 1, 1, 2, 3, 1, 0, \n1, 0, 1, 1, 1, 1, 1, 5, 3)\n# Número de simulaciones/observaciones\nnsim=length(defectos)\n# Tamaño de la caja\ntamaño <- rep(144,200)\n# Conjunto de datos\nhuevos <- data.frame(tamaño, defectos)\n# Pr(X > 3)\nsel <- dplyr::filter(huevos, defectos >3)\nprob <- nrow(sel)/nsim\ncat(\"Probabilidad estimada [Pr(X > 3)]: \", prob)## Probabilidad estimada [Pr(X > 3)]:  0.075\n# Pr(X <= 3)\nsel <- dplyr::filter(huevos, defectos <= 3)\nprob <- nrow(sel)/nsim\ncat(\"Probabilidad estimada [Pr(X <= 3)]: \", prob)## Probabilidad estimada [Pr(X <= 3)]:  0.925\n# Pr(X = 0)\nsel <- dplyr::filter(huevos, defectos == 0)\nprob <- nrow(sel)/nsim\ncat(\"Probabilidad estimada [Pr(X = 0): \", prob)## Probabilidad estimada [Pr(X = 0):  0.235\n# Pr(X/144 <=0.01)\nsel <- dplyr::filter(huevos, defectos <= (0.01*144))\nprob <- nrow(sel)/nsim\ncat(\"Probabilidad estimada [Pr(X/144 <=0.01): \", prob)## Probabilidad estimada [Pr(X/144 <=0.01):  0.62\nI.a=(huevos$defectos <= 1.44)*1\nprob=mean(I.a)\ncat(\"prob.estim=\",prob)## prob.estim= 0.62\nvn=sum((I.a-prob)^2)/(nsim^2)\nerror=sqrt(vn)\ncat(\"Error Estimado=\",round(error,3))## Error Estimado= 0.034\n# límites del IC redondeados a 3 cifras decimales\nic.low=round(prob-qnorm(0.975)*error,3)\nic.up=round(prob+qnorm(0.975)*error,3)\ncat(\"IC(95%)[AproxMC(prob.estim)]=[\",ic.low,\",\",ic.up,\"]\")## IC(95%)[AproxMC(prob.estim)]=[ 0.553 , 0.687 ]"},{"path":"intro.html","id":"mc-y-momentos","chapter":"Unidad 1 Conceptos básicos","heading":"1.2.2 MC y momentos","text":"Si disponemos de una muestra (de observaciones o simulaciones) lo suficientemente grande de la variable aleatoria \\(X\\) podemos aproximar -de modo razonablemente preciso- el valor esperado y la varianza (o desviación típica) sin más que calcular la media y varianza de los datos que componen la muestra.La precisión de estas estimaciones estará directamente relacionada con el tamaño de la muestra utilizada.Sean \\(x_1, x_2,...,x_N\\) simulaciones disponibles para \\(X\\). Entonces \\[\\begin{eqnarray*}\nE(X) &\\approx& \\bar{x}_N=\\sum_{=1}^N x_i /N \\\\\nVar(X) &\\approx& \\sum_{=1}^N (x_i-\\bar{x}_N)^2/n = \\bar{x}_N^2-\\sum_{=1}^N x_i^2 /N.\n\\end{eqnarray*}\\]Ejemplo 1.4  Con los datos del ejemplo anterior, queremos saber cuál es el número aproximado de huevos que se rompen en cada caja, conocer su dispersión y tener así mismo un intervalo de confianza para la media.","code":"\n# media\nmedia=mean(huevos$defectos)\n# dispersión\nvarianza=var(huevos$defectos)\ndesvtip=sd(huevos$defectos)\n\n# ic para la media\nerror=sqrt(sum((huevos$defectos-media)^2)/(nsim^2))\ncat(\"\\n Error Estimado (media)=\",round(error,3))## \n##  Error Estimado (media)= 0.089\n# límites del IC redondeados a 3 cifras decimales\nic.low=round(media-qnorm(0.975)*error,3)\nic.up=round(media+qnorm(0.975)*error,3)\ncat(\"IC(95%)[AproxMC(media)]=[\",ic.low,\",\",ic.up,\"]\")## IC(95%)[AproxMC(media)]=[ 1.255 , 1.605 ]"},{"path":"intro.html","id":"distribuciones-discretas","chapter":"Unidad 1 Conceptos básicos","heading":"1.3 Distribuciones discretas","text":"Destacamos como principales variables de tipo discreto las siguientes: Bernouilli, Binomial, Geométrica y Poisson.","code":""},{"path":"intro.html","id":"bernouilli","chapter":"Unidad 1 Conceptos básicos","heading":"1.3.1 Bernouilli","text":"Imaginemos una situación experimental donde el resultado de cierta variable que observamos únicamente puede tomar dos valores posibles, denominados “éxito” (codificado con el valor 1) y “fracaso” (codificado con el valor 0). Así pues, la variable aleatoria asociada \\(X\\) verifica que:Definición 1.9  Una variable aleatoria \\(X\\) cuya fmp viene dada por (1.2) se denomina variable Bernouilli, con probabilidad de éxito \\(\\theta\\), y se denota por:\\[X \\sim Ber(\\theta)\\]de forma que \\(E(X) = \\theta\\) y \\(V(X) = \\theta(1-\\theta).\\)Un ejemplo típico de una variable Bernouilli es el lanzamiento de una moneda que sólo tiene dos posibles resultados: cara o cruz. Si la moneda esta equilibrada tenemos que \\(\\theta = 0.5\\) (idéntica probabilidad para cualquiera de los dos resultados), de forma que si definimos por ejemplo el éxito por conseguir cara, tendremos:\\[X = \\text{ Obtener cara } \\sim Ber(0.5)\\]Una distribución \\(Ber(p)\\) es equivalente una distribución binomial con parámetros 1 y p, \\(Bin(1,p)\\), de modo que para simular y realizar cálculos de probabilidad con ella utilizaremos las funciones correspondientes la distribución binomial que vemos continuación.La función dbinom(x,1,prob) nos permite evaluar la \\(Pr(X=x)\\) para una variable Bernoilli con probabilidad de éxito prob.La función pbinom(x,1,prob) nos permite evaluar la \\(Pr(X \\leq x), x=0,1\\).La función rbinom(n,1,prob) permite simular \\(n\\) valores Bernouilli.","code":""},{"path":"intro.html","id":"binomial","chapter":"Unidad 1 Conceptos básicos","heading":"1.3.2 Binomial","text":"Consideramos un experimento Bernouilli que repetimos en \\(n\\) ocasiones, obteniendo en cada repetición sólo dos resultados posibles, “éxito” o “fracaso,” con cierta probabilidad \\(\\theta\\) para el éxito, y contabilizamos el número de éxitos \\(N\\). Los posibles resultados de este experimento son \\(\\{0, 1, 2,...,n\\}\\) éxitos conseguidos en un total de \\(n\\) pruebas. La probabilidad de observar \\(x\\) éxitos en \\(n\\) pruebas viene dada por la función:\\[\\begin{equation}\nPr(N = x) = \\frac{n!}{x!(n-x)!}  \\theta^{x} (1-\\theta)^{n-x}  \\text{ para } x = 0, 1,\\ldots,n,\n\\tag{1.3}\n\\end{equation}\\] con \\(n\\) el número de repeticiones o pruebas Bernouilli realizadas, \\(x\\) el número de éxitos obtenidos, y \\(\\theta\\) la probabilidad de éxito.Definición 1.10  La variable aleatoria \\(N\\) que se obtiene como la suma de \\(n\\) variables Bernouilli independientes con la misma probabilidad de éxito \\(\\theta\\), y cuya función de masa de probabilidad viene dada en (1.3), se denomina variable Binomial de tamaño \\(n\\) y probabilidad de éxito \\(\\theta\\), y se denota por:\\[N \\sim Bi(n,\\theta)\\]con \\(E(N) = n\\theta\\) y \\(V(N) = n\\theta(1-\\theta).\\)continuación se presentan algunos ejemplos de aplicación de la variable Binomial donde representamos tanto la fmp como la función de distribución asociada al problema de interés. Antes mencionamos las funciones de R relacionadas con esta distribución.La función dbinom(x,size,prob) nos permite evaluar la \\(Pr(N=x)\\) para una variable Binomial con tamaño size y probabilidad de éxito prob.pbinom(x,size,prob) permite evaluar la \\(Pr(N \\leq x)\\).rbinom(n,size,prob) permite simular \\(n\\) valores de una variable Binomial de tamaño size y probabilidad de éxito \\(prob\\).Ejemplo 1.5  Estamos revisando en una empresa el comportamiento de las bajas laborales. En base al histórico, se tiene que cada día aproximadamente el 3% de los trabajadores faltan al trabajo alegando una baja laboral. Si el número de trabajadores de la empresa es de 150, queremos saber qué porcentaje de días vamos tener al menos 3 trabajadores de baja.Denotemos por \\(N\\) la variable aleatoria que indica el número de trabajadores de baja en un día cualquiera, e identifiquemos el “éxito” por el hecho de “estar de baja.” Así, podemos asumir que la distribución de \\(N\\) es binomial, con tamaño 50 y probabilidad 0.03.\\[N \\sim Bi(50,0.03).\\]En consecuencia, el valor esperado del número de trabajadores de baja cada día es \\(E(N) = 50 \\cdot 0.03=1.5\\).continuación, en la Figura 1.1 representamos la fmp y la función de distribución asociadas.\nFigura 1.1: Función de masa de probabilidad y Función de distribución para el número de trabajadores de baja un día cualquiera.\nEn la fmp (Figura 1.1-izquierda) podemos ver que en este caso la probabilidad se concentra en muy pocos valores, en concreto por debajo de 10, de modo que antes de llegar \\(x=10\\) la probabilidad acumulada llega al valor 1, como se aprecia en la Figura 1.1-derecha.La probabilidad que nos reclaman en el enunciado es \\[Pr(N\\geq 3)=1-Pr(N \\leq 2),\\] que calculamos y podemos aproximar por MC partir, por ejemplo, de 1000 simulaciones.El error estimado de esta aproximación, que calculamos con la raíz cuadrada de (??) esde donde podríamos calcular un intervalo de confianza para la aproximación MC de \\(Pr(N \\geq 3)\\) al 95% utilizando la distribución (??) y la fórmula (1.1):Ejemplo 1.6  Una empresa de fabricación produce piezas, de las cuales el 97% están dentro de las especiﬁcaciones y el 3% son defectuosas (fuera de las especiﬁcaciones). Aparentemente hay ningún patrón en la producción de piezas defectuosas. La cadena de producción empaqueta las piezas en cajas de 20 piezas cada una, y produce 1000 cajas al día. Al gerente de la empresa le gustaría estimar el número de cajas con al menos dos piezas defectuosas, de entre todas las que se producen al día durante un día cualquiera.Si \\(N\\) es la variable aleatoria que recoge el número de piezas defectuosas en una caja, tenemos que: \\[N \\sim Bi(20, 0.03)\\] La probabilidad de que una caja tenga al menos dos piezas defectuosas se calcula con \\(p_N=Pr(N \\geq 2)=1-Pr(N\\leq 1)\\).Sin embargo, lo que nos piden es, de un total de 1000 cajas, cuál es el número esperado de cajas con al meos dos piezas defectuosas. Para ello, surge la variable \\(D_N\\) que representa el número de cajas, de un total de 1000, con al menos 2 piezas defectuosas, que es binomial de tamaño 1000 y probabilidad \\(p_N\\), \\[D_N \\sim Bin(1000,p_N),\\] y lo que nos están pidiendo es \\(E(D_N)=1000 p_N\\).Si simulamos con la distribución de \\(N\\) lo acontecido un día, esto es, con 1000 cajas o simulaciones, y contamos el número de cajas con 2 o más piezas defectuosas, obtenemos una aproximación la cantidad que nos piden.El problema es que todos los días son iguales. De hecho si repites los siguientes cálculos varias veces, verás como el resultado varía. La aproximación Monte Carlo habría de considerar simulaciones de la variable \\(D_n\\) , esto es, nsim días, para con ellos poder sacar una conclusión “promedio” de lo que puede ocurrir un día cualquiera.","code":"\n# los valores posibles de la variable Bin(1000,0.03) son\nxs <- 0:50\nn=50\np=0.03\n# Data frame\ndatos <- data.frame(xs = xs, probs = dbinom(xs, n,p), \n                    probsacum = pbinom(xs, n,p))\n# función de masa de probabilidad\ng1 <- ggplot(datos, aes(x=xs, y=probs)) + \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  ylim(0,0.5) +\n  labs(x =\"x\", y = \"Probabilidad puntual. Pr(N=x)\")\n# función de distribución\ng2 <- ggplot(datos, aes(xs, probsacum)) + \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  scale_y_continuous(breaks = scales::breaks_extended(10)) +\n  labs(x =\"x\", y =\"Probabilidad acumulada. Pr(N<=x)\")\ngrid.arrange(g1, g2, nrow = 1)\nnsim=1000\nn=50\np=0.03\n# valor real de la probabilidad\nprob=1-pbinom(2,n,p)\ncat(\"Pr(N>=3)=\",round(prob,3))## Pr(N>=3)= 0.189\nset.seed(1234)\n# simulaciones\nI.a=(rbinom(nsim,n,p)>=3)*1  # función indicatriz para la probabilidad requerida\nprob=mean(I.a)\ncat(\"AproxMC=\",prob)## AproxMC= 0.193\nerror=sqrt(sum((I.a-prob)^2)/(nsim^2))\ncat(\"Error.AproxMC=\",round(error,3))## Error.AproxMC= 0.012\n# límites del IC redondeados a 3 cifras decimales\nic.low=round(prob-qnorm(0.975)*error,3)\nic.up=round(prob+qnorm(0.975)*error,3)\ncat(\"IC(95%)[AproxMC]=[\",ic.low,\",\",ic.up,\"]\")## IC(95%)[AproxMC]=[ 0.169 , 0.217 ]\nn=20\np=0.03\nprob=(1 - pbinom(1, n,p))\ncat(\"Probabilidad de que una caja tenga al menos dos defectos=\",prob)## Probabilidad de que una caja tenga al menos dos defectos= 0.119838\nn=20\np=0.03\nsum(rbinom(1000,n,p)>=2)## [1] 99\nnsim=5000 # número de días simulados\nn=1000\np=prob\n# valor real del valor esperado\nmedia=n*p\ncat(\"E(D_N)=\",round(media,3))## E(D_N)= 119.838\n# simulaciones\nxi=rbinom(nsim,n,p)\nm=mean(rbinom(nsim,n,p))\ncat(\"AproxMC=\",m)## AproxMC= 119.7926\n# Error MC\nerror=sqrt(sum((xi-m)^2)/(nsim^2))\n# límites del IC redondeados a 3 cifras decimales\nic.low=round(m-qnorm(0.975)*error,3)\nic.up=round(m+qnorm(0.975)*error,3)\ncat(\"IC(95%)[AproxMC]=[\",ic.low,\",\",ic.up,\"]\")## IC(95%)[AproxMC]=[ 119.51 , 120.076 ]"},{"path":"intro.html","id":"geométrica","chapter":"Unidad 1 Conceptos básicos","heading":"1.3.3 Geométrica","text":"Imaginemos una situación experimental donde se repite un experimento hasta que sucede un “éxito.” En otras palabras, se piensa en \\(\\theta\\) como la probabilidad de éxito para un solo ensayo, y realizamos sucesivamente los ensayos hasta que se produce un éxito. La variable aleatoria \\(N\\) se define entonces como el número de ensayos Bernouilli realizados hasta conseguir un éxito. Nótese que aunque la variable aleatoria geométrica es discreta, su rango es inﬁnito, y su fmp viene dada por:\\[\\begin{equation}\nPr(N = x) = \\theta (1-\\theta)^{x}  \\text{ para } x = \\text{1, 2,...}\n\\tag{1.4}\n\\end{equation}\\] con \\(x\\) el número de repeticiones hasta alcanzar un éxito, y \\(\\theta\\) la probabilidad de éxito.Definición 1.11  La variable aleatoria \\(N\\) cuya función de masa de probabilidad viene dada en (1.4) se denomina variable Geométrica de parámetro \\(\\theta\\), y se denota por:\\[N \\sim Ge(\\theta)\\]Las funciones de R relacionadas con esta distribución se presentan continuación, y tras ello un ejemplo de aplicación de la variable Geométrica.La función dgeom(x, prob) nos permite evaluar la \\(Pr(N=x)\\) para una variable Geométrica con probabilidad de éxito prob.pgeom(x, prob) calcula la función de distribución.rgeom(n, prob) permite generar \\(n\\) valores de una variable Geométrica con probabilidad de éxito \\(prob\\). Los resultados que proporciona son el número de repeticiones realizadas hasta alcanzar el primer éxito.Ejemplo 1.7  Una vendedora de coches ha hecho un análisis estadístico de su historial de ventas anterior y ha determinado que cada día tiene un 10% de probabilidad de vender un coche de lujo. Tras un cuidadoso análisis posterior, también está claro que la venta de un coche de lujo en un día es independiente de la ventas realizadas cualquier otro día. El día de Año Nuevo (un día festivo en el que el concesionario estaba cerrado) la vendedora está intentando predecir cuándo venderá su primer coche de lujo del año.Si consideramos \\(N\\) como la variable aleatoria que indica el día de la primera venta de coches de lujo (N = 1 implica que la venta se realizaría el día 2 de enero), entonces: \\[N \\sim Ge(0.1)\\]En este caso el valor esperado del número de días transcurridos hasta la venta del primer coche de lujo es \\(E(N) = 0.9/0.1 = 9\\) días, con una desviación típica de 9.5 días. Así pues, es posible que el día 10 de enero tenga su primera venta. En la Figura 1.2 se muestran la fmp y la función de distribución asociadas.\nFigura 1.2: Función de masa de probabilidad y Función de distribución para el día en que venderá el primer coche de lujo.\nHacemos continuación un análisis de simulación para aproximar los datos teóricos dados en la definición 1.11. Simulamos 1000 valores de una \\(Ge(0.1)\\), con los que calculamos una aproximación al valor esperado de los días que deben transcurrir para vender un coche de lujo, y construimos un intervalo de confianza para la aproximación MC según (1.1).","code":"\n# Valores de N\nxs <- seq(0, 60, 1)\n# Data frame\ndatos <- data.frame(xs = xs, probs = dgeom(xs, 0.1), \n                    probsacum = pgeom(xs, 0.1))\n# función de masa de probabilidad\ng1 <- ggplot(datos, aes(xs, probs)) + \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  ylim(0,0.12) +\n  labs(x =\"x\", y = \"Probabilidad puntual. Pr(N=x)\")\n# función de distribución\ng2 <- ggplot(datos, aes(xs, probsacum)) + \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  scale_y_continuous(breaks = scales::breaks_extended(10)) +\n  labs(x =\"x\", y = \"Probabilidad acumulada Pr(N<=x)\")\ngrid.arrange(g1, g2, nrow = 1)\n# Parámetros de la simulación\n\nset.seed(1970)\nnsim <- 10000\nprob <- 0.1\nmedia<-(1-prob)/prob\ncat(\"E(N)=\",media)## E(N)= 9\n# Valores simulados\ndatos <- rgeom(nsim, prob)\n# Aproximación MC del valor esperado\nm=round(mean(datos),0)\ncat(\"AproxMC=\",m)## AproxMC= 9\n# Error MC\nerror=sqrt(sum((datos-m)^2)/(nsim^2))\n# límites del IC redondeados a 3 cifras decimales\nic.low=round(m-qnorm(0.975)*error,3)\nic.up=round(m+qnorm(0.975)*error,3)\ncat(\"IC(95%)[AproxMC]=[\",ic.low,\",\",ic.up,\"]\")## IC(95%)[AproxMC]=[ 8.811 , 9.189 ]"},{"path":"intro.html","id":"poisson","chapter":"Unidad 1 Conceptos básicos","heading":"1.3.4 Poisson","text":"La distribución de Poisson se emplea como un modelo para variables aleatorias de tipo discreto cuando se quieren obtener las probabilidades de ocurrencia de un evento que se distribuye al azar en el espacio o el tiempo. Algunos ejemplos de esta distribución se presentan continuación.En el estudio de cierto organismo acuático, se toman un gran número de muestras de un lago y se cuenta el número de dichos organismos que aparecen en cada muestra. Podríamos plantear como objetivo el conocer cuál es la probabilidad de encontrar dicho organismo en una próxima muestra si la media observada en el conjunto de muestras es de 2 organismos.En el estudio de cierto organismo acuático, se toman un gran número de muestras de un lago y se cuenta el número de dichos organismos que aparecen en cada muestra. Podríamos plantear como objetivo el conocer cuál es la probabilidad de encontrar dicho organismo en una próxima muestra si la media observada en el conjunto de muestras es de 2 organismos.En un estudio sobre la efectividad de un insecticida sobre cierto tipo de insecto, se fumiga una gran región. Posteriormente se crea una cuadrícula sobre el terreno, se selecciona de forma aleatoria un conjunto de ellas, y se cuenta el número de insectos vivos dentro de cada una. Planteamos como objetivo conocer cuál es la probabilidad de que encontremos ningún insecto vivo en una próxima cuadrícula si se sabe que la media de insectos vivos en las cuadrículas analizadas es de 0.5.En un estudio sobre la efectividad de un insecticida sobre cierto tipo de insecto, se fumiga una gran región. Posteriormente se crea una cuadrícula sobre el terreno, se selecciona de forma aleatoria un conjunto de ellas, y se cuenta el número de insectos vivos dentro de cada una. Planteamos como objetivo conocer cuál es la probabilidad de que encontremos ningún insecto vivo en una próxima cuadrícula si se sabe que la media de insectos vivos en las cuadrículas analizadas es de 0.5.Un grupo de investigadores observó la ocurrencia de hemangioma capilar retiniano (RCH) en pacientes con la enfermedad de von Hippel-Lindau (VHL). RCH es un tumor vascular benigno de la retina. Usando una revisión retrospectiva de series de casos consecutivos, los investigadores encontraron que el número de medio de tumores RCH por ojo para pacientes con VHL era de 4. Están interesados en conocer cuál es la probabilidad de que se detecten más de cuatro tumores por ojo.Un grupo de investigadores observó la ocurrencia de hemangioma capilar retiniano (RCH) en pacientes con la enfermedad de von Hippel-Lindau (VHL). RCH es un tumor vascular benigno de la retina. Usando una revisión retrospectiva de series de casos consecutivos, los investigadores encontraron que el número de medio de tumores RCH por ojo para pacientes con VHL era de 4. Están interesados en conocer cuál es la probabilidad de que se detecten más de cuatro tumores por ojo.La variable aleatoria \\(N\\) se define entonces como el número de eventos que ocurren en un espacio o un tiempo determinados, y viene caracterizada por la denominada tasa de eventos o número medio de eventos que ocurren en el tiempo o espacio, y que se denota habitualmente por \\(\\lambda\\). El rango de esta variable es infinito y su fmp viene dada por:\\[\\begin{equation}\nPr(N = x) = \\frac{e^{-\\lambda}\\lambda^x}{x!}  \\text{ para } x = \\text{1, 2,...}\n\\tag{1.5}\n\\end{equation}\\] con \\(\\lambda\\) es la tasa y \\(x\\) es el número de eventos que han ocurrido.Definición 1.12  La variable aleatoria \\(X\\) cuya función de masa de probabilidad viene dada en (1.5) se denomina variable poisson de parámetro \\(\\lambda > 0\\), y se denota por:\\[N \\sim Po(\\lambda)\\]continuación vemos diferentes ejemplos de uso de la distribución de Poisson, tras presentar las funciones de R relacionadas.La función dpois(x, lambda) nos permite evaluar la \\(Pr(X=x)\\) para una variable poisson de media \\(\\lambda\\).ppois(x, lambda) calcula la función de distribución.rpois(n, lambda) permite generar \\(n\\) valores de una variable Poisson con media \\(\\lambda\\). Los resultados que proporciona son el número de eventos que ocurren en el tiempo o espacio determinado.Ejemplo 1.8  Una empresa de asesoramiento está realizando el análisis del funcionamiento de una panadería y ha estimado que el número medio de barras de pan que se venden en un periodo de media hora es de 12. La empresa está interesada en saber cuál es la capacidad de venta en cada franja de diez minutos (pues es prácticamente el tiempo de horneado), y también cuál es la probabilidad de que el número de barras que se venden en diez minutos sea exactamente de tres.Como nuestro interés radica en un periodo de diez minutos y el número de intervalos de diez minutos en un periodo de 30 minutos es tres, tenemos que el número medio de barras puestas la venta en ese periodo viene dado por: \\[\\lambda = 12/3 = 4.\\]\nLa variable aleatoria que reproduce el número de barras que se venden en una franja de cinco minutos es:\\[N \\sim Po(4)\\]En este caso el valor esperado del número de barras que se venden es 4 y la desviación típica es igual 2(\\(=\\sqrt{4}\\)). En la Figura 1.3 se muestran la fmp y la función de distribución asociadas.\nFigura 1.3: Función de masa de probabilidad y Función de distribución para el número de barras de pan que se venden cada cinco minutos.\nPodemos reconoder en la Figura 1.3-izquierda los valores más probables con las barras más altas (3 y 4(. De hecho, en la Figura 1.3-derecha, la probabilidad de que lo sumo se vendan menos de 5 barras es algo superior 0.6.Para calcular la probabilidad pretendida, esto es, \\(Pr(N=3)\\) utilizamos la función fmp correspondiente en R y la aproximamos por MC con 1000 simulaciones, dando también una banda de confianza.Si la aproximación la hacemos con 10 veces más simulaciones, el intervalo de estimación resultará más preciso:Ejemplo 1.9  Una empresa de fabricación de galletas de chocolate está analizando la calidad en su empresa para responder del mejor modo posible sus clientes. Para ello ha fijado que con probabilidad 0.8 las galletas deben contener al menos tres trozos de chocolate para satisfacer las exigencias de los clientes. Se trata pues de fijar el valor medio de trozos de chocolate que debe ir suministrando en la cadena de producción para cumplir con el nivel de exigencia establecido.Si \\(N\\) es la variable aleatoria que indica el número de trozos de chocolate en una galleta, tenemos que: \\[N \\sim Po(\\lambda)\\]\ndonde en este caso el valor de \\(\\lambda\\) es desconocido y representa el número medio de trozos de chocolate en cada galleta. Planteamos un estudio de simulación para aproximar dicho valor.Algoritmo para aproximar el valor de \\(\\lambda\\).Considerar una secuencia de valores de \\(\\lambda_i\\), \\(=1,...,K\\)Obtener una muestra de tamaño \\(nsim\\) para cada distribución \\(Po(\\lambda_i)\\), \\(M_i=\\{x_{i_1},\\ldots,x_{i_{nsim}}\\}\\).Con cada muestra \\(M_i\\) aproximar la probabilidad de que el número de trozos sea mayor o igual 3, \\(p_i\\approx Pr(N_{\\lambda_i}\\geq3)\\).Obtener el valor mínimo de \\(\\lambda\\), de entre \\(\\{\\lambda_1,\\ldots,\\lambda_K\\}\\) que verifica \\(p_i \\geq 0.8\\).En la Figura 1.4 se muestra el proceso de simulación realizado continuación y el resultado obtenido para el valor de \\(\\lambda\\) para cumplir los requisitos de la empresa.\nFigura 1.4: Probabilidad estimada de conseguir al menos 3 trozos de chocolate en cada galleta, en función de lambda.\nAsí pues, el número medio de trozos de chocolate que ha de suministrarse cada galleta ha de ser al menos de 4.25.","code":"\n# Valores de N\nlambda=4\nxs <- seq(0, 10, 1)\n# Data frame\ndatos <- data.frame(xs = xs, probs = dpois(xs, lambda), \n                    probsacum = ppois(xs, lambda))\n# función de masa de probabilidad\ng1 <- ggplot(datos, aes(xs, probs)) + \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  scale_x_continuous(breaks = 0:10, labels = 0:10) +\n  ylim(0,0.3) +\n  labs(x =\"x\", y = \"Probabilidad puntual. Pr(N=x)\")\n# función de distribución\ng2 <- ggplot(datos, aes(xs, probsacum)) + \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  scale_x_continuous(breaks = 0:10, labels = 0:10) +\n  scale_y_continuous(breaks = scales::breaks_extended(10)) +\n  labs(x =\"x\", y = \"Probabilidad acumulada Pr(N<=x)\")\ngrid.arrange(g1, g2, nrow = 1)\nlambda=4\n# Probabilidad buscada P(N=3) para la poisson con media 2\nmedia=dpois(3,lambda)\ncat(\"Pr(N=4)=\",round(media,3))## Pr(N=4)= 0.195\nnsim <- 10000\n# Simulamos de la poisson y evaluamos la función indicatriz para la prob de interés\nset.seed(1970)\nI.a <- (rpois(nsim, lambda)==3)*1\n# Realizamos la aproximación MC\nm=mean(I.a)\ncat(\"AproxMC=\",m)## AproxMC= 0.1934\n# Error MC\nerror=sqrt(sum((I.a-m)^2)/(nsim^2))\n# límites del IC redondeados a 3 cifras decimales\nic.low=round(m-qnorm(0.975)*error,3)\nic.up=round(m+qnorm(0.975)*error,3)\ncat(\"IC(95%)[AproxMC]=[\",ic.low,\",\",ic.up,\"]\")## IC(95%)[AproxMC]=[ 0.186 , 0.201 ]\nlambda=4\n# Probabilidad buscada P(N=3) para la poisson con media 2\nmedia=dpois(3,lambda)\ncat(\"Pr(N=4)=\",round(media,3))## Pr(N=4)= 0.195\nnsim <- 10000*10\n# Simulamos de la poisson y evaluamos la función indicatriz para la prob de interés\nset.seed(1970)\nI.a <- (rpois(nsim, lambda)==3)*1\n# Realizamos la aproximación MC\nm=mean(I.a)\ncat(\"AproxMC=\",m)## AproxMC= 0.19375\n# Error MC\nerror=sqrt(sum((I.a-m)^2)/(nsim^2))\n# límites del IC redondeados a 3 cifras decimales\nic.low=round(m-qnorm(0.975)*error,3)\nic.up=round(m+qnorm(0.975)*error,3)\ncat(\"IC(95%)[AproxMC]=[\",ic.low,\",\",ic.up,\"]\")## IC(95%)[AproxMC]=[ 0.191 , 0.196 ]\n# Paso 1\nset.seed(1970)\nnsim <- 5000\nlams <- seq(0.1, 5, 0.01) # valores de lambda\nnlams <- length(lams)     # número de lambdas para evaluar\nprob <- c()  # vector de probabilidades\n\n# Pasos 2 y 3\nfor(i in 1:nlams){\n  datos <- rpois(nsim, lams[i])    \n  prob[i] <- mean(datos >= 3)   \n}\n\n# Paso 4. Resultado del problema\nlambda=lams[min(which(prob >= 0.8))];lambda## [1] 4.25\n# Pintamos los resultados de la simulación realizada\ndat=data.frame(lams=lams,prob=prob)\nggplot(dat,aes(x=lams,y=prob))+\n  geom_point()+\n  geom_hline(yintercept=0.8)+\n  geom_vline(xintercept=lambda)+\n  labs(x=\"lambda\",y=\"Pr(N>=3)\")"},{"path":"intro.html","id":"distribuciones-continuas","chapter":"Unidad 1 Conceptos básicos","heading":"1.4 Distribuciones continuas","text":"En este punto estudiamos las principales variables de tipo continuo. La especificación de estas variables se hace partir de la función de densidad.","code":""},{"path":"intro.html","id":"uniforme","chapter":"Unidad 1 Conceptos básicos","heading":"1.4.1 Uniforme","text":"La distribución uniforme es la distribución de probabilidad continua más sencilla y se refiere eventos infinitos que tienen la misma probabilidad de ocurrir en una intervalo dado. Si \\(\\) y \\(b\\) son dos números reales con \\(< b\\) entonces la función de distribución asociada la probabilidad acumulada la izquierda de cualquier valor \\(x \\[, b]\\) viene dada por: \\[\\begin{equation}\nF(x) = \n\\begin{cases}\n0 & \\text{ si } x < \\\\\n\\frac{x-}{b-} & \\text{ si } \\leq x \\leq b\\\\\n1 & \\text{ si } \\leq x \\leq b.\n\\end{cases}\n(\\#eq:var-uniforme2)\n\\end{equation}\\]Definición 1.13  Una variable aleatoria \\(X\\) tiene una distribución uniforme en el intervalo \\([, b]\\), con $,b R,\\[X \\sim U(,b)\\]La variable uniforme más famosa es la \\(U(0,1)\\) ya que se utiliza habitualmente para modelizar la incertidumbre sobre una probabilidad desconocida, y es la base para muchos de los algoritmos de simulación de variables y procesos que estudiaremos en el futuro.La función runif(n, , b) permite generar \\(n\\) valores de una variable uniforme en el intervalo \\([, b]\\); runif(n) da una muestra para una distribución uniforme en [0, 1].dunif(x,,b) da la fdp en \\(x\\).punif(x,,b) da la probabilidad acumulada para cualquier punto \\(x \\[,b]\\).","code":""},{"path":"intro.html","id":"exponencial","chapter":"Unidad 1 Conceptos básicos","heading":"1.4.2 Exponencial","text":"La distribución exponencial es una distribución muy común en la modelización probabilística. Esta distribución describe procesos que describen el tiempo entre sucesos consecutivos, con la peculiaridad de que sus probabilidades dependen del instante en que se produzcan los eventos. Es decir:\\[Pr(X > t+s | X > t) = Pr(X > s)\\] Esta propiedad es característica de la distribución exponencial y se denomina “propiedad de la pérdida de memoria.”Ejemplos de este tipo de distribución son:El tiempo que tarda una partícula radiactiva en desintegrarse. El conocimiento de la ley que sigue este evento se utiliza en ciencias para, por ejemplo, la datación de fósiles o cualquier materia orgánica mediante la técnica del carbono 14.El tiempo que tarda una partícula radiactiva en desintegrarse. El conocimiento de la ley que sigue este evento se utiliza en ciencias para, por ejemplo, la datación de fósiles o cualquier materia orgánica mediante la técnica del carbono 14.El tiempo que puede transcurrir en un servicio de urgencias, entre llegadas de pacientes, o en una fábrica entre roturas de una máquina.El tiempo que puede transcurrir en un servicio de urgencias, entre llegadas de pacientes, o en una fábrica entre roturas de una máquina.Esta distribución está muy relacionada con unos procesos que estudiaremos más adelante, denominados Procesos de Poisson.La distribución exponencial viene completamente especificada, través del parámetro \\(\\lambda >0\\) que mide el número esperado de veces que ocurre el evento de interés por cada unidad de tiempo, y cuya función de distribución viene dada por:Definición 1.14  Una variable aleatoria \\(X\\) tiene una distribución exponencial de parámetro \\(\\lambda\\), que se denota por\\[X \\sim Exp(\\lambda)\\]si su función de densidad viene dada por \\[\\begin{equation}\nf(x)=\\lambda e^{-\\lambda x}, \\quad x \\geq 0,\n\\end{equation}\\] de forma que \\(E(X) = 1/\\lambda\\) y \\(V(X) = 1/\\lambda^2.\\)Las funciones relacionadas con la distribución exponencial en R son:La función dexp(x, lambda) nos permite evaluar la función de densidad para una variable poisson de parámetro \\(\\lambda\\).pexp(x, lambda) nos permite evaluar la función de distribución.rexp(n, lambda) permite generar \\(n\\) valores de una variable Exponencial de parámetro \\(\\lambda\\).continuación estudiamos dos ejemplos de uso de la distribución exponencial. Como siempre presentamos los resultados téoricos y procedemos mediante simulación para ver la aproximación conseguida.Ejemplo 1.10  Se ha comprobado que el tiempo de vida de cierto tipo de marcapasos sigue una distribución exponencial con media 16 años. (1) ¿Cuál es la probabilidad de que una persona la que se le ha implantado este marcapasos se le deba reimplantar otro antes de 20 años? (2) Si el marcapasos lleva funcionando correctamente 5 años en un paciente, ¿cuál es la probabilidad de que haya que cambiarlo antes de 25 años desde que se implantó?Si \\(T\\) es la variable aleatoria que indica el tiempo de vida del marcapasos tenemos que:\\[T \\sim Exp(\\lambda = 1/16)\\]\nSe puede reponder fácilmente las preguntas planteadas sin más que hacer uso de la función pexp(). Sin embargo, también simularemos para aproximarlas. Hemos de calcular(1). Si es preciso implantar antes de 20 años, es porque el tiempo de vida va ser superior 20. Hemos de calcular pues, \\(Pr(T \\leq 20)\\). (2). Nos piden \\(Pr(T \\leq 25|T>5)=Pr(T\\leq 20)\\), por la propiedad de la pérdida de memoria. Es decir, respondiendo (1) tendremos respondidas las dos preguntas formuladas.\nFigura 1.5: Función de densidad del tiempo de vida del marcapasos (en años)\nObtenemos la probabilidad deseada:La probabilidad de que el marcapasos dure más de 20 años y haya que reemplazarlo es de 0.289, por lo que efectivamente, es muy recomendable reemplazarlo antes. Sin embargo, al paciente en la pregunta (2) se le daría la misma recomendación, cuando la probabilidad de que el marcapasos dure más de 25 años desde su implante, que sería el tiempo que lo llevaría, es considerablemente inferior, 0.21. es pues recomendable, utilizar esta distribución para modelizar el tiempo de vida de un implante.Ejemplo 1.11  Un motor eléctrico tiene una vida media de 6 años y se modeliza con una distribución exponencial. ¿Cuál debe ser el tiempo de garantía que debe tener el motor si se desea que lo sumo el 15 % de los motores fallen antes de que expire su garantía?Si \\(T\\) es la variable aleatoria que indica el tiempo de vida del producto tenemos que: \\[T \\sim Exp(\\lambda = 1/6).\\]\nEn este caso estamos interesados en encontrar el tiempo para que podamos garantizar que el 85% de los motores siguen funcionando, es decir, buscamos el cuantil 0.15 de la distribución de \\(T\\). Planteamos un análisis de simulación para estimar dicho valor.Para que tan sólo el 15% de los motores necesiten reparación durante el periodo de garantía, debemos establecer una garantía de aproximadamente 1 año.En la Figura 1.6 se representan, para los datos simulados, los cuantiles aproximados versus su probabilidad asociada. Con el gráfico se puede atisbar también el periodo de garantía recomendado.\nFigura 1.6: Tiempo de garantía recomendado en función de la probabilidad de que los motores necesiten reparación.\nCon esta gráfica podemos establecer el tiempo de garantía en función de las especificaciones de la empresa, es decir, fijando el porcentaje de motores que necesitarán reparación.","code":"\nlambda <- 1/16\n# Data frame para la representación gráfica\nsec <- seq(0, 80, by = 0.01)\ndatos<- data.frame(sec = sec, densidad = dexp(sec,lambda))\n# Gráfico función de densidad\nggplot(datos, aes(sec, densidad)) + \n  geom_line() +\n  scale_x_continuous(breaks = seq(0,80,5), labels = seq(0,80,5)) +\n  scale_y_continuous(breaks = scales::breaks_extended(10)) +\n  geom_vline(xintercept = 20, col = \"red\") +\n  labs(x =\"Tiempo de vida del marcapasos (en años)\", \n       y = \"Función de densidad\")\n# Probabilidad real\nlambda=1/16\np=pexp(20,lambda)\ncat(\"Pr(T<=20)=\",round(p,3))## Pr(T<=20)= 0.713\n# Parámetros de la simulación\nset.seed(123)\nnsim <- 5000\n# Simulaciones\ndatos <- rexp(nsim, lambda)\n# Probabilidad de interés\npMC=mean(datos <= 20)\ncat(\"Aprox.MC[Pr(T<=20)]=\",round(pMC,3))## Aprox.MC[Pr(T<=20)]= 0.711\n# Calculamos el valor real para el periodo de garantía\nlambda <- 1/6\nq=qexp(0.15,lambda)\ncat(\"Periodo de garantía recomendado=\",round(q,2))## Periodo de garantía recomendado= 0.98\n# Parámetros de la simulación\nset.seed(123)\nnsim <- 5000\n# simulaciones\ndatos <- rexp(nsim, lambda)\n# cuantil de interés\nqMC=quantile(datos, 0.15)\ncat(\"Periodo de garantía aproximado=\",round(qMC,2))## Periodo de garantía aproximado= 1.02\n# cuantil de interés\nprobs <- seq(0.05, 0.95, by = 0.05)\ncuantiles <- quantile(datos, probs)\ndatoscuan <- data.frame(probs, cuantiles)\n# Gráfico\nggplot(datoscuan, aes(probs,cuantiles)) + \n  geom_line() +\n  scale_x_continuous(breaks = probs, labels = probs) +\n  scale_y_continuous(breaks = scales::breaks_extended(10)) +\n  geom_vline(xintercept = 0.15, col = \"red\") +\n  labs(x =\"Probabilidad\", y = \"Tiempo a la reparación (en años)\")  "},{"path":"intro.html","id":"gamma","chapter":"Unidad 1 Conceptos básicos","heading":"1.4.3 Gamma","text":"La distribución Gamma, al igual que ocurre con la exponencial, se utiliza habitualmente para modelizar variables aleatorias positivas y asimétricas, y sobre todo para describir procesos de eventos que ocurren en el tiempo. La función de densidad de una variable aleatoria Gamma se caracteriza por dos parámetros: \\(\\alpha\\) o parámetro de forma, y \\(\\beta\\) o parámetro de escala. El parámetro de forma se denomina así porque al variar su valor se obtienen diferentes formas para la fdp. La variación del parámetro de escala cambia la forma de la distribución, pero tiende “estirar” o “comprimir” el rango de valores sobre el que se define la probabilidad.Definición 1.15  Una variable aleatoria \\(X\\), con \\(x \\geq 0\\), tiene una distribución Gamma de parámetros \\(\\alpha > 0\\) y \\(\\beta > 0\\), denotada por\\[X \\sim Ga(\\alpha, \\beta)\\]si su función de densidad viene dada por la expresióncon \\(\\Gamma()\\) la función gamma, de forma que \\(E(X) = \\alpha\\beta\\) y \\(V(X) = \\alpha\\beta^2.\\)Un caso especial de la distribución Gamma es la distribución Erlang, que se denota por \\(X \\sim Erlang(k, \\beta)\\), y que se utiliza habitualmente en la modelización de sistemas de colas de espera. Su función de densidad viene dada por :con \\(E(x) = \\beta\\) y \\(V(X) = \\beta^2/k\\). La utilidad de una variable aleatoria Erlang con parámetros \\(k\\) y \\(\\beta\\) es que es el resultado de sumar \\(k\\) variables aleatorias exponenciales (independientes) cada una con media \\(\\beta/k\\). En la modelización de los tiempos relacionados con un proceso industrial, la distribución exponencial suele ser inadecuada porque la desviación estándar es tan grande como la media. Los ingenieros suelen tratar de diseñar sistemas que produzcan una desviación estándar de los tiempos del proceso que resulte significativamente menor que su media. La distribución Erlang tiene esta propiedad: su desviación estándar disminuye medida que aumenta \\(k\\), de modo que los tiempos de proceso con una desviación estándar pequeña menudo suelen ser aproximados por una variable aleatoria Erlang.La función dgamma(x, shape, scale) nos permite evaluar la función de densidad para una variable Gamma.pgamma(x, shape, scale) calcula la función de distribución.rgamma(n, shape, scale) permite generar \\(n\\) valores de una variable Gamma.Para simular un dato de una distribución \\(y \\sim (Erlang(k, \\beta)\\)) generamos \\(k\\) datos exponenciales de \\(x_i \\sim Exp(\\beta/k), =1,\\ldots,k,\\) y calculamos la suma de todos esos valores,\\(y=\\sum_i x_i\\). Repetir este proceso tantas veces como indique el tamaño de la muestra simulada que deseamos para la distribución Erlang.Si disponemos de la media y varianza de los datos resulta muy fácil ajustar los parámetros de la distribución Gamma o Erlang sin más que resolver las ecuaciones que nos dan el valor esperado y la varianza. Si \\(\\bar{x}\\) y \\(s^2\\) son respectivamente la media y varianza, podemos ajustar los parámetros de la Gamma con:\\[ \\beta = s^2/\\bar{x}; \\quad \\alpha = \\bar{x}/\\beta\\] mientras que para la Erlang tenemos:\\[ \\beta = \\bar{x}; \\quad k = \\bar{x}^2/s^2.\\]continuación se presenta la función para generar datos Erlang patir de datos exponenciales:","code":"\n# Función para generar \"nsim\" simulaciones de una Erlang \n# con parámetros k (entero) y beta>0\nrerlang <- function(nsim, k, beta)\n{\n  # verificamos que k es entero\n  if(k%%1 == 0)\n  {\n    # parámetro de la exponencial\n    lambda <- beta/k\n    # Generamos y almacenamos datos exponenciales\n    datosexp <- matrix(rexp(nsim*k, lambda), nrow = nsim)\n    # Obtenemos la muestra de la Erlang\n    datoserl <- apply(datosexp, 1, sum)\n    return(datoserl)\n  }\n  else{\n    cat(\"k debe ser entero\")\n  }\n}"},{"path":"intro.html","id":"weibull","chapter":"Unidad 1 Conceptos básicos","heading":"1.4.4 Weibull","text":"La distribución Weibull se utiliza para describir la resistencia la rotura de diversos materiales o para describir los tiempos de fallo de muchos tipos de sistemas diferentes. La distribución Weibull tiene dos parámetros: un parámetro de escala, \\(\\beta\\) , y un parámetro de forma \\(\\alpha\\), ambos positivos. La funcion de distribución asociada viene dada por:Como en el caso de la distribución Gamma el parámetro de forma determina la forma general de la fdp y el parámetro de escala expande o contrae la fdp.Definición 1.16  Una variable aleatoria \\(X\\) tiene una distribución Weibull de parámetros \\(\\alpha>0\\) y \\(\\beta>0\\), que se denota por\\[X \\sim Weib(\\alpha, \\beta)\\]si su función de densidad viene dada por la expresión \\[\\begin{equation}\nf(x)=\\frac{\\alpha}{\\beta}\\frac{x}{\\beta}^{\\alpha-1}e^{-(x/\\beta)^{\\alpha}}, \\quad x \\geq 0.\n(\\#eq:var-weibull)\n\\end{equation}\\]El valor esperado y la varianza vienen dados por:\\[E(X) = \\beta \\Gamma(1 + 1/\\alpha); \\quad V(X) = \\beta^2 (\\Gamma(1 + 2/\\alpha) - (\\Gamma(1 + 1/\\alpha))^2).\\]En R tenemos las siguientes funciones relacionadas con la distribución Weibull.La función dweibull(x, shape, scale) nos permite evaluar la función de densidad para una variable Weibullpweibull(x, shape, scale) calcula la función de distribución.rweibull(n, shape, scale) permite generar \\(n\\) valores de una variable Weibull.partir de la media (\\(\\bar{x}\\)) y varianza (\\(S^2\\)) de un conjunto de datos, es posible obtener los parámetros de la distribución Weibull sin más que resolver las ecuaciones: \\[\\begin{eqnarray}\n\\beta &=& \\frac{\\bar{x}}{\\Gamma(1 + 1/ \\alpha)} \\\\\n\\frac{s^2}{\\bar{x}^2} - \\frac{\\Gamma(1+ 2/\\alpha)}{(\\Gamma(1 + 1/ \\alpha))^2} + 1 &=& 0.\n(\\#eq:estimaweibuleq)\n\\end{eqnarray}\\]continuación se propone una función que permite obtener los parámetros partir de la media y varianza de los datos, junto con un pequeño ejemplo para verificar su funcionalidad.","code":"\nestima.weibull <- function(m, s)\n{\n  #m=media, s=desviación típica\n  library(rootSolve)\n  # Función para optimizar alpha\n  fun.alpha <- function(a, m, s)\n              {\n                res<- 1 + (s/m)^2 - gamma(1+2/a)/(gamma(1+1/a))^2\n                return(res)\n              }\n  # Obtención de alpha\n    alpha <- round(uniroot(fun.alpha, c(0.1, 10000),m=m,s=s)$root,2)\n  # Obtención de beta\n  beta <- round(m/gamma(1+1/alpha), 2)\n  # Devolvemos alpha y beta\n  return(c(alpha, beta))\n}\n\n# Datos de ejemplo\nm <- 80     # media\ns <- sqrt(50)  # desviación típica\n# Estimación\nres=estima.weibull(m,s)\ncat(\"Weibull alpha=\",res[1],\", Weibull beta=\",res[2])## Weibull alpha= 13.83 , Weibull beta= 83.06"},{"path":"intro.html","id":"normal","chapter":"Unidad 1 Conceptos básicos","heading":"1.4.5 Normal","text":"La distribución normal es la distribución más común, reconocida por la mayoría de personas por su curva en forma de “campana,” y también llamada “campana de Gauss.” Aunque la distribución normal se utiliza mucho en la modelización de procesos y sitemas, es sin duda, la más relevante de las distribuciones aleatorias, ya que representa el supuesto básico distribucional para resolver muchos de los problemas de inferencia estadística habituales, como veremos en la sección final de esta unidad.Definición 1.17  Una variable aleatoria \\(X\\) tiene una distribución Normal de parámetros \\(\\mu\\) y \\(\\sigma\\) con \\(\\sigma >0\\), denotada por \\[ X \\sim N(\\mu, \\sigma^2),\\]\nsi su función de densidad viene dada por \\[\\begin{equation}\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right), \\quad x \\R\n\\end{equation}\\]con \\(E(X) = \\mu\\) y \\(V(X) = \\sigma^2\\), y que se denota:El parámetro \\(\\mu\\) identifica la media, y por lo tanto el centro de la distribución al ser simétrica, y el parámetro \\(\\sigma\\) la desviación típica.El caso más destacado es la denominada distribución Normal estándar, para la que \\(\\mu = 0\\) y \\(\\sigma = 1\\), por su utilización en problemas inferenciales sencillos donde la variabilidad es conocida.partir de cualquier distribución Normal podemos transformar una distribución Normal estándar. Si \\(X \\sim N(\\mu, \\sigma^2)\\) entonces la variable aleatoria \\(Z\\) definida como\\[Z = \\frac{X - \\mu}{\\sigma} \\sim N(0,1).\\]Vinculadas la distribución Normal surgen las distribuciones \\(t\\) de Student, Chi-chadrado y \\(F\\) de Snedecor (también llamada de Fisher-Snedecor), que son ampliamente utilizadas en inferencia estadística. En el último apartado de esta unidad veremos cómo utilizar estas distrbuciones para resolver mediante simulación problemas de intervalos de confianza o contrastes de hipótesis.Si \\(\\bar{X_n}=\\sum_i X_i/n\\) representa la media muestral de \\(n\\) v.. \\(N(\\mu,\\sigma)\\) y \\(S^2=\\sum_i(X_i-\\bar{X_n})^2/(n-1)\\) su varianza muestral, entonces la variable \\(Y\\) \\[ Y= \\frac{\\bar{X_n}-\\mu}{S/\\sqrt{n}}\\sim St(n-1)\\] sigue una distribución t de Student con \\(n-1\\) grados de libertad, y se denota por \\(Y\\sim St(n-1)\\).Si tenemos un conjunto de variables normales estándar independientes, \\(X_i\\sim N(0,1), =1,\\ldots,n\\), entonces su suma al cuadrado sigue una distribución chi-cuadrado con \\(n\\) grados de libertad. \\[Z=\\sum_{=1}^n X_i^2 \\sim \\chi^2_{n}\\] Por último, partir de dos distribuciones chi-cuadrado independientes, \\(U\\sim \\chi^2_n\\) y \\(V\\sim \\chi^2_m\\), tenemos que su cociente, corregido por sus grados de libertad, sigue una distribución F de Snedecor con \\(n\\) y \\(m\\) grados de libertad, \\[ W=\\frac{U/n}{V/m} \\sim F_{(n,m)}.\\]Para la distribución Normal,La función dnorm(x, mean, sd) nos permite evaluar la función de densidad para una variable Normal.pnorm(x, mean, sd) calcula la función de distribución.rnorm(n, mean, sd) permite generar \\(n\\) valores de una variable Normal.Para la distribución t de Student con \\(df1\\) grados de libertad, las funciones correspondientes son dt(x, df1), pt(x, df1) y rt(n,df1).Para la distribución chi-cuadrado con \\(df1\\) grados de libertad, contamos con las funciones dchisq(x,df1), pchisq(x,df1) y rchisq(n,df1) respectivamente.Para la distribución F de Snedecor con \\(df1\\) y \\(df2\\) grados de libertad, tenemos las correspondencias df(x, df1, df2), pf(x, df1, df2) y rf(n,df1,df2).En la Figura 1.7 aparecen representadas varias distribuciones normales con distinta media y varianza.\nFigura 1.7: Funciones de densidad para varias distribuciones normales.\nEn la Figura 1.8 aparecen representadas varias distribuciones t de Student con distintos grados de libertad.\nFigura 1.8: Funciones de densidad para varias distribuciones T de Student.\nEn la Figura 1.9 aparecen representadas varias distribuciones chi-cuadrado con distintos grados de libertad.\nFigura 1.9: Funciones de densidad para varias distribuciones Chi-cuadrado.\nEn la Figura 1.10 aparecen representadas varias distribuciones F de Snedecor con distintos grados de libertad.\nFigura 1.10: Funciones de densidad para varias distribuciones F-Snedecor.\n","code":"\nx=seq(-10,10,0.1)\ny1=dnorm(x)\ny2=dnorm(x,0,3)\ny3=dnorm(x,2,1)\ny4=dnorm(x,2,3)\ndatos=as.tibble(cbind(x,y1,y2,y3,y4))## Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n## Please use `as_tibble()` instead.\n## The signature and semantics have changed, see `?as_tibble`.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\nlevels=c(\"N(0,1)\"=\"y1\",\"N(0,3)\"=\"y2\",\"N(2,1)\"=\"y3\",\"N(2,3)\"=\"y4\")\ndatos=datos %>%\n  pivot_longer(cols=2:5,names_to=\"tipo\",values_to=\"valor\") \ndatos$tipo=fct_recode(datos$tipo,!!!levels)\n\nggplot(datos,aes(x=x,y=valor,color=tipo))+\n  geom_line()+\n  labs(color=\"Distribuciones\",y=\"Función de densidad\")\nx=seq(-5,5,0.1)\ny1=dt(x,2)\ny2=dt(x,5)\ny3=dt(x,10)\ny4=dnorm(x)\ndatos=as.tibble(cbind(x,y1,y2,y3,y4))\nlevels=c(\"St(2)\"=\"y1\",\"St(5)\"=\"y2\",\"St(10)\"=\"y3\",\"N(0,1)\"=\"y4\")\ndatos=datos %>%\n  pivot_longer(cols=2:5,names_to=\"tipo\",values_to=\"valor\") \ndatos$tipo=fct_recode(datos$tipo,!!!levels)\n\nggplot(datos,aes(x=x,y=valor,color=tipo))+\n  geom_line()+\n  labs(color=\"Distribuciones\",y=\"Función de densidad\")\nx=seq(0,200,0.1)\ny1=dchisq(x,5)\ny2=dchisq(x,10)\ny3=dchisq(x,50)\ny4=dchisq(x,100)\ndatos=as.tibble(cbind(x,y1,y2,y3,y4))\nlevels=c(\"Chi2(5)\"=\"y1\",\"Chi2(10)\"=\"y2\",\"Chi2(50)\"=\"y3\",\"Chi2(100)\"=\"y4\")\ndatos=datos %>%\n  pivot_longer(cols=2:5,names_to=\"tipo\",values_to=\"valor\") \ndatos$tipo=fct_recode(datos$tipo,!!!levels)\n\nggplot(datos,aes(x=x,y=valor,color=tipo))+\n  geom_line()+\n  labs(color=\"Distribuciones\",y=\"Función de densidad\")\nx=seq(0,5,0.01)\ny1=df(x,5,5)\ny2=df(x,1,5)\ny3=df(x,50,10)\ny4=df(x,100,200)\ndatos=as.tibble(cbind(x,y1,y2,y3,y4))\nlevels=c(\"F(5,5)\"=\"y1\",\"F(1,5)\"=\"y2\",\"F(50,10)\"=\"y3\",\"F(100,200)\"=\"y4\")\ndatos=datos %>%\n  pivot_longer(cols=2:5,names_to=\"tipo\",values_to=\"valor\") \ndatos$tipo=fct_recode(datos$tipo,!!!levels)\n\nggplot(datos,aes(x=x,y=valor,color=tipo))+\n  geom_line()+\n  labs(color=\"Distribuciones\",y=\"Función de densidad\")"},{"path":"intro.html","id":"transformadainversa","chapter":"Unidad 1 Conceptos básicos","heading":"1.5 Simular con la Transformada Inversa","text":"Aunque las distribuciones estudiadas en el punto anterior, al ser habituales provocan que los algoritmos de simulación y sus funciones de probabilidad ya estén implementadas en la mayoría de los paquetes estadísticos y de cálculo, en otras ocasiones, ante otras distribuciones menos comunes, disponemos de un método directo para la simulación de muestras aleatorias, y necesitamos recurrir algoritmos genéricos de simulación de variables.Presentamos continuación un algoritmo genérico para simular de variables discretas o continuas definidas trozos: el algoritmo de la transformada inversa, que pasamos describir, tanto para variables continuas como para variables discretas.Definición 1.18  Algoritmo de la transformada inversa para variables continuasDada una variable aleatoria \\(X\\) de tipo continuo, cuya función de distribución viene dada por \\(F(x)\\), y cuya función de distribución inversa se denota por \\(F^{-1}(x)\\), el algoritmo de la transformada inversa permite obtener una muestra de tamaño \\(n\\) de la variable \\(X\\) mediante el siguiente procedimiento:Generar \\(n\\) valores uniformes en el intervalo \\([0,1]\\), \\[u_i\\sim U(0,1), \\quad =1,...,n\\]Generar \\(n\\) valores uniformes en el intervalo \\([0,1]\\), \\[u_i\\sim U(0,1), \\quad =1,...,n\\]Devolver \\(x_i = F^{-1}(u_i)\\).Devolver \\(x_i = F^{-1}(u_i)\\).Así los valores \\(\\{x_1,...,x_n\\}\\) constituyen una muestra de \\(X\\).El algoritmo es conceptualmente similar para variables discretas, si bien por la discretización, varía levemente.Definición 1.19  Algoritmo de la transformada inversa para variables discretasDada una variable aleatoria \\(X\\), de tipo discreto, con \\(k\\) posibles valores diferentes \\(x_1,...,x_k\\), y cuya función de distribución viene dada por:\\[F(x) = Pr(X \\leq x) = \\sum_{x_i \\leq x} Pr(X = x_i), =1,...,k,\\]el algoritmo de la transformada inversa permite obtener una muestra de tamaño \\(n\\) de la variable \\(X\\) mediante el siguiente procedimiento:Generar \\(n\\) valores uniformes en el intervalo \\([0,1]\\), \\[u_i\\sim U(0,1), \\quad =1,...,n\\]Para cada \\(u_i\\) generado se determina el entero \\(\\) más pequeño que satisface \\(u_i \\leq F(x_I)\\), del conjunto \\(\\{x_1,...,x_k\\}\\)Devolver \\(x_I\\) para cada valor simulado.Así los valores \\(\\{x_1,...,x_n\\}\\) constituyen una muestra de \\(X\\).En los puntos siguientes vamos mostrar el uso de los algoritmos 1.18 y 1.19 en diferentes ejemplos de variables de tipo discreto y continuo.","code":""},{"path":"intro.html","id":"otras-distribuciones-discretas","chapter":"Unidad 1 Conceptos básicos","heading":"1.6 Otras distribuciones discretas","text":"Analizamos diferentes ejemplos en los que estamos interesados en evaluar un sistema que involucra una o más variables de tipo discreto, y donde únicamente disponemos de información sobre la función de masa de probabilidad o sobre la función de distribución.","code":""},{"path":"intro.html","id":"una-variable-discreta","chapter":"Unidad 1 Conceptos básicos","heading":"1.6.1 Una variable discreta","text":"Supongamos un sistema en el que contamos con información de una única variable discreta de interés que deseamos estudiar. En los casos más sencillos que tratamos aquí, las situaciones planteadas se pueden resolver teóricamente sin mucha dificultad, pero el objetivo es mostrar el uso de la simulación para llegar resultados aproximados los que proporcionan los métodos análiticos.Ejemplo 1.12  Una empresa que fabrica piezas para maquinaria de fabricación de calzado tiene diseñada la cadena de producción de tal forma que las piezas fabricadas se almacenan (y venden) en cajas de dos unidades. El beneficio estimado de una caja sin defectos es de 300 euros. La política de la empresa establece que si al servir una caja los clientes, esta contiene una pieza defectuosa, debe ser devuelta de forma inmediata para su reemplazo, lo que supone una pérdida de 50 euros por pieza defectuosa (y la devolución de los 300 euros de beneficio por la venta). El problema es que una vez cerradas las cajas en la cadena de producción se inspeccionan para estimar el número de cajas que se podrían devolver. La única información disponible hace referencia la tasa de defectos observada en cada caja cuando esta es devuelta, junto con el porcentaje de cajas que son devueltas. En base esta información, si \\(N\\) refleja el número de piezas defectuosas observadas, la empresa ha establecido que:La empresa quiere estudiar el beneficio estimado de acuerdo la politica de producción actual para el próximo mes, sabiendo que se pueden llegar producir hasta 1500 cajas en ese periodo. Además la empresa está interesada en conocer el beneficio estimado si cambiara su politica de calidad reduciendo su tasa de defectos por caja de acuerdo las siguientes proporciones:Para resolver las inquietudes de la empresa, vamos simular el proceso en las dos situaciones planteadas, para el horizonte propuesto de un mes, esto es, simulando las 1500 cajas y estimando el beneficio obtenido de acuerdo las políticas de calidad dadas en (1.10) y (1.11).Proponemos el siguiente algoritmo de simulación para obtener la ganancia asociada cada una de las políticas de calidad, y con dichas ganancias compararlas y concluir cuál es la más beneficiosa.Algoritmo de simulación Ante una política de calidad:Fijar las condiciones de simulación: nº cajas (\\(nsim = 1500\\)).Obtener las función de distribución acumulada vinculada con la politica de calidad de interés y aplicar el algoritmo dado en al definición 1.19 para obtener una muestra de \\(N\\), \\(x_1,...,x_n\\), relativas al número de piezas defectuosas en cada caja.Calcular el beneficio obtenido para cada caja, vinculado cada valor \\(x_i\\), denominado \\(b_i\\).Obtener la ganancia global con todas las cajas simuladas como:\\[G = \\sum_{=1}^n b_i\\]Lancemos el algoritmo para cada situación y obtengamos los beneficios esperados.En consecuencia, se aprecia cómo una leve mejora de la calidad en la producción (reduciendo la tasa de defectos) proporciona la empresa una ganancia sustancial, por lo que la política S2 sin duda es la más ventajosa para su negocio.Ejemplo 1.13  Una empresa de inversiones está considerando tres nuevos planes de inversión. Cada plan requiere una inversión de 25.000 dólares y el retorno será un año después. El plan retornará de forma fija 27.500 dólares. El plan B retornará 27.000 dólares o 28.000 dólares, con probabilidades 0.4 y 0.6, respectivamente. El plan C retornará 24.000, 27.000 o 33.000 dólares con probabilidades de 0.2, 0.5 y 0.3, respectivamente. Si el objetivo de la empresa es maximizar el rendimiento esperado, ¿qué plan debería elegir?Hay que tener en cuenta que en este caso sólo es relevante el rendimiento esperado, sino también la volatilidad esperada para ese beneficio, expresada en términos de variabilidad o incertidumbre. Será pues interesante, calcular el rendimiento o el retorno esperado en cada situación, además de su varianza o desviación típica.Vamos plantear un proceso de simulación para estimar los beneficios y volatilidad asociadas cada plan. Fijaremos el mismo número de simulaciones en cada plan, con el fin de hacer comparables los resultados. El algoritmo se presenta continuación.Algoritmo de simulaciónFijar condiciones de simulación (\\(nsim = 1000\\))Obtener la función de distribución acumulada vinculada con cada uno de los planes de inversión y aplicar el algoritmo dado en la definición 1.19 para obtener una muestra de cada uno de ellos.Calcular el beneficio obtenido para cada simulación en cada plan.Obtener la ganancia estimada de cada plan como la media de los beneficios obtenidos para cada simulación, y la volatilidad como la desviación típica de los beneficios obtenidos.Y procedemos con la simulación, calculando el beneficio esperado y la desviación típica en cada plan de inversión. Considerando que el plan tiene incertidumbre alguna (Varianza=0) y el beneficio fijo que generará será de $2500, lo incluimos en la simulación.Podemos ver que aunque el plan C es el que proporcioanrá más retorno esperado, también es el que tiene una mayor volatilidad (sd), lo que produce incertidumbre y podría repercutir en una mayor pérdida al final del periodo de inversión. El plan tiene un beneficio fijo sin volatilidad ninguna, pero es inferior al beneficio del plan B. efetos estadísticos, ya que la volatilidad (desviación típica) del plan B toma un valor inferior la media, el coeficiente de variación (\\(cv=sd/media\\)) resulta inferior 1, y en consecuencia da una alternativa razonable al plan . Por contra, ocurre así en el plan C (\\(cv>1\\)) lo que lo coloca en una situación de inferioridad frente los otros planes de inversión.Con el fin de afinar en nuestra comparación de los tres planes de inversión, nos vamos conformar con valores esperados y desviaciones típicas, y vamos calcular la probabilidad de que beneficio obtenido sea mayor 2500 dólares con cada plan, cálculo que podemos resolver fácilmente partir de las simulaciones obtenidas.Con este cálculo, el plan B sale claramente reforzado, con una probabilidad destacable de generar un beneficio superior $2500 (prob=0.6), frente al plan (prob=0) y al C (prob=0.29). El plan puede superar unos rendimientos superiores 2500, al ser este valor su fijo.","code":"\n# Parámetros de la simulación\nset.seed(19)\nnsim <- 1500\n# datos uniformes\nunif <- runif(nsim)\n# Valores a devolver (piezas defectuosas por caja)\nvalores <- c(0, 1, 2)\n# Valores a devolver y probabilidad acumulada para la política 1\nprob1 <- c(0.82, 0.15, 0.03)\nprobacum1 <- cumsum(prob1)\n# Valores a devolver y probabilidad acumulada para la política 2\nprob2 <- c(0.85, 0.13, 0.02)\nprobacum2 <- cumsum(prob2)\n# Inicialización de variables donde almacenamos las simulaciones\nxs1 <- c(); benef1 <- c()\nxs2 <- c(); benef2 <- c()\n# Simulación de la variable de interés\ni <- 1\nwhile (i <= nsim)\n{\n  # politica 1\n  xs1[i] <- valores[min(which(unif[i] <= probacum1))] \n  benef1[i] <- ifelse(xs1[i]==0, 300, -50*xs1[i]) # beneficios\n  # politica 2\n  xs2[i] <- valores[min(which(unif[i] <= probacum2))]  \n  benef2[i] <- ifelse(xs2[i]==0, 300, -50*xs2[i])\n    # nueva simulación\n  i <- i+1\n}\n# Resultados para las nsim simulaciones\nsimulacion <- data.frame(defec.s1 = xs1, benef.s1 = benef1, \n                         defec.s2 = xs2, benef.s2 = benef2)\ncat(\"Una muestra de las simulaciones realizadas es ...\\n\")## Una muestra de las simulaciones realizadas es ...\nhead(simulacion)##   defec.s1 benef.s1 defec.s2 benef.s2\n## 1        0      300        0      300\n## 2        0      300        0      300\n## 3        0      300        0      300\n## 4        0      300        0      300\n## 5        0      300        0      300\n## 6        0      300        0      300\n# Rendimientos globales\nbeneficios=simulacion %>% \n  summarise(G1 = sum(benef.s1), G2 = sum(benef.s2), \n                         Dif = G2 - G1)\ncat(\"Beneficios S1 (€):\",beneficios$G1,\n    \"Beneficios S2 (€):\",beneficios$G2,\n    \"Diferencia S2-S1 (€):\",beneficios$Dif)## Beneficios S1 (€): 350950 Beneficios S2 (€): 367200 Diferencia S2-S1 (€): 16250\n# Parámetros de la simulación\nset.seed(1970)\nnsim <- 1000\n# datos uniformes\nunif <- runif(nsim)\n# Beneficios asociados a cada plan\nBpB <- c(2000, 3000)  # beneficio variable\nBpC <- c(-1000, 2000, 8000) # beneficio variable\n# Distribuciones de probabilidiad para los planes B y C\nprobB <- c(0.4, 0.6)\nprobacumB <- cumsum(probB) # función de distribución plan B\nprobC <- c(0.2, 0.5, 0.3)\nprobacumC <- cumsum(probC) # función de distribución plan \n# Inicialización de variables donde almacenamos las beneficios \n# individuales para cada simulación\nbenefB <- c()\nbenefC <- c()\n# Simulación de la variable de interés\ni <- 1\nwhile (i <= nsim)\n{\n  # plan B\n  benefB[i] <- BpB[min(which(unif[i] <= probacumB))] \n  # plan C\n  benefC[i] <- BpC[min(which(unif[i] <= probacumC))]  \n  # nueva simulación\n  i <- i+1\n}\n# Resultado\nsimulacion <- data.frame(A=rep(2500,nsim),B = benefB, C = benefC)\ncat(\"Una muestra de las simulaciones realizadas es ...\\n\")## Una muestra de las simulaciones realizadas es ...\nhead(simulacion)##      A    B     C\n## 1 2500 2000 -1000\n## 2 2500 3000  8000\n## 3 2500 2000 -1000\n## 4 2500 2000 -1000\n## 5 2500 3000  8000\n## 6 2500 3000  8000\nbeneficios=simulacion %>% \n  summarise(mPB = mean(B), sdPB = sd(B), \n            mPC = mean(C), sdPC = sd(C))\n\ncat(\"Beneficios PlanA ($):\",2500,\n    \"Volatilidad (sd):\",0,\n   \"Beneficios PlanB ($):\",beneficios$mPB,\n    \"Volatilidad (sd):\",beneficios$sdPB,\n    \"Beneficios PlanC ($):\",beneficios$mPC, \n    \"Volatilidad (sd):\",beneficios$sdPC)## Beneficios PlanA ($): 2500 Volatilidad (sd): 0 Beneficios PlanB ($): 2604 Volatilidad (sd): 489.3091 Beneficios PlanC ($): 3122 Volatilidad (sd): 3315.435\n# Probabilidad beneficio > 2500\nc(prA = sum(simulacion$A>2500)/1000, \n  prB = sum(simulacion$B>2500)/1000, \n  prC = sum(simulacion$C>2500)/1000)##   prA   prB   prC \n## 0.000 0.604 0.289"},{"path":"intro.html","id":"mixturas-de-discretas","chapter":"Unidad 1 Conceptos básicos","heading":"1.6.2 Mixturas de Discretas","text":"Estas situaciones son muy habituales e involucran la combinación de diferentes variables de tipo discreto en un mismo sistema, en lo que se viene denominar mixtura de variables aleatorias de tipo discreto o modelos secuenciales. Sobre este tipo de distribuciones resulta bastante sencillo plantear un algoritmo de simulación. Antes de comenzar veamos desde un punto de vista téorico el concepto de mixtura de variables.Definición 1.20  Sean \\(X_1, X_2,...,X_n\\) un conjunto de variables aleatorias independientes de tipo discreto y sea \\(\\) una variable indicador de tipo discreto, definida en los valores \\(\\{1,..., n\\}\\), tal que \\[Pr(=j)=p_j, j=1,..., n, \\quad \\sum_{j=1}^n p_j = 1.\\]La variable aleatoria \\(T\\) que se define como:\\[ T = \\sum_{j =1}^n p_j X_j\\]se denomina mixtura del conjunto \\(X_1,...,X_n\\) con índice \\(\\), y además cumple que:\\[E(T) = \\sum_{j=1}^n p_j E(X_j)\\]\\[E(T^2) = \\sum_{j=1}^n p_j (V(X_j) + E(X_j)^2).\\]Así, la varianza de \\(T\\) se puede calcular fácilmente partir de la expresión:\\[V(T) = E(T^2) - E(T)^2\\]El algoritmo para simular de una mixtura es bastante sencillo y se basa en la aplicación consecutiva en dos pasos del algoritmo de la transformada inversa para variables discretas en la Definición 1.19.Definición 1.20  Algoritmo simulación mixtura variables discretasEn la situación descrita en la definición 1.20 el algoritmo para generar una muestra de la mixtura debe proporcioanr en cada simulación un vector de dos componentes: variable seleccionada (\\(\\)) y valor generado de \\(X_I\\). En concreto:Paso 1. Establecer el tamaño de muestra simular \\(nsim\\).Repetir los pasos 2 y 3 para cada iteración \\(\\) de \\(1, 2,..., nsim\\):Paso 2. Simular un valor para el indicador \\(I_i\\) de la variable de mixtura, mediante el algoritmo de la transformada inversa para una variable discreta (Definición 1.19) con probabilidades \\(p_1,...,p_n\\), y seleccionar la variable \\(X_{I_i}\\) para dicho indicador.Paso 2. Simular un valor para el indicador \\(I_i\\) de la variable de mixtura, mediante el algoritmo de la transformada inversa para una variable discreta (Definición 1.19) con probabilidades \\(p_1,...,p_n\\), y seleccionar la variable \\(X_{I_i}\\) para dicho indicador.Paso 3. Simular un valor \\(x_{I_i}\\) mediante el algoritmo de la transformada inversa para \\(X_i\\).Paso 3. Simular un valor \\(x_{I_i}\\) mediante el algoritmo de la transformada inversa para \\(X_i\\).Paso 4. Devolver el conjunto de simulaciones \\(\\{I_i, x_{I_i}\\}_{=1}^{nsim}.\\)Paso 4. Devolver el conjunto de simulaciones \\(\\{I_i, x_{I_i}\\}_{=1}^{nsim}.\\)Pasamos estudiar un par de ejemplos de situaciones secuenciales para variables discretas que se pueden modelizar según una mixtura y donde podemos aplicar el algoritmo anterior.Ejemplo 1.14  Una tienda de electrodomésticos desea analizar las ventas de hornos microondas. Los gerentes de la tienda saben que en muchas ocasiones la gente entra en la tienda simplemente para curiosear, pero de todas las personas con intenciones claras de compra, el 50% acaba comprando uno de los tres modelos disponibles y el otro 50% finalmente realiza ninguna compra. De los clientes que compran un horno, el 25% adquiere el modelo sencillo, el 50% el modelo estándar y el 25% el modelo de lujo. El modelo sencillo produce una ganancia de 30 dólares; el modelo estándar produce una ganancia de 60 dólares y el modelo de lujo produce una ganancia de 75 dólares.Los gerentes están interesados en estimar el beneficio medio por cliente de todos aquellos con intención de comprar, y que por tanto utilizan el asesoramiento (y tiempo) de los vendedores.El enfoque habitual para estimar el beneficio promedio sería mantener registros de todos los clientes que hablan con los vendedores y calcular con esos datos una estimación del beneficio esperado por cliente. Sin embargo, este proceso puede ser simulado sin mucha dificultad partir de la información proporcionada, para estimar, por ejemplo, el beneficio promedio por cliente para los próximos cien clientes.Este proceso se puede describir mediante una mixtura con dos variables \\(X_0\\) y \\(X_1\\) que expresan cuál es el beneficio que genera un cliente que entra en la tienda, mediante una variable indicador \\(\\), que identifica si un cliente está interesado o en comprar.Sea \\(X_i\\) la ganancia generada por cada cliente que entra la tienda, para cada uno de los tipos de cliente: 0=compra, 1=sí compra: \\[X_i, \\quad =0,1\\]La probabilidad de que un cliente compre o viene dada por: \\[\\begin{equation*}\nPr(= )=\n\\begin{cases}\n0.5 & =1 \\text{ (si compra)} \\\\\n0.5 & =0 \\text{ (si compra) }\n\\end{cases}\n\\end{equation*}\\]De modo que un cliente que compra produce beneficios 0 con probabilidad 1, \\[Pr(X_0=0)=1,\\] y el beneficio de un cliente que compra tiene como distribución de probabilidad: \\[\\begin{equation*}\nPr(X_1 = k) = \n\\begin{cases}\n0.25 & \\text{ para } k = 30 \\text{ modelo sencillo}\\\\\n0.50 & \\text{ para } k = 60 \\text{ modelo estándar}\\\\\n0.25 & \\text{ para } k = 75 \\text{ modelo lujo}.\n\\end{cases}\n\\end{equation*}\\]Es fácil simular cualquiera de estas distribuciones discretas mediante el algoritmo de la transformada inversa para variables discretas en la Definición 1.19, para acabar simulando de \\(T\\) con el algoritmo anterior en la Definición 1.20.Simulemos pues el proceso de venta para 30 clientes, recopilando, además de la ganancia que genera cada uno, la ganancia acumulada por las compras realizadas. Construimos una función para simular el proceso, en la que introducimos como parámetros la semilla de inicialización de la simulación y el número de clientes, por si deseamos ampliar el espectro de simulación en algún momento.Generamos el proceso para 30 clientes y analizamos los resultadosEl beneficio acumulado tras el paso de 30 clientes un día cualquiera que hemos simulado es de 600 dólares.En la Figura 1.11 se han representado los resultados de las simulaciones generadas (30 clientes que pasan la tienda), así como los beneficios acumulados por las ventas realizadas.\nFigura 1.11: Frecuencia relativa de cada tipo de venta (izquierda) y beneficio acumulado para los 30 clientes (derecha).\nPodemos también calcular la ganancia promedio que se obtiene con esos 30 clientes partir de la variable simulaciones$Bind, que resulta deSi queremos aproximar el beneficio esperado por cliente, bastará simular muchos clientes, y promediar los beneficios que le dan la tienda, o incluso el beneficio esperado por cliente que compra un microondas.Así, el beneficio medio por cliente es aproximadamente de 29.03 dólares, mientras que el beneficio esperado por cliente que compra un microondas es de 57.25 dólares. El beneficio esperado por cada 30 clientes que entran en la tienda será de \\(20.025 \\times 30=870.75\\) dólares.Ejemplo 1.15  Un fabricante de galletas presenta muchos productos nuevos cada año, de los cuales cerca del 60% fracasan, 30% tienen un éxito moderado y un 10% tienen un gran éxito. Para mejorar sus posibilidades, el fabricante somete una prueba sus nuevos productos, ante un grupo de clientes que actúa como jurado calificador. De los productos que fracasaron, 50% son calificados como malos, 30% como regulares y 20% como buenos. Para los que tuvieron un éxito moderado, la calificación es mala para un 20%, regular para un 40% y buena para otro 40%. Para los que tuvieron un gran éxito, los porcentajes son: malos 10%, regulares 30% y buenos 60%. El fabricante está interesado en conocer:¿Cuál es la probabilidad conjunta de que un producto tenga un éxito moderado y reciba una mala calificación?¿Cuál es la probabilidad conjunta de que un producto tenga un éxito moderado y reciba una mala calificación?Si un nuevo producto tiene una buena calificación, ¿cuál es la probabilidad de que fracase?Si un nuevo producto tiene una buena calificación, ¿cuál es la probabilidad de que fracase?¿Cuál es la probabilidad de que un producto tenga éxito moderado dado que este obtuvo una mala calificación?¿Cuál es la probabilidad de que un producto tenga éxito moderado dado que este obtuvo una mala calificación?Modelicemos el problema como una mixtura de distribuciones discretas según la Definición 1.20.Sea \\(I_i\\) la variable indicadora tal que \\[\\begin{equation*}\nPr(= k) = \n\\begin{cases}\n0.25 & \\text{ para } k = 1 \\text{ fracaso}\\\\\n0.50 & \\text{ para } k = 2 \\text{ éxito moderado}\\\\\n0.25 & \\text{ para } k = 3 \\text{ gran éxito}.\n\\end{cases}\n\\end{equation*}\\]Luego definimos las variables \\(X_i\\) que representan la calificación del jurado de un producto cuyo éxito o fracaso funcionó según \\(=\\): \\(X_1\\) calificación de un producto que fue un fracaso (\\(=1\\)), \\(X_2\\) calificación de un producto con un éxito moderado (\\(=2\\)) y \\(X_3\\) calificación de un producto con una gran éxito (\\(=3\\)). Las distribuciones de \\(X_1, X_2, X_3\\) vienen dadas por: \\[\\begin{equation*}\nPr(X_1 = k) = \n\\begin{cases}\n0.5 & \\text{ para } k = 1 \\text{ malo}\\\\\n0.3 & \\text{ para } k = 2 \\text{ regular}\\\\\n0.2 & \\text{ para } k = 3 \\text{ bueno}.\n\\end{cases}\n\\end{equation*}\\] \\[\\begin{equation*}\nPr(X_2 = k) = \n\\begin{cases}\n0.2 & \\text{ para } k = 1 \\text{ malo}\\\\\n0.4 & \\text{ para } k = 2 \\text{ regular}\\\\\n0.4 & \\text{ para } k = 3 \\text{ bueno}.\n\\end{cases}\n\\end{equation*}\\] \\[\\begin{equation*}\nPr(X_3 = k) = \n\\begin{cases}\n0.1 & \\text{ para } k = 1 \\text{ malo}\\\\\n0.3 & \\text{ para } k = 2 \\text{ regular}\\\\\n0.6 & \\text{ para } k = 3 \\text{ bueno}.\n\\end{cases}\n\\end{equation*}\\]Veamos el algoritmo de simulación necesario para este problema. Queremos simular productos que pueden haber tenido un gran éxito, un éxito moderado y o haber fracasado. Y para cada uno de ellos, queremos simular su calificación por el jurado que lo evaluó.Consideramos una variable \\(\\) que indica el éxito de un nuevo producto y \\(X_I\\) que indica la evaluación del producto por un jurado (para cada tipo de producto \\(\\)). En esta situación debemos proporcionar las simulaciones correspondientes \\(\\) e \\(X_I\\). En concreto:Paso 1. Establecer tamaño de muestra simular \\(nsim\\).Repetir los pasos 2 y 3 para cada iteración \\(\\) de \\(1, 2,..., nsim\\):Paso 2. Simular de la variable indicador, \\(I_i\\), mediante el algoritmo de la transformada inversa para una variable discreta con probabilidades \\(0.6, 0.3, 0.1\\) (fracaso, éxito moderado, gran éxito), y seleccionar la variable \\(X_{I_i}\\).Paso 2. Simular de la variable indicador, \\(I_i\\), mediante el algoritmo de la transformada inversa para una variable discreta con probabilidades \\(0.6, 0.3, 0.1\\) (fracaso, éxito moderado, gran éxito), y seleccionar la variable \\(X_{I_i}\\).Paso 3. Simular un valor \\(x_{I_i}\\) mediante el algoritmo de la transformada inversa para \\(X_i\\) con valores malos, regulares, buenos, y probabilidades dadas por:\nfracasos (0.5, 0.3, 0.2)\néxito moderado (0.2, 0.4, 0.4)\ngran éxito (0.1, 0.3, 0.6)\nPaso 3. Simular un valor \\(x_{I_i}\\) mediante el algoritmo de la transformada inversa para \\(X_i\\) con valores malos, regulares, buenos, y probabilidades dadas por:fracasos (0.5, 0.3, 0.2)éxito moderado (0.2, 0.4, 0.4)gran éxito (0.1, 0.3, 0.6)Paso 4. Devolver el conjunto de simulaciones \\(\\{(I_i, x_{I_i})\\}_{=1}^{nsim}.\\)Paso 4. Devolver el conjunto de simulaciones \\(\\{(I_i, x_{I_i})\\}_{=1}^{nsim}.\\)Procedamos pues, simular el proceso para, con las simulaciones, responder las preguntas planteadas por la empresa.partir de las simulaciones, obtenemos la tabla conjunta de frecuencias (Tabla 1.1) y las frecuencias relativas (Tabla 1.2), que constituyen una aproximación de las probabilidades de ocurrencia.\nTabla 1.1: Frecuencias observadas en las simulaciones.\n\nTabla 1.2: Frecuencias relativas observadas en las simulaciones. Aproximación de la distribución conjunta.\nPodemos contestar ahora las preguntas planteadas sin más que mirar la tabla anterior o realizar calculos sencillos con los datos obtenidos:¿Cuál es la probabilidad conjunta de que un producto tenga un éxito moderado y reciba una mala calificación? Estamos interesados en la probabilidad\\[Pr(\\text{Éxito = \"Moderado\" y Evaluación =  \"Malo\"})\\] cuyo valor es 0.0584.Si un nuevo producto tiene una buena calificación, ¿cuál es la probabilidad de que fracase? Para responder esta pregunta podemos aplicar el Teorema de Bayes para resolver la probabilidad condicionada siguiente partir de las frecuencias observadas en la simulación y mostradas en la Tabla 1.1,\\[Pr(\\text{E= \"Fracaso\" | Eval= \"Bueno\"}) =\n\\frac{Pr(\\text{ E=\"Fracaso\" , Eval= \"Bueno\"})}{Pr(\\text{ Eval= \"Bueno\"})}\\]donde \\(E=\\)Éxito y \\(Eval=\\)Evaluación,o directamente seleccionar sobre la Tabla 1.2 las simulaciones en las que el producto fue evaluado como “Bueno” por el jurado, y contabilizar en cuántas de ellas el producto finalmente fracasó (través del ratio correspondiente).\nTabla 1.3: Distribución condicionada que el producto fue evaluado como Bueno por el jurado.\nLa probabilidad de interés resulta 0.4080. De hecho, en la Tabla 1.3 se muestran, en la columna “resultado,” las probabilidades condicionadas que el jurado emitió una buena calificación del producto. ¿Cómo podemos interpretar esas probabilidades?¿Cuál es la probabilidad de que un producto tenga éxito moderado dado que éste obtuvo una mala calificación? Procedemos como en la pregunta anterior ya que estamos interesados en\\[Pr(\\text{E= \"Moderado\" | Eval = \"Malo\"}) = \\frac{Pr(\\text{E= \"Moderado\" , Eval = \"Malo\"})}{Pr(\\text{ Eval= \"Malo\"})}\\] Y lo resolvemos de nuevo generando la distribución condicionada que la evaluación por el jurado sea “Mala,” que se muestra en la Tabla 1.4\nTabla 1.4: Distribución condicionada que el producto fue evaluado como Malo por el jurado.\nLa probabilidad de interés es 0.1574. ¿Cómo podemos interpretar la Tabla 1.4 de probabilidades obtenida?","code":"\nsimula.ventas.micro <- function(clientes, semilla)\n{\n# Descripción del proceso de compra o no compra\ncompra <- c(\"Si\", \"No\")\npcompra <- 0.50\n# Descripción del proceso de adquisión del microondas\ntipo <- c(\"Sencillo\", \"Estándar\", \"Lujo\")\nprmicro <- c(0.25, 0.50, 0.25) # fmp X1\nprmicroacum <- cumsum(prmicro) # fon. distribución X1\nbeneficio <- c(30, 60, 75)\n# Inicialización de variables para las simulaciones\nindicador <- c()             # proceso de compra\nmicro <- c()                 # tipo microondas adquirido\nbind <- rep(0, clientes)     # beneficio individual\nbacum <- rep(0, clientes)    # beneficio acumulado\n\n## Simulación del proceso\n##########################\ni <- 1\n# Generamos uniformes para describir el proceso de compra y \n# el tipo de microondas adquirido\nset.seed(semilla)\nucompra <- runif(clientes) # uniformes para el indicador\numicro <- runif(clientes)  # uniformes para la compra\n\n# Bucle de simulación\nwhile (i <= clientes)\n{\n  # Proceso de compra\n  indicador[i] <- ifelse(ucompra[i] <= 0.5, compra[1], compra[2])\n  # Tipo de microndas\n  if(indicador[i] == compra[1])\n  {\n    pos <- min(which(umicro[i] <= prmicroacum))\n    micro[i] <- tipo[pos]\n    bind[i] <- beneficio[pos]\n  }\n  else\n  {\n    micro[i] <- \"Sin venta\"\n    bind[i] <- 0\n  }\n  bacum[i] <- sum(bind[1:i])  # se acumulan todos los beneficios\n  # nueva simulación\n  i <- i+1\n}\n# Resultado\nreturn(data.frame(Compra = indicador, Tipo = micro, \n                  Bind = bind, Bacum = bacum))\n}\nsimulacion <- simula.ventas.micro(30, 123)\nhead(simulacion)##   Compra      Tipo Bind Bacum\n## 1     Si      Lujo   75    75\n## 2     No Sin venta    0    75\n## 3     Si  Estándar   60   135\n## 4     No Sin venta    0   135\n## 5     No Sin venta    0   135\n## 6     Si  Estándar   60   195\n# el beneficio acumulado tras el paso de 30 clientes\ntail(simulacion,n=1)##    Compra     Tipo Bind Bacum\n## 30     Si Estándar   60   600\ng1=simulacion %>%\n  group_by(Tipo) %>%\n  summarise(n=n()) %>%\n  mutate(prop=n/nrow(simulacion)) %>%\n  ggplot(aes(x = Tipo, y = prop)) +\n    geom_col(aes(fill = Tipo), position = \"dodge\") +\n    geom_text(aes(label = scales::percent(prop), \n                  y = prop, group = Tipo),\n              position = position_dodge(width = 0.9),\n              vjust = 1.5)+\n  labs(x=\"Tipo de cliente\",y=\"Proporción\")+\n  theme(legend.position=\"none\")\n\ng2 <- ggplot(simulacion, aes(1:30, Bacum)) + \n  geom_line() +\n  labs(x = \"Cliente\", y = \"Beneficio acumulado\")\ngrid.arrange(g1, g2, nrow = 1)\nmean(simulacion$Bind)## [1] 20\nnsim <- 1000 # número de clientes simulados\nsimulacion <- simula.ventas.micro(nsim,123)\n# aproximación MC del beneficio medio de un cliente cualquiera\nmean(simulacion$Bind)## [1] 29.025\n# beneficio medio de un cliente de compra\nmean(simulacion$Bind[simulacion$Compra==\"Si\"])## [1] 57.24852\n# Parámetros iniciales\nnsim <- 5000\nsemilla <- 12\n# Descripción variable indicadora\nexito <- c(\"Fracaso\", \"Moderado\", \"Éxito\")\npexito <- c(0.6, 0.3, 0.1)\npexitoacum <- cumsum(pexito)\n# Descripción del proceso de adquisión del microondas\nclasifi <- c(\"Malo\", \"Regular\", \"Bueno\")\np1 <- c(0.5, 0.3, 0.2)\np2 <- c(0.2, 0.4, 0.4)\np3 <- c(0.1, 0.3, 0.6)\np1acum <- cumsum(p1)\np2acum <- cumsum(p2)\np3acum <- cumsum(p3)\n\n# Inicialización de variables para las simulaciones\nproducto <- c()             # éxito producto\njurado <- c()               # clasificación jurado\n\n## Simulación del proceso\n##########################\ni <- 1\n# Generamos uniformes para describir el proceso de indicadores de éxito\n# y también el de evaluación o clasificación por el jurado\nset.seed(semilla)\nuexito <- runif(nsim)  \nuclasi <- runif(nsim)\n\n# Bucle de simulación\nwhile (i <= nsim)\n{\n  # Éxito del producto\n  producto[i] <- exito[min(which(uexito[i] <= pexitoacum))]\n  # Tipo de microndas\n  if(producto[i] == exito[1])\n  {\n    jurado[i] <- clasifi[min(which(uclasi[i] <= p1acum))]\n  }\n  else if (producto[i] == exito[2])\n  {\n    jurado[i] <- clasifi[min(which(uclasi[i] <= p2acum))]\n  }\n  else\n  {\n    jurado[i] <- clasifi[min(which(uclasi[i] <= p3acum))]    \n  }\n  # nueva simulación\n  i <- i+1\n}\n# Resultado\nsimulacion <- data.frame(producto = producto, jurado = jurado)\ndistri.conjunta.frec <- table(simulacion)\nkbl(distri.conjunta.frec,caption=\"Frecuencias observadas en las simulaciones.\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"),full_width = F)\ndistri.conjunta=as.data.frame(table(simulacion)/nsim)\nkbl(distri.conjunta,caption=\"Frecuencias relativas observadas en las simulaciones. Aproximación de la distribución conjunta.\") %>%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\"),full_width = F)\ndistri.conjunta.frec[2,1]/sum(distri.conjunta.frec[,1])## [1] 0.4080352\ndistri.conjunta %>% \n  filter(jurado == \"Bueno\") %>%\n  mutate(pr.bueno = sum(Freq), resultado = round(Freq/pr.bueno,4)) %>%\n  kbl(caption=\"Distribución condicionada a que el producto fue evaluado como Bueno por el jurado.\")%>%\n      kable_styling(bootstrap_options =c(\"striped\",\"hoover\"),full_width = F)\ndistri.conjunta %>% \n  filter(jurado == \"Malo\") %>%\n  mutate(pr.malo = sum(Freq), resultado = round(Freq/pr.malo,4)) %>%\n  kbl(caption=\"Distribución condicionada a que el producto fue evaluado como Malo por el jurado.\") %>%\n  kable_styling(bootstrap_options =c(\"striped\",\"hoover\"),full_width = F)"},{"path":"intro.html","id":"otras-distribuciones-continuas","chapter":"Unidad 1 Conceptos básicos","heading":"1.7 Otras distribuciones continuas","text":"En el caso de variables de tipo continuo de las que disponemos de un generador de valores aleatorios pero sí disponemos de su función de densidad o distribución, podemos utilizar el algoritmo de la transformada inversa, dado en la definición 1.18, para obtener una muestra aleatoria de tamaño \\(n\\) de su distribución.En primer lugar estudiamos situaciones con una variable y posteriormente vemos ejemplos de sistemas de variables continuas o mixturas de discretas y continuas.","code":""},{"path":"intro.html","id":"una-variable-continua","chapter":"Unidad 1 Conceptos básicos","heading":"1.7.1 Una variable continua","text":"Estudiamos aquí, través de ejemplos, la simulación de variables aleatorias de tipo continua para las que conocemos la función de densidad o distribución, y se quiere revolver algún problema inferencial.Ejemplo 1.16  Sea \\(X\\) una variable aleatoria de tipo continuo cuya función de densidad viene dada por: \\[\\begin{equation*}\nf(x) = 2e^{-2x}  \\text{ para } x \\geq 0\n\\end{equation*}\\]Estamos interesados en conocer:¿Cuál es la probabilidad de que la variable de interés tome valores en el intervalo [1, 2]?¿Cuál es la probabilidad de que la variable de interés tome valores mayores o iguales 1.5?¿Cuál es el valor esperado de la variable? ¿y la desviación típica?Para poder responder las preguntas planteadas debemos obtener en primer lugar la función de distribución asociada \\(X\\), que viene dada por:Podemos aplicar ahora el método de la transformada inversa para obtener una muestra de \\(X\\).El algoritmo de simulación basado en la transformada inversa, en la Definición 1.18 viene dado por:Si \\(F(X)\\) es la función de distribución para \\(X\\) dada en la Ecuación (1.12)Paso 1. Establecer el tamaño de muestra simular \\(nsim\\).Repetir los pasos 2 y 3 para cada iteración \\(\\) de \\(1, 2,..., nsim\\):Paso 2. Generar \\(u_i\\) partir de una \\(U(0,1)\\).Paso 2. Generar \\(u_i\\) partir de una \\(U(0,1)\\).Paso 3. Aplicar el método de la transformada inversa para obtener \\(x_i = F^{-1}(u_i)\\) con \\(F^{1}(u_i) = -log(1-u_i)/2.\\)Paso 3. Aplicar el método de la transformada inversa para obtener \\(x_i = F^{-1}(u_i)\\) con \\(F^{1}(u_i) = -log(1-u_i)/2.\\)Paso 4. Devolver el conjunto de simulaciones \\(\\{x_i\\}_{=1}^{nsim}\\).Paso 4. Devolver el conjunto de simulaciones \\(\\{x_i\\}_{=1}^{nsim}\\).Apliquemos pues el algoritmo anterior, y generemos una muestra de tamaño \\(nsim=5000\\) para \\(X\\). Aprovechamos el calculo vectorial de R para tener que hacer un bucle.Y con las simulaciones obtenidas, respondamos cada una de las preguntas planteadas:","code":"\n# Parámetros iniciales\nnsim <- 5000\nset.seed(12)\n# Generamos uniformes \nuniforme <- runif(nsim)\n# Calculamos x con F^-1\nxs <- -log(1-uniforme)/2\n# Pr(1 <= X <= 2)\ncat(\"Pr(1 <= X <= 2)=\",round(mean(xs >= 1 & xs <= 2), 4))## Pr(1 <= X <= 2)= 0.121\n# Pr(X >= 1.5)\ncat(\"Pr(X >= 1.5)=\",round(mean(xs >= 1.5), 4))## Pr(X >= 1.5)= 0.053\n# Valor esperado y varianza\ncat(\"E(X)=\",round(mean(xs), 4))## E(X)= 0.5046\ncat(\"V(X)=\",round(sd(xs), 4))## V(X)= 0.5078"},{"path":"intro.html","id":"composicionsec","chapter":"Unidad 1 Conceptos básicos","heading":"1.7.2 Transformaciones y Método de Composición","text":"En ocasiones, se nos plantea el problema de inferir, través de simulación, sobre una variable aleatoria \\(Y\\) que se obtiene como una transformación continua de otra variable \\(X\\) cuya distribución conocemos, esto es, \\[Y=h(X), \\quad \\text{ con } X \\sim F(x).\\]En particular, \\[E(Y)=\\int_S h(x) f(x)dx.\\]Se propone un algoritmo sencillo para simular muestras aleatorias de la variable \\(Y\\), denominado método de composición y que se presenta continuación.Definición 1.21  Método de composiciónSi \\(X\\) es una variable aleatoria continua con función de distribución \\(F(X)\\), e \\(Y\\) otra variable aleatoria que se obtiene como \\(Y = h(X)\\), donde \\(h()\\) es una función continua, podemos obtener una muestra de \\(Y\\) partir del siguiente proceso:Paso 1. Fijar el número de simulaciones (\\(nsim\\)).Repetir los pasos 2 y 3 hasta alcanzar el número de simulaciones del paso 1.Paso 2. Generar un valor de la variable \\(X\\), \\(\\{x_i \\sim F(x)\\}\\).Paso 3. Calcular el valor de la variable \\(Y\\) para esa simulación mediante \\(y_i = h(x_i)\\).Paso 4. Devolver el conjunto de valores simulados \\(\\{y_i\\}_{=1}^{nsim}.\\)Ejemplo 1.17  Sea \\(X\\) una variable aleatoria de tipo continuo cuya función de densidad viene dada por:y consideramos la variable aleatoria \\(Y = 1 - X^2\\). Estamos interesados en conocer:¿Cuál es el valor esperado de la variable \\(Y\\)? ¿Y su desviación típica?\\(Pr(Y \\[0,1])\\)\\(Pr(Y \\geq 0.5)\\)Puesto que la distribución de \\(X\\) es de las estándar, para simular de ella hemos de utilizar el método de la transformada inversa (Definición 1.18), para lo que hemos de obtener necesariamente su función de distribución, que viene dada por:La función de distribución inversa es pues: \\[F^{-1}(u)=u^{1/3}\\]El algoritmo para obtener una muestra de \\(Y\\) viene dado por:Si \\(F(X)\\) es la función de distribución para \\(X\\) dada en (1.13)Paso 1. Establecer tamaño de muestra simular \\(nsim\\).Repetir los pasos 2 4 para cada iteración \\(\\) de \\(1, 2,..., nsim\\):Paso 2. Generar \\(u_i\\) partir de una \\(U(0,1)\\).Paso 3. Aplicar el método de la transformada inversa para obtener \\(x_i = F^{-1}(u_i)=u^{1/3}\\).Paso 4. Actuar por composición y calcular \\(y_i = 1 - x_i^2\\).Paso 5. Devolver el conjunto \\(\\{y_i\\}_{=1}^{nsim}.\\)Procedemos con el algoritmo de simulación.Podemos calcular ahora las cantidades de interés:Representamos gráficamente las simulaciones obtenidas tanto para la variable \\(X\\) como la \\(Y\\).\nFigura 1.12: Función de densidad empírica e histogramas para X e Y.\n","code":"\n# Parámetros iniciales\nnsim <- 5000\nset.seed(12)\n# Generamos uniformes \nuniforme <- runif(nsim)\n# Calculamos x con F^-1\nxs <- uniforme^(1/3)\n# Calculamos y = h(x)\nys <- 1 - xs\n# Devolvemos los valores de x e y\nsimulacion <- data.frame(sim = 1:nsim, x = xs, y = ys)\n# Valor esperado y desviación típica de Y \ndatos <- simulacion$y\ncat(\"E(Y)=\", round(mean(datos), 4))## E(Y)= 0.2478\ncat(\"sd(Y)=\", round(sd(datos), 4))## sd(Y)= 0.1915\n# Pr(0 <= Y <= 1) \ncat(\"Pr(0 <= Y <= 1)=\", round(sum(datos >= 0 & datos <= 1)/nsim, 4))## Pr(0 <= Y <= 1)= 1\n# Pr(Y >= 1) \ncat(\"Pr(Y >= 0.5)=\", round(sum(datos >= 0.5)/nsim, 4))## Pr(Y >= 0.5)= 0.121\ng1 <- ggplot(simulacion, aes(x, ..density..)) + \n  geom_histogram(fill = \"steelblue\") +\n  geom_density()+\n  labs(x = \"X\", y = \"Densidad\")\ng2 <- ggplot(simulacion, aes(y, ..density..)) + \n  geom_histogram(fill = \"steelblue\") +\n  geom_density()+\n  labs(x = \"Y\", y = \"Densidad\")\ngrid.arrange(g1, g2, nrow = 1)## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"intro.html","id":"combinaciones-de-variables","chapter":"Unidad 1 Conceptos básicos","heading":"1.7.3 Combinaciones de variables","text":"Continuamos este bloque con un tipo de problema que nos encontraremos en muchas ocasiones en el análisis de sistemas, como es la definición de nuevas variables al operar (combinar aritméticamente) otras cuya distribución es conocida. Un ejemplo típico es la suma o resta de variables aleatorias. Imaginemos que tenemos dos variables \\(X_1\\) y \\(X_2\\) con funciones de densidad \\(f_1(x_1)\\) y \\(f_2(x_2)\\) respectivamente, y estamos interesados en estudiar las variables:\\[Y = X_1 + X_2 \\quad\\text{ y } \\quad Z = X_1 - X_2\\] Para el estudio de \\(Y\\) y \\(Z\\) podemos proceder teóricamente mediante los correspondientes cambios de variable, pero en situaciones má complejas o con más variables ese procedimiento es poco práctico. En dichas situaciones, podemos utilizar el método de composición para obtener una muestra de las nuevas variables.Definición 1.22  Método de composición para combinaciones de variablesSi \\(X_1,..., X_n\\) es un conjunto de variables aleatorias continuas con funciones de distribución \\(F_1,..., F_n\\) y se define la variable aleatoria \\(Y\\) mediante una transformación \\(h(X_1,...,X_n)\\), donde \\(h()\\) es una función continua, podemos obtener una muestra de \\(Y\\) mediante el siguiente procedimiento:Paso 1. Fijar el número de simulaciones (\\(nsim\\)).Repetir pasos 2 y 3 hasta alcanzar el número de simulaciones fijado en el paso 1Paso 2. Generar un valor de cada variable \\(X_i\\), \\(x_{ji} \\sim F(x_j), \\quad j=1,\\ldots,n\\).Paso 3. Calcular el valor de la variable \\(Y\\) mediante \\(y_i = h(x_{1i},...,x_{ni})\\).Paso 4. Devolver el conjunto de valores simulados \\(\\{y_i\\}_{=1}^{nsim}.\\)Estudiamos continuación algunos ejemplos donde se aplica el algoritmo expuesto.Ejemplo 1.18  Supongamos que tenemos un conjunto de 10 variables \\(X_1,...,X_{10}\\), tales que cada una de ellas se distribuye de forma independiente como: \\[X_i \\sim U(0,1), \\quad =1,...,10\\] y consideramos además las variables aleatorias \\[\\begin{eqnarray*}\nY_{min} &=& min\\{X_1,...,X_{10}\\},\\\\\nY_{max} &=& max\\{X_1,...,X_{10}\\}.\n\\end{eqnarray*}\\]Estamos interesados en conocer:¿Cuál es el valor de \\(Pr[(Y_{min} \\leq 0.1) \\cap (Y_{max} \\geq 0.8)]\\).¿Cuál es el valor esperado del rango, definido como \\(R = Y_{max} - Y_{min}\\)?¿Cuál es el valor de \\(Pr(R \\geq 0.5)\\)?Auque el problema teórico se puede resolver fácilmente, vamos plantear un algoritmo de simulación para responder las cuestiones de interés.Algoritmo para obtener una muestra de \\(Y_{min}, Y_{max}\\) y \\(R\\).Paso 1. Fijar el número de simulaciones (\\(nsim\\)).Repetir los pasos 2 4 hasta alcanzar el número de simulaciones fijado en el paso 1.Paso 2. Generar valores \\(x_{1,},...,x_{10,} \\sim U(0,1)\\).Paso 3. Aplicando composición calcular \\(y_{min,} = min\\{x_{1,},...,x_{10,}\\}\\) e \\(y_{max,} = max\\{x_{1,},...,x_{10,}\\}\\).Paso 4. Aplicando composición calcular \\(r_{} = y_{max,} - y_{min,}.\\)Paso 5. Devolver el conjunto de valores simulados \\(\\{y_{min,}, y_{max,}, r_{}\\}_{=1}^{nsim}.\\)Procedemos con el algoritmo de simulación. Aprovechamos las ventajas de R para el cálculo vectorial y evitar los bucles.Podemos evaluar ahora las cuestiones de interés partir de la muestra obtenida para las tres variables.Representamos en la Figura 1.13 la distribución obtenida partir de las simulaciones para las tres variables consideradas.\nFigura 1.13: Simulaciones del mímimo, máximo y rango de X1,…,X10 v.. U(9,1).\nEjemplo 1.19  En un estudio de calidad se está analizando el ajuste entre las pernos y las tuercas de cierto proceso de fabricación. Los pernos y las tuercas se fabrican de forma independiente y se colocan en dos cajas. Posteriormente se elige un perno y una tuerca y se prueba si encajan entre sí. Un perno y una tuerca ajustarán si el diámetro del agujero de la tuerca es mayor que el diámetro del perno y la diferencia entre estos diámetros es mayor que 0.06 centímetros. Cuando se cumplen estas especificaciones, tanto la tuerca como el perno se desechan. Las especificaciones de fabricación de los pernos indican que su diámetro se puede considerar que es una variable Normal con media 2 centimetros y desviación típica de 0.01 centímetros, mientras que el diámetro de las tuercas es una variable Normal con media 2.03 centímetros y desviación típica de 0.02 centímetros.¿Cuál es la probabilidad de que encajen un perno y una tuerca elegidos al azar en una caja cualquiera?Si se fabrican 10000 pernos y tuercas en un día, ¿cuántas desecharemos?Si el porcentaje de desechos es inferior al 15% en un día se modificarán las especificaciones de fabricación ¿Consideras que deberían modificarse las especificaciones de fabricación?Partimos pues, para resolver el problema, de las variables \\(T\\sim N(2.03, 0.02)\\), que representa el diámetro de una tuerca, y \\(P \\sim N(2, 0.01)\\) que representa el diámetro de un perno. Las especificaciones de calidad exigen que \\(T>P\\) y que \\(Dif=T-P\\leq 0.6\\), o lo que es lo mismo, \\(0<Dif\\leq 0.6\\).Veamos cómo podríamos simular para responder las preguntas planteadas.Algoritmo para obtener la diferencia entre los diámetros de las tuercas y los pernos.Paso 1. Fijar el número de simulaciones (\\(nsim\\)).Repetir los pasos 2 4 hasta alacanzar el número de simulaciones fijado en el paso 1.Paso 2. Generar valores \\(t_i\\sim F(T)\\) y \\(p_i \\sim F(P)\\) de sus respectivas distribuciones.Paso 3. Aplicando composición, calcular \\(dif_i = t_i - p_i.\\)Paso 4. Verificar el requisito de calidad: \\(0 < dif_i \\leq 0.06\\) y asignar \\(valid_i = 1\\) si se cumple con el criterio y \\(valid_i = 0\\) en otro caso.Paso 5. Devolver el conjunto de valores simulados \\(\\{t_i, p_i, dif_i, valid_i\\}_{=1}^{nsim}.\\)Pongamos en práctica el algoritmo diseñado.Representamos los datos simulados en la Figura 1.14, con la que podemos ya responder la primera pregunta:¿Cuál es la probabilidad de que encajen un perno y una tuerca elegidos al azar en una caja cualquiera? Como vemos en la gráfica superior izquierda, la respuesta es 0.82, la vista de que el 82% de las cajas inspeccionadas son válidas.\nFigura 1.14: Simulaciones del proceso de calidad para tuercas y pernos.\nRespondemos las siguientes preguntas:Si se fabrican 10000 pernos y tuercas en un día, ¿cuántas desecharemos? Si nuestra producción es de 10000 parejas, el número de parejas desechadas será igual :Si el porcentaje de desechos es inferior al 15% en un día se modificarán las especificaciones de fabricación ¿Consideras que deberían modificarse las especificaciones de fabricación? Realmente el porcentaje de piezas desechadas es del 18% (gráfico superior izquierdo en la Figura 1.14), por lo que la recomendación sería abordar un proceso de mejora en la fabricación para reducir los defectos.Ejemplo 1.20  Una empresa de fabricación de componentes para aviones tiene entre sus productos una barra que se coloca como sujeción en las alas, y que se construye mediante la unión consecutiva de tres secciones , B, y C. Las especificaciones de fabricación establecen que la longitud (en pulgadas) de cada barra es una distribución Normal. Más concretamente la sección tiene una media de 20 pulgadas y una varianza de 0.04. la longitud de la sección B tiene una media de 14 y varianza de 0.01, mientras que la sección C tiene una media de 26 y varianza 0.04. Las tres piezas se unen consecutivamente (con B y B con C) de forma que se encajan superponiendo 2 pulgadas en cada unión. La barra sólo puede ser utilizada si su longitud total está entre 55.5 y 56.5 pulgadas.¿Cuál es la probabilidad de que la barra sea utilizable?Si en un mes se fabrican 25000 barras ¿cuál es el número de barras desechadas?Por cada barra dentro de especificaciones se obtiene un beneficio de 300 euros, pero si se desecha, se genera una pérdida de 100 euros. ¿Cuál será el beneficio estimado en un mes?Si denominamos \\(LA\\), \\(LB\\), y \\(LC\\) las variables aleatorias correspondientes las longitudes de las secciones , B, y C respectivamente, las distribuciones asociadas vienen dadas por:\\[LA \\sim N(20, \\sqrt{0.04}); \\quad LB \\sim N(14, \\sqrt{0.01}); \\quad  LC \\sim N(26, \\sqrt{0.04})\\] La otra variable involucrada es la suma de barra al unir las piezas, que se obtiene como \\(L=LA+LB+LC-4\\), dado que en cada junta se pierden 2 pulgadas. Las especificaciones de calidad sobre ella son \\(55.5 \\leq L \\leq y 56.5\\).Proponemos pues, un algoritmo de simulación que nos permita simular la longitud total de la barra partir de cada una de las secciones, y verificar si está dentro de las especificaciones de calidad establecidas.Paso 1. Fijar el número de simulaciones (\\(nsim\\)).Repetir los pasos 2 4 hasta alcanzar el número de simulaciones fijado en el paso 1.Paso 2. Generar valores \\(LA_i\\), \\(LB_i\\), y \\(LC_i\\) partir de sus distribuciones correspondientes.Paso 2. Generar valores \\(LA_i\\), \\(LB_i\\), y \\(LC_i\\) partir de sus distribuciones correspondientes.Paso 3. Aplicando composición, calcular \\(L_i = LA_i + LB_i + LC_i - 4.\\)Paso 3. Aplicando composición, calcular \\(L_i = LA_i + LB_i + LC_i - 4.\\)Paso 4. Verificar el requisito de calidad: \\(55.5 \\leq L_i \\leq 56.5\\) y asignar \\(valid_i = 1\\) si lo cumple, y \\(valid_i = 0\\) si lo cumple.Paso 4. Verificar el requisito de calidad: \\(55.5 \\leq L_i \\leq 56.5\\) y asignar \\(valid_i = 1\\) si lo cumple, y \\(valid_i = 0\\) si lo cumple.Paso 5. Devolver el conjunto de valores simulados \\(\\{LA_i, LB_i, LC_i, L_i, valid_i\\}_{=1}^{nsim}.\\)Paso 5. Devolver el conjunto de valores simulados \\(\\{LA_i, LB_i, LC_i, L_i, valid_i\\}_{=1}^{nsim}.\\)Programemos el algoritmo.Respondamos las preguntas partir de las simulaciones obtenidas.¿Cuál es la probabilidad de que la barra sea utilizable? La respuesta viene aproximada por la proporción de piezas válidas. Calculamos también un intervalo de confianza utilizando la ecuación (1.1).Dado el error tan pequeño que genera el proceso de simulación, la estimación proporcionada es claramente precisa.Si en un mes se fabrican 25000 barras ¿cuál es el número de barras desechadas?Por cada barra dentro de especificaciones se obtiene un beneficio de 300 euros, pero si se desecha, se genera una pérdida de 100 euros. ¿Cuál será el beneficio estimado en un mes?","code":"\n# Parámetros iniciales\nnsim <- 5000\nnvar <- 10  # número de variables\nset.seed(12)\n# Generamos matriz de datos uniformes de dimensiones nsim*nvar \nuniforme <- matrix(runif(nsim*nvar), nrow = nsim)\n# Calculamos y_min e y_max\nymin <- apply(uniforme, 1, min)\nymax <- apply(uniforme, 1, max)\n# Calculamos rango\nrango <- ymax - ymin\n# Devolvemos los valores \nsimulacion <- data.frame(sim = 1:nsim, \n                         ymin = ymin, ymax = ymax, \n                         rango = rango)\n#  Pr(Y_{min} <= 0.1, Y_{max} >= 0.8)$\np1 = mean((simulacion$ymin <= 0.1) & (simulacion$ymax >= 0.8))\ncat(\"Pr(Y_{min} <= 0.1, Y_{max} >= 0.8)=\", round(p1, 4))## Pr(Y_{min} <= 0.1, Y_{max} >= 0.8)= 0.5732\n# Valor esperado del rango \ncat(\"E(R)=\",round(mean(simulacion$rango), 4))## E(R)= 0.8183\n# Pr(R >= 0.5)\ncat(\"Pr(R >= 0.5)=\",round(mean(simulacion$rango >= 0.5), 4))## Pr(R >= 0.5)= 0.9874\norden <- c(\"ymin\", \"ymax\", \"rango\")\n# Construimos matriz de datos para el gráfico\ndatos <- pivot_longer(simulacion, cols = 2:4, \n                      names_to = \"Medida\", values_to = \"Valor\")\n# gráfico\nggplot(datos, aes(Valor,fill = Medida))+\n  geom_histogram(aes(y = ..density..), position = \"identity\", alpha = 0.3, bins = 50)+\n  labs(y = \"Densidad\",x = \"\",fill = \"Variables\")\n# Parámetros iniciales\nnsim <- 5000\nset.seed(12)\n# Generamos diámetros para tuercas y pernos\ntuercas <- rnorm(nsim, 2.03, 0.02)\npernos <- rnorm(nsim, 2.00, 0.01)\n# Calculamos la diferencia y creamos filtro de calidad\ndiferencia <- tuercas - pernos\nvalid<- 1*(diferencia >0 & diferencia <= 0.06)\n# Devolvemos los valores \nsimulacion <- data.frame(sim = 1:nsim, \n                         tuercas = tuercas, \n                         pernos = pernos, \n                         diferencia= diferencia, \n                         valid = valid)\n# Calidad del proceso\ng1 <- simulacion %>%\n  count(valid)%>%\n  mutate(prop = prop.table(n)) %>%\n  ggplot(aes(x = as.factor(valid), y = prop, label = scales::percent(prop))) + \n  geom_col(fill = \"steelblue\", position = \"dodge\") +\n  scale_x_discrete(labels = c(\"No\", \"Sí\")) +\n  scale_y_continuous(labels = scales::percent)+\n  geom_text(position = position_dodge(width = 0.9), vjust = 1.5,size = 3)+\n  labs(x = \"Resultado del proceso: validez\", y = \"Porcentaje\")\n# Diferencia\ng2 <- ggplot(simulacion, aes(diferencia)) + \n  geom_histogram(fill = \"steelblue\",color=\"grey\") +\n  geom_vline(xintercept = c(0, 0.06), col = \"red\") +\n  labs(x = \"Diferencia Tuerca-Perno\", y = \"Frecuencia\")\n# Diámetros\norden <- c(\"tuercas\", \"pernos\")\ndatos <- pivot_longer(simulacion, cols = 2:3, names_to = \"Medida\", values_to = \"Valor\")\n# gráfico\ng3 <- ggplot(datos, aes(Medida, Valor)) + \n  geom_boxplot(fill = \"steelblue\") +\n  scale_x_discrete(limits = orden, labels = orden) +\n  labs(x = \"\", y = \"Diámetro\")\n# Combinación\ngrid.arrange(g1, g2, g3, nrow = 2)## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n10000*(1 - mean(simulacion$valid == 1))## [1] 1794\n# Parámetros iniciales\nnsim <- 5000\nset.seed(12)\n# Generamos longitudes de las secciones\nLA <- rnorm(nsim, 20, sqrt(0.04))\nLB <- rnorm(nsim, 14, sqrt(0.01))\nLC <- rnorm(nsim, 26, sqrt(0.04))\n# Calculamos longitud total y verificamos requisitos\nL <- LA + LB + LC - 4\nvalid <- 1*(L >= 55.5 & L <= 56.5)\n# Devolvemos los valores \nsimulacion <- data.frame(sim = 1:nsim, LA = LA, LB = LB, \n                         LC = LC, L = L,valid=valid)\n#  Pr proceso cumpla criterios calidad\np = mean(simulacion$valid == 1)\nerror = sqrt((sum(simulacion$valid-p)^2)/(nsim^2))\nalpha = 0.05 # 1-alpha=nivel de confianza para el IC\nic.low = p - qnorm(1-alpha/2)*error\nic.up = p + qnorm(1-alpha/2)*error\ncat(\"Pr(barra utilizable)=\", p)## Pr(barra utilizable)= 0.9016\ncat(\"Error de la aproximación=\", error)## Error de la aproximación= 4.298784e-17\ncat(\"IC(\", 1-alpha,\"%)= [\", ic.low,\",\", ic.up,\"]\")## IC( 0.95 %)= [ 0.9016 , 0.9016 ]\ndesechos=25000*(1-p)\ncat(\"Barras desechadas en un mes:\", desechos)## Barras desechadas en un mes: 2460\nbenef=(25000-desechos)*300-desechos*100\ncat(\"Beneficio obtenido en un mes:\", benef, \"€\")## Beneficio obtenido en un mes: 6516000 €"},{"path":"intro.html","id":"modelos-secuenciales","chapter":"Unidad 1 Conceptos básicos","heading":"1.7.4 Modelos secuenciales","text":"En la última sección para variables de tipo continuo presentamos los primeros modelos de simulación para variables aleatorias que actúan de forma consecutiva lo largo del tiempo. Será pues, una introducción los modelos estocásticos que estudiaremos en el resto de unidades. En estas situaciones todas las variables involucradas en el sistema hacen referencia al tiempo de ocurrencia de los eventos de interés. Trabajemos con ejemplos, para entender los conceptos y problemas involucrados.Ejemplo 1.21  El equipo de mantenimiento de una empresa debe programar las visitas cierta instalación para establecer una calendario eficiente de revisiones. El sistema que debe analizar está compuesto por tres procesos (, B, y C) que funcionan de forma independiente, pero que están conectados en serie, de forma que todo el sistema se detiene si un proceso falla. El tiempo de vida o tiempo hasta un fallo o avería, medido en horas, para cada uno de los procesos se puede considerar aleatorio y responde distribuciones exponenciales con medias 1000, 333, y 167 respectivamente.El proceso de fabricación completo, que involucra los tres procesos , B y C, funciona 24 horas al día y completa un ciclo cada siete días, tras el cual realiza un parón para tareas de mantenimiento. En ese ciclo, los procesos , B y C operan consecutivamente durante un día: \\(\\) trabaja durante 15.6 horas, luego entra en funcionamiento el proceso \\(B\\) durante 5.52 horas, y finalmente el \\(C\\) durante 2.88 horas.En la actualidad el equipo de manteniento está interesado en reajustar el ciclo para realizar las labores de mantenimiento, si fuera necesario, y reducir el tiempo muerto en que el sistema está parado, pues en estos momentos se dedican 24 horas tras cada ciclo, para las tareas de mantenimiento.¿Cuál es la probabilidad de que el sistema falle antes de finalizar un ciclo de trabajo?¿Cuál de los procesos está generando más parones en el ciclo debidos una avería?¿Cuál es el tiempo medio de funcionamiento del sistema sin ningún fallo? Interesa además, un rango o intervalo de confianza para dicha estimación. ¿Cuál sería el tiempo óptimo del ciclo para abordar las tareas de mantenimiento?En primer lugar modelicemos el sistema en base la información proporcionada. Definamos las variables aleatorias \\(TA\\), \\(TB\\), y \\(TC\\) que representan, respectivamente, el tiempo de funcionamiento -o tiempo fallo- (en horas) de cada proceso , B y C. Sus distribuciones son: \\[TA \\sim Exp(1/1000); \\quad TB \\sim Exp(1/333); \\quad TC \\sim Exp(1/167).\\] También son importantes las siguientes cantidades: - El tiempo de funcionamiento requerido cada día para cada uno de los procesos \\(ta=15.6, tb=5.52, tc=2.88\\) y el número de días que conforma cada ciclo, \\(nciclo=7\\).El tiempo de vida potencial del sistema completo, esto es, el tiempo \\(T\\) que funciona el sistema de fabricación hasta un fallo, y que se calcula partir del mínimo número de días que funciona cada proceso, \\(min \\{TA/ta,TB/tb,TC/tb\\}\\).Propongamos pues, un algoritmo de simulación que reproduzca el proceso de fabricación para un número \\(nsim\\) de ciclos simulados, cuyas simulaciones permitan responder las preguntas planteadas.Algoritmo para el estudio de fallo del sistemaPaso 1. Fijar el número de simulaciones o ciclos simular (\\(nsim\\)).Repetir los pasos 2 4 tantas veces como simulaciones generar (nsim).Paso 2. Generar valores \\(TA_i\\), \\(TB_i\\), y \\(TC_i\\) de los tiempos fallo de cada proceso según su distribución.Paso 2. Generar valores \\(TA_i\\), \\(TB_i\\), y \\(TC_i\\) de los tiempos fallo de cada proceso según su distribución.Paso 3. Calcular el número de días que dura sin fallos cada proceso, con los ratios \\(rt_i=\\{TA_i/ta, TB_i/tb, TC_i/tc\\}\\). Identificar cuál falla primero (\\(min(rt_i)\\)).Paso 3. Calcular el número de días que dura sin fallos cada proceso, con los ratios \\(rt_i=\\{TA_i/ta, TB_i/tb, TC_i/tc\\}\\). Identificar cuál falla primero (\\(min(rt_i)\\)).Paso 4. Verificar si el primero en fallar lo hace antes de terminar el ciclo, \\(min(rt_i)<=7\\). Si es que sí, guardar cuál es el proceso responsable del fallo y calcular la duración del ciclo mediante \\(24*rt_i\\) horas. Si es que , indicarlo y especificar como duración del ciclo \\(24*7\\) horas.Paso 4. Verificar si el primero en fallar lo hace antes de terminar el ciclo, \\(min(rt_i)<=7\\). Si es que sí, guardar cuál es el proceso responsable del fallo y calcular la duración del ciclo mediante \\(24*rt_i\\) horas. Si es que , indicarlo y especificar como duración del ciclo \\(24*7\\) horas.Paso 5. Devolver los valores de las simulaciones de los tiempos fallo de cada proceso, de la duración del ciclo, el indicador de fallo y el proceso responsable en cada ciclo (simulación).Paso 5. Devolver los valores de las simulaciones de los tiempos fallo de cada proceso, de la duración del ciclo, el indicador de fallo y el proceso responsable en cada ciclo (simulación).Lanzamos el proceso para los valores del ejemplo, y visualizamos los resultados en la Tabla 1.5\nTabla 1.5: Simulaciones para el proceso de fabricación con tres subprocesos encadenados , B y C. Tipo de fallo, tiempos de funcionamiento del sistema (Tciclo en horas, Dciclo en días) y tiempo de funcionamiento potencial (Tpotencial en horas). Días de vida DA, DB, DC de los procesos.\n¿Cuál es la probabilidad de que el sistema falle antes de finalizar un ciclo de trabajo?¿Cuál de los procesos está generando más parones en el ciclo debidos una avería?En la Figura 1.15 representamos (la izquierda) el porcentaje que se detiene el proceso de fabricación antes de finalizar el ciclo, para cada uno de los tipos de fallo posible (debido un parón en , B o C), y difieren muy poco entre sí. El más frecuente, dentro de la similaridad es el fallo en el proceso C, con una probabilidad de 0.0986. la derecha de la gráfica vemos cómo los tres tipos de fallo están dando tiempos de fabricación muy similares en media y variabilidad.\nFigura 1.15: Gráfico del ciclo de vida y de la probabilidad del tiempo de fabricación sin fallos.\n¿Cuál es el tiempo medio de funcionamiento del sistema sin ningún fallo? Interesa además, un rango o intervalo de confianza para dicha estimación. ¿Cuál sería el tiempo óptimo del ciclo para abordar las tareas de mantenimiento?Respondemos esta pregunta utilizando el tiempo de ciclo impuesto como cota superior, sino el tiempo de funcionamiento que el sistema es capaz de aguantar sin fallos, recogido en la variable Tpotencial(en horas). Damos una estimación y construimos un intervalo de confianza al 95% para responder la pregunta.Resulta pues, que el sistema de fabricación tiene capacidad para funcionar sin fallos una media de 20.5 días, y el intervalo de confianza da un límite inferior de 19.98, lo que da justificaría, con unas garantías del 97.5%, reajustar el ciclo y darle un tamaño de 20 días, reduciendo así considerablemente los parones de un día completo de mantenimiento cada 7 en funcionamiento.Ejemplo 1.22  El gerente de una empresa que se dedica la extracción y venta de piedra natural está preocupado porque piensa que hay un problema con la máquina que se dedica cortar, en bloques más manejables, los bloques de piedra que vienen desde la cantera. La máquina trabaja durante 24 horas al día los 365 días del año, y las especificaciones de calidad establecen que la media y varianza del tiempo hasta que la máquina se detiene por un fallo, \\(TF\\), han de ser de 80 y 50 horas respectivamente.En el histórico de mantenimiento de la empresa se han detectado tres tipos de fallos que se han catalogado como leves, moderados y graves. Además, la información del equipo de mantenimiento indica que el tipo de fallo que se produce está muy relacionado con el tiempo de funcionamiento de la máquina, de forma que la probabilidad de que se produzca un fallo u otro varía de acuerdo la tabla siguiente:Los tiempos de reparación (medidos en minutos), \\(TR\\), tienen medias y varianzas dadas por:Además se sabe que si el fallo es leve, es necesario detener la producción por completo, ya que esta se puede reducir al 60% y seguir trabajando mientras se realiza la reparación. En los otros dos casos la máquina debe detenerse por completo.El gerente está interesado en conocer el funcionamiento de la máquina en los próximos seis meses asumiendo que las variables de tiempo de funcionamiento y tiempo de reparación son de tipo Weibull. En concreto desea saber qué porcentaje del tiempo la máquina estará trabajando pleno rendimiento, rendimiento reducido y parada.Antes de plantear un algoritmo de simulación, tratemos de entender y modelizar bien la secuenciación de variables involucradas, según las especificaciones dadas. Las variables descritas son:\\(TF\\): Tiempo de funcionamiento de la máquina hasta fallo.\\(averia\\): Tipo de avería cuando el sistema falla: leve, moderado, grave. Su distribución depende de \\(tf\\).\\(TR.xx\\): Tiempo de reparación para una avería “xx={leve, moderado, grave},” que depende del tipo de avería.El tiempo de funcionamiento pleno rendimiento vendrá dado por el tiempo acumulado en el que el sistema funciona sin ningún fallo, obtenido de todos los \\(TF\\) simulados. El funcionamiento rendimiento reducido se dará mientras se está reparando alguna avería de tipo leve. El tiempo de parada del sistema corresponde los periodos en los que se está reparando alguna avería de tipo moderada o grave. Puesto que el funcionamiento del sistema depende del tipo de avería, nos interesará guardar información sobre el tipo de avería que se está reparando, información que recopilaremos en la variable \\(averia\\). El tiempo dedicado reparaciones lo guardaremos en una variable global denominada \\(TREPARA\\), que nos permitirá calcular cuándo el sistema funciona pleno rendimiento.\\(TREPARA\\): Tiempo total dedicado reparaciones.En cada simulación nos interesará contabilizar el tiempo transcurrido, en una variable\\(ciclo\\): Tiempo de funcionamiento hasta fallo + tiempo de reparación.Interesa simular el funcionamiento del sistema en los próximos seis meses, de modo que dicho periodo expresado en minutos es de 2.592^{5}, y la simulación parará cuando \\(ttotal<259200\\) minutos, siendo\\(ttotal\\): tiempo total acumulado de funcionamiento y reparaciones.Puesto que nos piden modelizar con distribuciones Weibull y sólo nos han dado su media y su varianza, hemos de calcular los parámetros utilizar, para lo que acudimos la función que ya propusimos en la Ecuación (??).Así, tendremos las siguientes distribuciones para el tiempo de funcionamiento \\(tf\\) y los tiempos de reparación \\(tr\\): \\[\\begin{eqnarray*}\nTF &\\sim& Weib(1.64,5365.22) \\\\\nTR.leve &\\sim& Weib(2.10, 33.87)  \\\\\nTR.moderado &\\sim& Weib(2.10, 67.74)  \\\\\nTR.grave &\\sim& Weib(2.90, 134.58).  \n\\end{eqnarray*}\\]Veamos ahora el algoritmo de simulación para este problema.Algoritmo secuencial para el estudio de fallo de la máquinaPaso 1. Inicializar todos las variables temporales 0.Repetir los pasos 2 5 hasta que \\(tiempo > 6*30*24*60 = 259200\\) minutos.Paso 2. Generar \\(tf\\).Paso 2. Generar \\(tf\\).Paso 3. Generar el tipo de averia \\(averia\\) en función de \\(tf\\).Paso 3. Generar el tipo de averia \\(averia\\) en función de \\(tf\\).Paso 4. Generar el tiempo de reparación \\(trepara\\) en función del tipo de avería.Paso 4. Generar el tiempo de reparación \\(trepara\\) en función del tipo de avería.Paso 5. Actualizar el tiempo total acumulado \\(ttotal\\) con el tiempo de funcionamiento y reparación.Paso 5. Actualizar el tiempo total acumulado \\(ttotal\\) con el tiempo de funcionamiento y reparación.Paso 6. Devolver el conjunto de valores simulados.Paso 6. Devolver el conjunto de valores simulados.Mostramos en la Tabla 1.6 las simulaciones obtenidas y damos continuación una breve descripción.\nTabla 1.6: Simulaciones para el sistema de corte de piedra.\nRespondamos ya diversas preguntas de interés.¿Cuál es tiempo total de funcionamiento del sistema, incluidas reparaciones?¿Qué porcentaje del tiempo total el sistema ha estado pleno rendimiento, reducido y en parada?Se concluye que el 99.08% del tiempo durante los seis meses simulados, el sistema ha estado pleno rendimiento, operando sin averías.","code":"\n# Función para simular el proceso de fabricación con tres subprocesos ABC encadenados.\nsimula.proceso=function(nsim, nciclo, alpha, beta, delta, ta, tb, tc){\n# semilla=Semilla aleatoria y nsim=nº simulaciones o ciclos a simular\n#nciclo es el número de días del ciclo\n# alpha, beta y delta son los parámetros de las exponenciales TA,TB,TC\n# ta,tb y tc son los tiempos de funcionamiento diarios para los procesos A, B y C.\nTciclo=Dciclo = rep(0, nsim)   # tiempo de ciclo (en horas T y días D)\nTpotencial = rep(0, nsim)      # tiempo(en horas) que funcionaría sin fallos\nfallo = c()                   # qué proceso ha fallado en cada ciclo\nprocesos = c(\"A\", \"B\", \"C\")\n\n# simulamos las duraciones para todos los ciclos\nTA = rexp(nsim, alpha)  \nTB = rexp(nsim, beta)\nTC = rexp(nsim, delta)\nt = c(ta, tb, tc) # funcionamiento diario de cada proceso\n\nfor(j in 1:nsim){\n  T = c(TA[j], TB[j], TC[j])      # tiempos de vida para el ciclo j\n  nfallo = T/t                  # número días que funcionará cada proceso\n  falla = which.min(nfallo)     # qué proceso falla primero\n  if(nfallo[falla] <= nciclo){  # si falla antes de cerrar el ciclo\n   fallo[j] = procesos[falla]   #identificamos el proceso que falla\n   Dciclo[j] = T[falla]/t[falla]   # y lo pasamos a días\n   Tciclo[j] = Tpotencial[j]=24*Dciclo[j]   # duración del ciclo (en horas)\n  }\n  else{                       #si no falla ninguno antes de cerrar el ciclo\n    Tciclo[j] = 24*7            #cerramos el ciclo sin fallos\n    Dciclo[j] = 7\n    fallo[j] = \"No\"\n    Tpotencial[j] = T[falla]/t[falla]*24    # y guardamos la duración potencial \n  }\n} # fin del for (j)\nresultado = data.frame(ciclo = 1:nsim, fallo,\n                     Tciclo = round(Tciclo, 2),Dciclo = round(Dciclo, 2),\n                     Tpotencial = round(Tpotencial, 2),\n                     DA = round(TA/ta, 2), DB = round(TB/tb, 2), DC = round(TC/tc, 2))\n\nreturn(resultado)\n}\nnciclo = 7; alpha = 1/1000; beta = 1/333; delta = 1/167\nta = 15.6;tb = 5.52; tc = 2.88\nsemilla = 12\n\nset.seed(semilla)\nnsim=5000                  \nsimulacion=simula.proceso(nsim,nciclo,alpha,beta,delta,ta,tb,tc)\nkbl(head(simulacion),caption=\"Simulaciones para el proceso de fabricación con tres subprocesos encadenados A, B y C. Tipo de fallo, tiempos de funcionamiento del sistema (Tciclo en horas, Dciclo en días) y tiempo de funcionamiento potencial (Tpotencial en horas). Días de vida DA, DB, DC de los procesos.\") %>%\n kable_styling(bootstrap_options = \"striped\", full_width = F, position = \"left\")\nm = mean(simulacion$fallo != \"No\")\nerror = sqrt(sum(((simulacion$fallo != \"No\")*1-m)^2) / (nsim^2))\nic.low = m - qnorm(0.975)*error\nic.up = m + qnorm(0.975)*error\ncat(\"Pr(fallo antes del ciclo=\",m)## Pr(fallo antes del ciclo= 0.2876\ncat(\"IC(Probabilidad)=[\",round(ic.low, 4),\",\",round(ic.up, 4),\"]\")## IC(Probabilidad)=[ 0.2751 , 0.3001 ]\n#  Representación gráfica del ciclo de vida: tabla de probabilidades\ng1 = simulacion %>%\n  group_by(fallo) %>%\n  summarise(n = n(), prop = n/nrow(simulacion)) %>%\n  ggplot(aes(x = fallo, y = prop)) +\n    geom_col(aes(fill = fallo), position = \"dodge\") +\n    geom_text(aes(label = scales::percent(prop), \n                  y = prop, group = fallo),\n              position = position_dodge(width = 0.9),\n              vjust = 1.5)+\n  labs(x = \"Tipo de fallo\",y = \"Proporción\")+\n  theme(legend.position = \"none\")\n\n\n# Tiempo de vida en función del ciclo\ng2 <- ggplot(simulacion, aes(fallo, Tciclo)) + \n  geom_boxplot(fill = \"steelblue\") +\n  labs(x = \"Tipo de fallo\", y = \"Tiempo de funcionamiento (horas)\")\ngrid.arrange(g1, g2, nrow = 1)\nm = mean(simulacion$Tpotencial)\nerror = sqrt(sum((simulacion$Tpotencial-m)^2) / (nsim^2))\nic.low = m - qnorm(0.975)*error\nic.up = m + qnorm(0.975)*error\ncat(\"E(Tpotencial)=\",round(m/24, 2))## E(Tpotencial)= 20.54\ncat(\"IC(estimación)=[\",round(ic.low/24, 2),\",\",round(ic.up/24, 2),\"]\")## IC(estimación)=[ 19.98 , 21.11 ]\n# Parámetros tiempo funcionamiento (en minutos)\ntf.params <- estima.weibull(80*60, 50*60); tf.params## [1]    1.64 5365.22\n# Tiempo de reparación para avería leve\ntr.leve <- estima.weibull(30, 15); tr.leve## [1]  2.10 33.87\n# Tiempo de reparación para avería moderada\ntr.moderado <- estima.weibull(60, 30); tr.moderado## [1]  2.10 67.74\n# Tiempo de reparación para avería moderada\ntr.grave <- estima.weibull(120, 45); tr.grave## [1]   2.90 134.58\n# Fijamos semilla y límite de tiempo para la simulación\nsemilla <- 12\nset.seed(semilla)\nTsim <- 259200\n# Incicializamos variables\ntf <- c()\ntrepara <- c()\naveria <- c()\nttotal <- 0\nciclo <- c(0)\n# Creamos variables necesarias para la simulación del tipo de avería:\n# probabilidades de avería leve, moderada y grave\neti <- c(\"leve\", \"moderada\", \"grave\")\npr1 <- c(0.85, 0.10, 0.05)  # si tf<=1500\npr1acu <- cumsum(pr1)\npr2 <- c(0.75, 0.15, 0.10)  # si 1500<tf<=3000\npr2acu <- cumsum(pr2)\npr3 <- c(0.65, 0.20, 0.15)  # si tf>3000\npr3acu <- cumsum(pr3)\n\n#############################\n## Simulación del proceso\n#############################\ni <- 1\nwhile (ttotal<= Tsim)\n{\n  # Tiempo de funcionamiento\n  tf[i] <- rweibull(1, tf.params[1], tf.params[2])\n  # Tipo Averia\n  if(tf[i] <= 1500)\n      averia[i] <-eti[min(which(runif(1) <= pr1acu))]\n  else if(tf[i] > 1500 & tf[i] <= 3000)\n      averia[i] <-eti[min(which(runif(1) <= pr2acu))] \n  else if(tf[i] > 3000)\n       averia[i] <-eti[min(which(runif(1) <= pr3acu))]\n # tiempo de reparación\n  if(averia[i] == \"leve\")\n      trepara[i] <- rweibull(1, tr.leve[1], tr.leve[2])\n  else if(averia[i] == \"moderada\" )\n      trepara[i] <- rweibull(1, tr.moderado[1], tr.moderado[2])\n  else if(averia[i] == \"grave\")\n      trepara[i] <- rweibull(1, tr.grave[1], tr.grave[2]) \n  # actualizamos tiempo total\n  ciclo[i]=tf[i]+trepara[i]\n  ttotal=ttotal+ciclo[i]\n  i <- i + 1\n}\nsimulacion <- data.frame(tf, averia = as.factor(averia), \n                         trepara,tiempo = cumsum(ciclo))\nkbl(head(simulacion),caption = \"Simulaciones para el sistema de corte de piedra.\") %>%\n  kable_classic_2(full_width = F)\n# Descriptivo del sistema\nsummary(simulacion)##        tf               averia      trepara            tiempo      \n##  Min.   :  532.4   grave   : 5   Min.   :  5.171   Min.   :  9779  \n##  1st Qu.: 2460.9   leve    :41   1st Qu.: 21.329   1st Qu.: 84710  \n##  Median : 3878.1   moderada: 9   Median : 33.343   Median :146116  \n##  Mean   : 4687.1                 Mean   : 43.292   Mean   :142494  \n##  3rd Qu.: 6600.7                 3rd Qu.: 59.206   3rd Qu.:204825  \n##  Max.   :13942.6                 Max.   :159.389   Max.   :260174\n# Tiempo total de funcionamiento del sistema (con reparaciones)\nttotal <- last(simulacion$tiempo)\n# Tiempo a pleno rendimiento\ntpleno <- sum(simulacion$tf)\n# Tiempo a rendimiento reducido\ntparcial <-sum((simulacion$averia == \"leve\")*trepara*0.6)\n# Tiempo parado (reparaciones moderadas y graves)\ntdetenido <- sum((simulacion$averia != \"leve\")*trepara)\n# Juntamos los tiempos y calculamos porcentajes sobre el tiempo de funcionamiento total\nkbl(round(100*cbind(ttotal, tpleno, tparcial, tdetenido)/ttotal,2),\n    col.names=c(\"%Tiempo total\",\"%Pleno rendimiento\",\"%Rendimiento reducido\",\"%Parado\")) %>%\n  kable_classic_2(full_width = F)"},{"path":"intro.html","id":"ProEstoc","chapter":"Unidad 1 Conceptos básicos","heading":"1.8 Procesos estocásticos","text":"Una vez hemos recordado cuestiones básicas y distribuciones comunes de probabilidad, la vez que hemos aprendido algunos algoritmos como el de la Transformada Inversa (Sección 1.5 o el de Composición Sección 1.7.2), damos un paso más y presentamos el concepto de procesos estocásticos, que es el objeto de esta asignatura.Definición 1.23  Un proceso estocástico es una secuencia de variables aleatorias \\(\\{X(t), t \\T\\}\\) y que dependen del parámetro \\(t\\), que toma valores en el conjunto índice \\(T\\) o de instantes de tiempo.Se denomina espacio de estados del proceso, \\(S\\), al conjunto de todos los posibles valores de las variables aleatorias que componen el proceso.Si \\(T\\) es un conjunto de tiempos discretos, \\(t = 0, 1, 2, 3,...\\), definidos por ejemplo al finalizar cada día o cada hora, obtenemos un proceso estocástico de tiempo discreto (PETD), \\(\\{X(0), X(1), X(2),...\\}\\).En cambio, si observamos el sistema continuamente lo largo del tiempo \\(t>\\geq 0\\), obtenemos un proceso estocástico de tiempo continuo (PETC), \\(\\{X(t), t \\geq 0\\}\\).El espacio de estados de un proceso puede ser de tipo discreto o continuo, en función de los posibles valores que pueden tomar las variables aleatorias \\(X(t)\\) que lo componen.","code":""},{"path":"intro.html","id":"ejemplos-de-procesos-estocásticos","chapter":"Unidad 1 Conceptos básicos","heading":"1.8.1 Ejemplos de procesos estocásticos","text":"continuación veamos algunos ejemplos de procesos PETD y PETC. Te proponemos identificar en cada uno de ellos cuáles pueden ser las cuestiones de interés investigar.En primer lugar, presentamos algunos ejemplos de procesos estocásticos de tiempo discreto (PETD).Ejemplo 1.23  Sea \\(X_t\\) la temperatura (en grados centígrados) registrada en el aeropuerto de Alicante-Elche las 12:00 horas del día \\(t\\). El espacio de estados del proceso estocástico \\(S\\) viene dado por \\((-20, 50).\\) Esto implica que la temperatura nunca baja de veinte bajo cero ni supera los cincuenta grados; da lugar un espacio de estados continuo.Ejemplo 1.24  Consideramos como \\(X_t\\) la variable aleatoria que registra el número ganador de la en el sorteo diario. Puesto que los números tienen 5 dígitos, el espacio de estados es discreto y viene dado por el conjunto de enteros entre 00000 y 99999.Ejemplo 1.25  Sea \\(X_t\\) la variable aleatoria que registra el valor del IPC al final del mes \\(t\\) para España. En tería el IPC puede tomar cualquier valor ente \\((-\\infty, +\\infty)\\), por lo que el espacio de estados es continuo.Ejemplo 1.26  Sea \\(X_t\\) el número de reclamaciones que recibe una compañía de seguros una semana cualquiera \\(t\\). El espacio de estados es discreto y viene dado por \\(\\{0, 1, 2, 3, 4,...\\}\\).Ejemplo 1.27  Sea \\(X_t\\) el número de accidentes que ocurren en la carretera que une las poblaciones de Elche y Santa Pola en la semana \\(t\\). El espacio de estados es discreto y viene dado por \\(\\{0, 1, 2, 3, 4,...\\}\\).Ejemplo 1.28  Sea \\(X_t\\) el número de productos defectuosos que genera una cadena de producción en cada uno de los lotes fabricados lo largo de un día. El espacio de estados es discreto, \\(\\{0, 1, 2, 3, 4,...\\}\\) y también \\(t\\), que identifica el número de lote producido.Y continuación veamos otros ejemplos de procesos estocásticos de tiempo continuo (PETC).Ejemplo 1.29  Supongamos que una máquina puede estar en dos estados, encendido o apagado. Sea \\(X(t)\\) la variable aleatoria que refleja el estado de la máquina en el instante de tiempo \\(t\\). Entonces \\(\\{X(t), t \\geq 0\\}\\) es un proceso estocástico de tiempo continuo con el espacio de estados discreto, con valores posibles {encendido, apagado}.Ejemplo 1.30  Un ordenador personal (PC) puede ejecutar muchos procesos simultáneamente. Si \\(X(t)\\) es el número de procesos que se ejecutan en dicho PC en el momento \\(t\\). Entonces \\(X(t), t \\geq 0\\) es un proceso estocástico de tiempo continuo con espacio de estados discreto \\(0, 1, 2,...,K\\) ,donde \\(K\\) es el número máximo de trabajos que puede manejar el PC simultáneamente.Ejemplo 1.31  Sea \\(X(t)\\) es el número de clientes que entran una tienda de libros en una franja de tiempo de duración \\(t\\). Entonces \\(X(t), t \\geq 0\\) es un proceso estocástico de tiempo continuo con espacio de estados discreto \\(0, 1, 2,...\\).Ejemplo 1.32  Sea \\(X(t)\\) una variable que recopila información sobre si se produce o un fallo en el sistema de alimentación eléctrico de un circuito lo largo del tiempo. El espacio de estados es discreto, con valores \\(\\{0,1\\}\\).Ejemplo 1.33  Sea \\(X(t)\\) la temperatura en grados centígrados registrada en una localización dada en cualquier instante de tiempo \\(t\\). Entonces \\(X(t), t \\geq 0\\) es un proceso estocástico de tiempo continuo con espacio de estados continuo.","code":""},{"path":"intro.html","id":"función-de-distribución-del-proceso","chapter":"Unidad 1 Conceptos básicos","heading":"1.8.2 Función de distribución del proceso","text":"Los ejemplos anteriores muestran una variedad de problemas que pueden ser modelados y estudiados como procesos estocásticos, y para hacerlo será preciso analizar el comportamiento aleatorio del proceso, sea cual sea la naturaleza de los tiempos, discretos o continuos.Puesto un proceso estocástico es una colección de variables aleatorias, la forma de inferir sobre él es través de la función de distribución conjunta que se construye partir de las variables \\(X(t_1), X(t_2),...,X(t_n)\\):donde \\(x_1, x_2,..., x_n \\\\mathbb{R}^n.\\)Si el proceso estocástico tiene una estructura simple, entonces los cálculos son excesivamente complicados, pero suele ser la tónica de procesos útiles para representar sistemas reales. lo largo de los años los investigadores han modelizado y estudiado clases especiales de procesos estocásticos que pueden utilizarse para describir una gran variedad de sistemas reales, resolviendo y posibilitando así los cálculos probabilísticos necesarios, aunque su complejidad en ocasiones haya sido evitable. Las dos clases más importantes de procesos estocásticos ya modelizados son las cadenas de Markov de tiempo discreto (CMTD) y las cadenas de Markov de tiempo continuo (CMTC). Sin embargo, en los últimos años el desarrollo de la computación ha posibilitado el uso intensivo de la simulación para resolver de un modo sencillo cálculos probabilísticos complejos y así analizar fácilmente el comportamiento de los sistemas reales, sin necesidad de extraer analíticamente la distribución de probabilidad conjunta del proceso.En los temas siguientes iremos describiendo este tipo de procesos, mostrando los resultados teórico, pero centrándonos en cómo utilizar las herramientas de simulación disponibles para reproducir el comportamiento del sistemas reales sin necesidad de registrar datos ni de realizar complejos desarrollos probabilísticos.Por analogía con el análisis de variables aleatorias serán relevantes en el estudio de procesos estocásticos, su valor esperado, \\(E[X(t)]\\), su varianza, \\(V[X(t)] = E[X(t)^2] - E[X(t)]^2\\) y la covarianza \\(Cov[X(t), X(s)] = E[X(t)X(s)] - E[X(t)]E[X(s)]\\), que vendrán dadas en función de tiempos \\(t\\) y \\(s\\).","code":""},{"path":"intro.html","id":"ejer-u1","chapter":"Unidad 1 Conceptos básicos","heading":"1.9 Ejercicios","text":"","code":""},{"path":"intro.html","id":"básicos","chapter":"Unidad 1 Conceptos básicos","heading":"1.9.1 Básicos","text":"Ejercicio B1.1. Un proceso de fabricación tiene una tasa de defectos del 20% y los artículos se colocan en cajas de cinco. Un inspector toma muestras de dos artículos de cada caja. Si uno o los dos artículos seleccionados son defectuosos, la caja se rechaza. Si un cliente pide 10 cajas, ¿cuál es el número esperado de artículos defectuosos que recibirá el cliente? Da una aproximación del error y una banda de confianza.Ejercicio B1.2. Un vendedor domicilio vende ollas y sartenes. Sólo entra en el 50% de las casas que visita. De las casas en las que entra, 1/6 de los propietarios están interesados en comprar nada, 1/2 de ellos acaban haciendo un pedido de 60 dólares, y 1/3 de ellos acaban haciendo un pedido de 100 dólares. Estima el promedio de ventas (en dólares) conseguidas para 25 visitas (junto con una medida del error). Estima el promedio de ventas por visita.Ejercicio B1.3. Un contratista de techos independiente ha determinado que el número de trabajos que se solicitan para el mes de septiembre es bastante variable. partir de la experiencia anterior, las probabilidades de obtener 0, 1, 2 o 3 trabajos se han determinado como 0.1, 0.35, 0.30 y 0.25, respectivamente. El beneficio obtenido por cada trabajo es de 300 dólares. ¿Cuál es el beneficio esperado para el mes de septiembre?Ejercicio B1.4. Un sistema de visión está diseñado para medir el ángulo en el que el brazo de un robot se desvía de la vertical. Sin embargo, el sistema de visión es totalmente preciso, y el resultado de las observaciones es una variable aleatoria con una distribución uniforme. Si la medición indica que el rango del ángulo está entre 9.7 y 10.5 grados, aproxima por simulación la probabilidad de que el ángulo real esté entre 9.9 y 10.1 grados y da una medida del error de dicha aproximación.Ejercicio B1.5. En una operación de soldadura automatizada, la posición en la que se coloca la soldadura es muy importante. La desviación del centro de la placa es una variable aleatoria normal con una media de 0 pulgadas y una desviación estándar de 0.01 pulgadas. Una desviación positiva indica una desviación la derecha del centro y una desviación negativa indica una desviación la izquierda del centro.¿Cuál es la probabilidad de que en una placa dada, la ubicación real de la soldadura se desvíe menos de 0.005 pulgadas (en valor absoluto) del centro?¿Cuál es la probabilidad de que en una placa dada, la ubicación real de la soldadura se desvíe más de 0.02 pulgadas (en valor absoluto) del centro?Da aproximaciones del error cometido al aproximar por simulación.Ejercicio B1.6. Un departamento de compras percibe que el 75% de sus pedidos especiales se reciben tiempo. De los pedidos que se reciben tiempo, el 80% cumple totalmente las especificaciones; de los pedidos que llegan con retraso, el 60% cumple con las especificaciones. Responde las siguientes preguntas utilizando simulación, dando también una medida del error.¿Cuál es la probabilidad de que un pedido llegue tiempo y cumpla con las especificaciones?¿Cuál es la probabilidad de que un pedido cumpla con las especificaciones?Si se han recibido cuatro pedidos, ¿cuál es la probabilidad de que los cuatro pedidos cumplan con las especificaciones?Ejercicio B1.7. Una empresa manufacturera tiene tres operarios para una máquina que produce cierto tipo de componentes. El operario tiene una tasa de defectos del 5%, el operario B del 3%, y el operario C del 2%. Los tres operarios producen el mismo número de componentes. Si un componente elegido al azar resulta defectuoso, ¿cuál es la probabilidad de que el componente haya sido producido por , B, o C? Responde la pregunta con simulación y da una medida del error de la aproximación.Ejercicio B1.8. El 1% de los préstamos que hace cierta empresa financiera son saldados (es decir, la cantidad prestada le es devuelta en su totalidad). La compañía efectúa un estudio rutinario de las posibilidades crediticias de los solicitantes. Encuentra que el 30% de los préstamos saldados se hicieron clientes de alto riesgo, el 40% clientes de riesgo moderado y el restante 30% clientes de bajo riesgo. De los préstamos que fueron saldados, el 10% se hicieron clientes de alto riesgo, el 40% clientes de riesgo moderado y el 50% clientes de bajo riesgo. Responde las siguientes preguntas utilizando simulación, dando también una medida del error.¿Cuál es la probabilidad de que un préstamo de alto riesgo sea saldado?¿Cuál es la probabilidad de que una deuda saldada, dado que el riesgo es moderado?Ejercicio B1.9. Se hacen dos inversiones de 10000€ cada una en dos proyectos. Se supone que el proyecto va producir un rendimiento neto de 800, 1000 y 1200 euros con probabilidades respectivas de 0.2, 0.6, 0.2. Se supone que el proyecto B va producir una ganancia neta de 800, 1000, y 1200 euros, con probabilidades respectivas 0.3, 0.4, 0.3. Si asumimos que lo que se gana con un proyecto es independiente de lo que se gana con el otro, responde las siguientes preguntas utilizando simulación, dando también una medida del error.¿Cuál es la probabilidad de que la ganancia total sea de 2000 euros exactamente?¿Cuál es la probabilidad de que la ganancia total sea igual o superior 2000 euros?¿Cuál es la probabilidad de que la ganancia sea inferior 2000 euros?Ejercicio B1.10. Sea \\(X\\) una variable aleatoria de tipo continuo cuya función de densidad viene dada por: \\[\\begin{equation*}\nf(x) = \\frac{5}{3}(1-x^3)x  \\text{ para } 0 \\leq x \\leq 1\n\\end{equation*}\\]Utilizando simulación:Determina la \\(Pr(X \\leq 0.5).\\)Determina la \\(Pr(0.25 \\leq X \\leq 0.75).\\)Determina la \\(Pr(X > 1/3).\\)Ejercicio B1.11. Sea \\(X\\) una variable aleatoria de tipo continuo cuya función de densidad viene dada por:Utilizando simulación:Determina el valor de \\(t\\) tal que \\(Pr(X \\leq t) = 0.25\\)Determina el valor de \\(t\\) tal que \\(Pr(X \\leq t) = 0.5\\)Ejercicio B1.12. Sea \\(X\\) una variable aleatoria de tipo continuo cuya función de densidad viene dada por:Utilizando simulación:Determina el valor esperado y la desviación típica de la variable \\(Y = X^{1/2}.\\)Determina \\(Pr(Y \\geq 1).\\)Ejercicio B1.13. Los administradores de cierta industria han probado, por pruebas técnicas, que su producto tiene una vida media de 5 años, y la han descrito con una distribución exponencial. Si el tiempo de garantía asignado por los administradores es de 1 año, ¿qué porcentaje de sus productos será devuelto para reparar durante el periodo de garantía? Aproxima por simulación y da una medida del error.","code":""},{"path":"intro.html","id":"avanzados","chapter":"Unidad 1 Conceptos básicos","heading":"1.9.2 Avanzados","text":"Ejercicio A1.1.Los problemas de inventario tratan de dar respuesta las necesidades de almacenamiento de las empresas para satisfacer la demanda de los consumidores. En concreto, en este caso se plantea el problema de un distribuidor del mercado central especializado en la venta de fresas. Dicho comerciante compra cajas al precio de 20€, y las vende por 50€, y tiene dos problemas relacionados directamente con lo que denominamos “inventario”:Si los clientes solicitan más cajas de las disponibles el comerciante pierde 30€ por cada caja de menos disponible.Si el comerciante almacena más cajas de las solicitadas por los clientes, el producto se debe tirar y pierde 20€ por cada caja que vende.Para tratar de determinar el número de cajas que debe comprar y almacenar, recoge información sobre la demanda realizada por los clientes en la campaña anterior, cuyos datos vienen dados en la tabla siguiente:La empresa proporciona en la tabla siguiente las ganancias esperadas diarias (en euros) asociadas al número de cajas vendidas y las cajas que debería almacenar:En base esta información se debe obtener la ganancia esperada para cada acción de inventario, y determinar aquella que proporcione mayores beneficios, es decir, las mayores ganancias diarias. ¿Qué recomendación se debería hacer al distribuidor?Por otro lado, los asesores convencen al distribuidor de que para tener mayor certeza de sus ganancias debería realizar un estudio marginal, que se basa en el hecho de que cuando se compra una unidad adicional de un artículo (en este caso una caja) pueden ocurrir dos cosas: la unidad se vende o se vende. De esta forma:¿Cuál es la probabilidad de que la demanda sea al menos de 11 cajas? ¿Y de al menos 12? ¿Y de al menos 13?¿Cuál resulta la ganancia y pérdida marginal esperada por la venta o de una caja más con cada una de las probabilidades anteriores?¿Qué opción recomiendas al distribuidor?","code":""},{"path":"cmtd.html","id":"cmtd","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"Unidad 2 Cadenas de Markov de Tiempo Discreto","text":"En esta unidad trabajamos con un tipo especial de proceso estocástico de tiempo discreto: las Cadenas de Markov de Tiempo Discreto, las que aludiremos en adelante como CMTD. Analizamos teóricamente este tipo de procesos y presentamos las herramientas de cálculo y simulación necesarias para poder resolver problemas asociados sistemas reales modelizables con una CMTD. Utilizaremos en R la librería markovchain.29","code":""},{"path":"cmtd.html","id":"definiciones","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.1 Definiciones","text":"Definición 2.1  Un proceso estocástico \\(\\{X(t), t \\\\mathbb{N}\\}\\) con espacio de estados de tipo discreto, \\(S\\), se denomina Cadena de Markov de Tiempo Discreto, si para cualquier par de estados \\(\\) y \\(j\\) de \\(S\\) tenemos que:es decir, la probabilidad de que el proceso en un instante \\(t+1\\) se encuentre en un estado \\(j\\), dada toda la evolución del proceso lo largo del tiempo, sólo depende del estado en el que el sistema se encuentrara justamente en el instante anterior \\(t\\), esto es, \\(X(t)=\\), y y del estado del proceso en los instantes anteriores \\(t-1, t-2,...,0\\).En ocasiones utilizaremos la siguiente notación,\n\\[X(n)=X_n, \\qquad n \\geq 0\\]La probabilidad condicionada dada en (2.1) se denomina probabilidad de transición de un paso y se denota por \\(p_{ij}(t,t+1)\\), y es la probabilidad de que, dado que el proceso en el instante \\(t\\) está en el estado \\(\\), un instante más tarde, \\(t+1\\) haya cambiado al estado \\(j\\): \\[p_{ij}(t,t+1)=Pr(X(t+1) = j | X(t) = ).\\]De forma similar podemos definir la probabilidad de transición de \\(n\\) pasos, \\(p_{ij}(t,t+n)\\) como la probabilidad de que, dado que el proceso en el instante \\(t\\) está en el estado \\(\\), \\(n\\) instantes más tarde, \\(t+n\\), esté en el estado \\(j\\) :Las probabilidades de transición así definidas cumplen que:Definición 2.2  Una \\(CMTD\\) dada por \\(\\{X(t), t \\\\mathbb{N}\\}\\) es homogénea cuando tiene probabilidades de transición estacionarias, es decir, cuando \\(p_{ij}(t, t+n)\\) depende de \\(t\\), es decir, la probabilidad de cambiar del estado \\(\\) al estado \\(j\\) en \\(n\\) pasos es independiente del instante temporal en que se encuentre el proceso:En este curso sólo estudiaremos \\(CMTD\\) homogéneas, por lo que para simplificar la notación, partir de ahora las denotaremos como \\(p_{ij}(n)\\) las probabilidades de transición de \\(n\\) pasos y \\(p_{ij}\\) las probabilidades de transición de un paso: \\[\\begin{eqnarray*}\np_{ij} &=& Pr[X(t+1) = j | X(t) = ] \\\\\np_{ij}(n) &=& Pr[X(t+n) = j | X(t) = ].\n\\end{eqnarray*}\\]Definición 2.3  El comportamiento aleatorio de una \\(CMTD\\) está completamente determinado por las probabilidades de transición de la cadena y la distribución del estado inicial, de forma que la función de distribución del proceso en un instante de tiempo \\(t\\) se calcula, mediante el teorema de la probabilidad total, según la Ecuación (2.3).con \\(p_i(0) = Pr(X(0) = )\\) la probabilidad de que en el instante inicial el proceso se encuentre en el estado \\(\\). De hecho, el vector\n\\[p(0) = \\{p_i(0)= Pr[X(0) = ], \\ \\S\\}\\]\nse denomina distribución inicial de la cadena e identifica la distribución de probabilidad del proceso en el instante inicial o punto de partida del proceso.De forma habitual se suelen expresar las probabilidades de transición de un paso para \\(N\\) estados en una \\(CMTD\\) mediante la denominada matriz de transición de un paso \\(P\\), que es una matriz estocástica con todos sus elementos constituidos por probabilidades, dada por:\\[P = \n\\begin{pmatrix}\np_{11} & p_{12} & ... & p_{1N}\\\\\np_{21} & p_{22} & ... & p_{2N}\\\\\n... & ... & ... & ...\\\\\np_{N1} & p_{N2} & ... & p_{NN}\n\\end{pmatrix}\\]La información sobre las probabilidades de transición también puede representarse de forma gráfica construyendo un diagrama de transición del \\(CMTD\\). Un diagrama de transición es un grafo dirigido con \\(N\\) nodos, un nodo por cada estado del \\(CMTD\\). Hay un arco dirigido que va del nodo \\(\\) al nodo \\(j\\) en el grafo si la transición del estado \\(\\) al estado \\(j\\) es viable, esto es, \\(p_{ij} \\neq 0\\). Los diagramas de transición se pueden utilizar como herramienta para visualizar la dinámica de la \\(CMTD\\).De forma similar podemos definir la matriz de transición de n pasos con la matriz estocástica \\(P(n)\\):\\[P(n) = \n\\begin{pmatrix}\np_{11}(n) & p_{12}(n) & ... & p_{1N}(n)\\\\\np_{21}(n) & p_{22}(n) & ... & p_{2N}(n)\\\\\n... & ... & ... & ...\\\\\np_{N1}(n) & p_{N2}(n) & ... & p_{NN}(n)\n\\end{pmatrix}\\]con \\[\\begin{eqnarray*}\n0 \\leq p_{ij}(n) &\\leq& 1 \\\\\n\\sum_{j \\S} p_{ij}(n) &=& 1.\n\\end{eqnarray*}\\]De forma genérica denotamos por \\(p(n)\\) la distribución del proceso en la n-ésima transición:\\[p(n) = \\{p_i(n)=Pr[X(n)=], \\ \\S\\}\\]Cualquier \\(CMTD\\) homogénea verifica la denominada Ecuación de Chapman-Kolmogorov que permite calcular la probabilidad de transición de un estado \\(\\) un estado \\(j\\) en \\(n\\) pasos través de todas las probabilidades de transición de \\(s\\) y \\(n-s\\) pasos, para cualquier \\(s<n\\) y cualquier \\(\\) y \\(j\\) en \\(S\\):Definición 2.4  Haciendo uso de la ecuación (2.4) se puede demostrar que la matriz de transición de \\(n\\) pasos \\(P(n)\\) se puede obtener como la potencia \\(n\\) de la matriz de transición de un paso \\(P\\), esto es,\\[\\begin{equation}\nP(n) = P^n,\n\\tag{2.5}\n\\end{equation}\\]de modo que conociendo la distribución inicial del proceso \\(p(0)\\) y la matriz de transición de un paso \\(P\\), tenemos perfectamente identificada la distribución del proceso en cualquier momento:\\[\\begin{equation}\np(n) = p(0)P^n.\n\\tag{2.6}\n\\end{equation}\\]","code":""},{"path":"cmtd.html","id":"libMC","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.2 Librería markovchain","text":"Para trabajar con procesos \\(CMTD\\) con R es útil la librería markovchain.30 Trabajamos continuación sobre un problema sencillo, para crear la matriz y el diagrama de transición de la cadena de Markov.Ejemplo 2.1  Tenemos una \\(CMTD\\) \\(\\{X(t), t \\\\mathbb{N}\\}\\) con espacio de estados \\(S = \\{, b, c\\}\\) y distribución inicial de la cadena dada por \\(p_a(0)=0.4, p_b(0)=0.2\\) y \\(p_c(0)=0.4\\). La matriz de transición de un paso viene dada por:\\[P = \n\\begin{pmatrix}\n0.20 & 0.30 & 0.50\\\\\n0.10 & 0.00 & 0.90\\\\\n0.55 & 0.00 & 0.45\n\\end{pmatrix}\\]Planteamos resolver las cuestiones siguientes:(1). Queremos representar el proceso través de un grafo.Para representar el proceso con markovchain, hemos de crear un vector con los estados y la matriz de transición con las probabilidades de transición. Definimos entonces el proceso con la función genérica new() para generar un objeto del tipo markovchain:\n\\[new(\"markovchain\",states,byrow=TRUE,transitionMatrix)\\]introduciendo el vector de estados en states, la matriz de transición en transitionMatrix, y especificando si dicha matriz se ha de leer por filas.continuación lo pintamos con la función plot().Procedemos con el ejemplo que nos atañe. El grafo en la Figura 2.1 muestra los tres estados como nodos y las probabilidades de transición para pasar de un estado otro en un único paso.\nFigura 2.1: Grafo del proceso.\n(2). Si la \\(CMTD\\) está en el estado \\(c\\) en el momento 17, ¿cuál es la probabilidad de que esté en el estado \\(\\) en el momento 18?RESPUESTA: Nos preguntan por la probabilidad de transición para pasar, en un solo paso, del estado \\(c\\) (3) al estado \\(\\) (1), por lo que viene dada por la componente \\(p_{31}\\) de la matriz de transición, es decir, 0.55.Para resolver el cálculo con el ordenador basta utilizar la función transitionProbability(), con los argumentos: object (la cadena de markov), t0 (el estado en el instante inicial), t1 (el estado en el instante final).Así la pregunta (2) se responde con:(3). Si la \\(CMTD\\) está en el estado \\(c\\) en un momento dado, ¿cuál es la probabilidad de que esté en el estado \\(\\) transcurridos tres unidades de tiempo? ¿y después de 10?RESPUESTA: Para resolver esta cuestión definimos el estado inicial y lo multiplicamos por la matriz de transición que corresponda, que en este caso, aplicando la Ecuación (2.5), será \\(P^n\\), para \\(n=3\\) y \\(n=10\\). Obtendremos así la distribución de probabilidad en \\(n\\) transiciones, con la probabilidad de llegar cada uno de los eventos posibles, \\(\\{,b,c\\}\\) en \\(n\\), partiendo de un estado inicial dado.(4). ¿Cuál es la distribución de probabilidad del proceso transcurridos \\(10\\) instantes de tiempo desde el momento inicial del proceso, sea cual sea su estado?RESPUESTA: Si conocemos la distribución de probabilidad en el estado inicial, \\(p(0)\\), podemos obtener la distribución de probabilidad en \\(n\\) transiciones con la Ecuación :En base la distribución del proceso tras \\(n=10\\) pasos, apreciamos que lo más probable es que el sistema se ecuentre en el estado “c” (prob=0.52), y lo menos probable es que se encuentre en el estado “b” (prob=0.11).(5). Corroborar los resultados analíticos obtenidos en (4) con simulaciones.RESPUESTA: Para ver el comportamiento de un proceso después de que transcurran \\(n\\) pasos habrá que simularlo durante \\(n\\) instantes de tiempo. Puesto que buscamos una estimación de lo que va ocurrir en ese momento, simularemos \\(nsim=100\\) veces el proceso hasta el instante \\(n=10\\), nos quedaremos con el estado en que se encuentra el proceso en ese instante \\(n\\) y evaluaremos las probabilidades obtenidas para los tres estados \\(\\{,b,c\\}\\). Los resultados serán más próximos la solución analítica, cuanto mayor sea el número de simulaciones (prueba modificar \\(nsim\\)).Para simular una CMTD hasta una transición \\(n\\) con la librería markovchain\nbasta utilizar la función rmarkovchain(n, proceso), donde proceso ha sido definido previamente con la función new().","code":"\nrequire(markovchain)\n# Definimos estados\nestados <- c(\"a\", \"b\", \"c\")\n# Creamos la matriz de transición \npmat <- matrix(data = c(0.20, 0.30, 0.50, 0.10, 0.00, 0.90,0.55, 0.00, 0.45), \n               byrow = TRUE, nrow = 3, \n               dimnames = list(estados, estados))\n# Creamos la CMTD\nproceso <- new(\"markovchain\", states = estados, \n               byrow = TRUE, transitionMatrix = pmat)\n# Verificamos los datos introducidos\nproceso## Unnamed Markov chain \n##  A  3 - dimensional discrete Markov Chain defined by the following states: \n##  a, b, c \n##  The transition matrix  (by rows)  is defined as follows: \n##      a   b    c\n## a 0.20 0.3 0.50\n## b 0.10 0.0 0.90\n## c 0.55 0.0 0.45\n# y obtenemos el diagrama del proceso\nplot(proceso)\ntransitionProbability(object = proceso, t0 = \"c\", t1 = \"a\")## [1] 0.55\n# Estado inicial en c\nsini <- c(0, 0, 1)\n# matriz de transición de 3 pasos\nmt3 <- proceso^3\n# Situación del proceso dentro de 3 instantes\nsini*mt3##             a       b        c\n## [1,] 0.350625 0.10725 0.542125\n# matriz de transición de 10 pasos\nmt10 <- proceso^10\n# Situación del proceso dentro de 10 instantes\nsini*mt10##              a         b         c\n## [1,] 0.3703899 0.1110948 0.5185153\n### Distribución de probabilidad del proceso dentro de 10 instantes\n# Distribución de  probabilidad inicial\ndini <- c(0.4, 0.2, 0.4)\n# matriz de transición de 10 pasos\nmt10 <- proceso^10\n# distribución de probabilidad en 10 pasos\ndini*mt10##             a         b         c\n## [1,] 0.370364 0.1111134 0.5185226\n### Simulación del proceso para n=10 instantes \nres=vector()\nnsim=100\nn=10\nfor(i in 1:nsim){\n  res[i]=rmarkovchain(n, proceso)[n]}\nprop.table(table(res))## res\n##    a    b    c \n## 0.31 0.12 0.57"},{"path":"cmtd.html","id":"ExCMTD","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3 Aplicaciones","text":"Las aplicaciones de las CMTD son muy numerosas. continuación presentamos una colección de ejemplos basados en aplicaciones prácticas de estos procesos, con algunos de los cuales trabajaremos lo largo de la unidad.","code":""},{"path":"cmtd.html","id":"CM01","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3.1 Colas de espera","text":"Supongamos una consulta médica en un centro de salud, en el que los pacientes que llegan se colocan en una única cola de espera, son atendidos consecutivamente y sólo se atiende un paciente en cada periodo de 5 minutos. Consideramos las variables aleatorias:\\(Y_n:\\) Número de clientes que acuden la consulta durante el n-ésimo periodo de servicio, con posibles valores \\(\\{0, 1, 2,...\\}\\) donde\\[Pr(Y_n = k) = a_k, \\quad k=0, 1, 2,...; \\quad 0 \\leq a_k \\leq 1; \\quad \\sum_{k=0}^{\\infty} a_k =1\\]\\(X_n:\\) Número de pacientes que hay esperando en la cola en el momento que empieza el n-ésimo periodo de servicio, con posibles valores \\(\\{0, 1, 2,...\\}\\), que conforman un proceso estocástico discreto con:de forma que cada \\(X_n\\) sólo dependerá de lo que haya ocurrido en el periodo inmediatamente anterior, luego \\(\\{X_n, n \\\\mathbb{N}\\}\\) es una \\(CMTD\\), con probabilidades de transición dadas por:La matriz de transición viene dada por:\\[P = \n\\begin{pmatrix}\na_0 & a_1 & a_2 & a_3 &...& a_j & ...\\\\\na_0 & a_1 & a_2 & a_3 &...& a_j & ...\\\\\n0 & a_0 & a_1 & a_2 &...& a_{j-1} & ...\\\\\n0 & 0 & a_0 & a_1 &...& a_{j-2} & ...\\\\\n... & ... & ... & ... &...& ... & ...\n\\end{pmatrix}\\]","code":""},{"path":"cmtd.html","id":"fiabilidad","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3.2 Fiabilidad de máquinas","text":"La empresa Depend--Us fabrica una máquina que está encendida o apagada (“”/“”). Si está “” al principio de un día, entonces está “” al principio del día siguiente con una probabilidad de 0.98 (independientemente del historial de la máquina), o falla con una probabilidad de 0.02. Una vez que la máquina falla, la empresa envía una persona para que la repare. Si la máquina está averiada al principio de un día, está “” al principio del día siguiente con una probabilidad de 0.03 (independientemente del historial de la máquina), o la reparación se completa y la máquina está “” con probabilidad de 0.97. Una máquina reparada está como nueva.Podemos modelar este sistema mediante una \\(CMTD\\) si consideramos la variable aleatoria \\(X_n\\) que refleja el estado de la máquina en el día \\(n\\) definida como:de forma que la matriz de transicción viene dada por: \\[P = \n\\begin{pmatrix}\n0.03 & 0.97\\\\\n0.02 & 0.98\n\\end{pmatrix}\\]Supongamos ahora que la empresa mantiene dos máquinas de este tipo que son idénticas, se comportan de forma independiente y cada una tiene su propio reparador.Sea \\(Y_n\\) el número de máquinas en estado “” al principio del día \\(n\\), que constituye una CMTD cuyo espacio de estados es \\(\\{0, 1, 2\\}\\), puesto que la situación de las máquinas un día cualquiera sólo depende de cómo estaban el día anterior (cumplen la Ecuación (2.1).Calculemos la probabilidad de transición para un caso concreto: \\(Y_n = = 1\\) e \\(Y_{n+1} = j = 0\\), que identifica una situación en la que una máquina está en funcionamiento y otra en paro el día \\(n\\), pero al día siguiente ambas están paradas. Así, la máquina que está “” el día \\(n\\) debe permanecer “” al día siguiente, y la máquina que está “” debe cambiar “” el día siguiente. Como las máquinas son independientes, la probabilidad de cambio de estado es:\\[p_{10}=Pr[Y_{n+1} = 0 | Y_n = 1] = 0.03 * 0.02 = 0.0006\\] Procediendo de la misma forma obtenemos la matriz completa de transición de un paso del proceso como:\\[P = \n\\begin{pmatrix}\n0.0009 & 0.0582 & 0.9409\\\\\n0.0006 & 0.0488 & 0.9506\\\\\n0.0004 & 0.0392 & 0.9604\n\\end{pmatrix}\\]Representamos continuación este sistema en forma de grafo en la Figura 2.2. Para ello acudimos la librería markovchain.\nFigura 2.2: Diagrama del sistema de fiabilidad\n","code":"\n# Definimos estados\nestados <- c(\"0\", \"1\", \"2\")\n# Matriz de transición \npmat <- matrix(data = c(0.0009, 0.0582, 0.9409, \n                        0.0006, 0.0488, 0.9506, \n                        0.0004, 0.0392, 0.9604), \n               byrow = TRUE, nrow = 3, \n               dimnames = list(estados, estados))\n# CMTD\nfiabilidad <- new(\"markovchain\", states = estados, \n                 byrow = TRUE, transitionMatrix = pmat, \n                 name = \"Fiabilidad\")\n# Verificamos los datos introducidos\nfiabilidad## Fiabilidad \n##  A  3 - dimensional discrete Markov Chain defined by the following states: \n##  0, 1, 2 \n##  The transition matrix  (by rows)  is defined as follows: \n##       0      1      2\n## 0 9e-04 0.0582 0.9409\n## 1 6e-04 0.0488 0.9506\n## 2 4e-04 0.0392 0.9604\n# Diagrama\nplot(fiabilidad, vertex.color=\"steelblue\", \n     vertex.label.font = 2, \n     edge.label.size = 0.1,\n     edge.arrow.size=0.5, \n     vertex.shape = \"rectangle\", \n     vertex.size = 20)"},{"path":"cmtd.html","id":"meteo","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3.3 Meteorología","text":"El tiempo en la ciudad de Heavenly se clasifica como soleado, nublado o lluvioso. Supongamos que el tiempo de mañana depende sólo del tiempo de hoy de la siguiente manera: si hoy hace sol, mañana estará nublado con una probabilidad de 0.3 y lluvioso con probabilidad 0.2; si hoy está nublado, mañana estará soleado con probabilidad 0.5 y lluvioso con probabilidad 0.3; y finalmente, si hoy está lluvioso, mañana estará soleado con probabilidad 0.4 y nublado con probabilidad 0.5.Consideramos la variable aleatoria \\(X_n\\) que registra las condiciones meteorológicas del día \\(n\\) como:de forma que el proceso \\(\\{X_n, n \\\\mathbb{N}\\}\\) con espacio de estados \\(S = \\{1, 2, 3\\}\\) se puede considerar como una \\(CMTD\\), cuya matriz de transición se puede obtener de forma muy rápida como:\\[P = \n\\begin{pmatrix}\n0.50 & 0.30 & 0.20\\\\\n0.50 & 0.20 & 0.30\\\\\n0.40 & 0.50 & 0.10\n\\end{pmatrix}\\]Representamos continuación este sistema en forma de grafo en la Figura 2.3.\nFigura 2.3: Diagrama del sistema de metereología\n","code":"\n# Definimos estados\nestados <- c(\"Soleado\", \"Nublado\", \"LLuvioso\")\n# Matriz de transición \npmat <- matrix(data = c(0.50, 0.30, 0.20, \n                        0.50, 0.20, 0.30, \n                        0.40, 0.50, 0.10), \n               byrow = TRUE, nrow = 3, \n               dimnames = list(estados, estados))\n# CMTD\nmeteo <- new(\"markovchain\", states = estados, \n                 byrow = TRUE, transitionMatrix = pmat, \n             name = \"Meteorología\")\n# Verificamos los datos introducidos\nmeteo## Meteorología \n##  A  3 - dimensional discrete Markov Chain defined by the following states: \n##  Soleado, Nublado, LLuvioso \n##  The transition matrix  (by rows)  is defined as follows: \n##          Soleado Nublado LLuvioso\n## Soleado      0.5     0.3      0.2\n## Nublado      0.5     0.2      0.3\n## LLuvioso     0.4     0.5      0.1\n# Diagrama\nplot(meteo, vertex.color=\"steelblue\", \n     vertex.label.font = 2, \n     edge.label.size = 0.1,\n     edge.arrow.size=0.5, \n     vertex.shape = \"rectangle\", \n     vertex.size = 60)"},{"path":"cmtd.html","id":"inventario","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3.4 Problema de inventario","text":"Computers-R-Us almacena una amplia variedad de PCs para la venta al por menor. La tienda abre de lunes viernes de 8:00 .m. 5:00 p.m., y utiliza la siguiente política operativa para controlar el inventario al inicio de semana, en función del número de PCs que quedan en stock el viernes de la semana anterior las 5:00 p.m:Si el stock al finalizar una semana es inferior dos, se piden suficientes ordenadores para disponer de un stock total de cinco al inicio la semana siguiente.Si el stock al finalizar una semana es inferior dos, se piden suficientes ordenadores para disponer de un stock total de cinco al inicio la semana siguiente.Si el stock al final de la semana es de dos o más, se realiza ningún pedido.Si el stock al final de la semana es de dos o más, se realiza ningún pedido.La demanda de ordenadores durante la semana es una variable aleatoria de Poisson con media 3. Cualquier demanda que pueda ser satisfecha inmediatamente se pierde.Se consideran las variables aleatorias:\\(X_n:\\) número de PCs en stock las 8:00 .m del lunes de la semana \\(n\\).\\(D_n:\\) número de PCs demandados durante la semana \\(n\\).De esta forma el número de Pcs que hay en la tienda al inicio de la semana \\(n+1\\) viene dado por los que habían en stock al inicio de la semana anterior menos los que se han vendido, siempre que dicho balance sea al menos de 2 unidades, y será de 5 en otro caso:Necesariamente entonces, \\(X_{n+1} \\geq X_n\\) dado que \\(D_n \\geq 0\\).Se trata de una CMTD con espacio de estados \\(\\{2, 3, 4, 5\\}\\), puesto que el estado del sistema en la semana \\(n+1\\) sólo depende de su estado en la semana anterior \\(n\\). Calculemos las probabilidades de transición.Para \\(j= 2, 3, 4\\)\\[\\begin{array}{ll}\nPr[X_{n+1}  = j | X_n = ] & = Pr[X_n - D_n = j | X_n = ]\\\\\n& = Pr[D_n=X_n-j | X_n = ]\\\\\n& = Pr[D_n = - j] \\\\\n&=\\begin{cases}\nPr[D_n = - j] \\quad \\text{ si } \\geq j \\\\\n0 \\qquad \\qquad \\qquad \\quad \\text{ si } < j\n\\end{cases}\n\\end{array}\\]Para \\(j=5\\) e \\(5>\\geq 2\\)\\[\\begin{array}{ll}\nPr[X_{n+1}  = 5 | X_n = ] & = Pr[X_n - D_n \\leq 1 | X_n = ]\\\\\n&=Pr[D_n \\geq X_n-1|X_n=] \\\\\n& = Pr(D_n \\geq - 1).\n\\end{array}\\]Para \\(j=5\\) e \\(=5\\), podría ocurrir que durante la semana anterior se hubiera vendido nada \\(D_n=0\\) o se hubieran vendido al menos cuatro ordenadores, \\(D_n \\geq 4\\) (para dejar un stock inferior 2),\\[\\begin{array}{ll}\nPr[X_{n+1}  = 5 | X_n = 5] & = Pr[X_n - D_n =5 | X_n = 5]\\\\\n&=Pr[D_n =0] + Pr(D_n \\geq 4).\n\\end{array}\\]Usando el hecho de que la variable \\(D_n \\sim Po(3)\\) podemos obtener la tabla de probabilidades siguientes:Usando los datos de esta tabla calculamos fácilmente la matriz de transición asociada la \\(CMTD\\) como:\\[P = \n\\begin{pmatrix}\n0.0498 & 0 & 0 & 0.9502\\\\\n0.1494 & 0.0498 & 0 & 0.8008\\\\\n0.2240 & 0.1494 & 0.0498 & 0.5768\\\\\n0.2240 & 0.2240 & 0.1494 & 0.4026\n\\end{pmatrix}\\]Representamos continuación este sistema en forma de grafo en la Figura 2.4.\nFigura 2.4: Diagrama del sistema de inventario\n","code":"\n# Definimos estados\nestados <- c(\"2 PCs\", \"3 PCs\", \"4 PCs\", \"5 PCs\")\n# Matriz de transición \npmat <- matrix(data = c(0.0498, 0, 0, 0.9502, \n                        0.1494, 0.0498, 0, 0.8008,  \n                        0.2240, 0.1494, 0.0498, 0.5768,\n                        0.2240, 0.2240, 0.1494, 0.4026), \n               byrow = TRUE, nrow = 4, \n               dimnames = list(estados, estados))\n# CMTD\ninventario <- new(\"markovchain\", states = estados, \n                 byrow = TRUE, transitionMatrix = pmat, \n                 name = \"inventario\")\n# Verificamos los datos introducidos\ninventario## inventario \n##  A  4 - dimensional discrete Markov Chain defined by the following states: \n##  2 PCs, 3 PCs, 4 PCs, 5 PCs \n##  The transition matrix  (by rows)  is defined as follows: \n##        2 PCs  3 PCs  4 PCs  5 PCs\n## 2 PCs 0.0498 0.0000 0.0000 0.9502\n## 3 PCs 0.1494 0.0498 0.0000 0.8008\n## 4 PCs 0.2240 0.1494 0.0498 0.5768\n## 5 PCs 0.2240 0.2240 0.1494 0.4026\n# Diagrama\nplot(inventario, vertex.color=\"steelblue\", \n     vertex.label.font = 2, \n     edge.label.size = 0.1,\n     edge.arrow.size=0.5, \n     vertex.shape = \"rectangle\", \n     vertex.size = 40)"},{"path":"cmtd.html","id":"planificacion","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3.5 Planificación de mano de obra","text":"Paper Pushers, Inc. es una empresa de seguros que emplea 100 trabajadores organizados en cuatro grados, etiquetados como \\(1\\), \\(2\\), \\(3\\) y \\(4\\). Por razones de simplicidad, supondremos que los trabajadores pueden ser promovidos de un grado otro, o dejar la empresa, sólo al principio de la semana. Un trabajador en el grado 1 al principio de la semana asciende al grado 2 con probabilidad 0.03, deja la empresa con una probabilidad de 0.02, o continúa en el mismo grado al principio de la semana siguiente. Un trabajador que se encuentra en el grado 2 al principio de la semana asciende al grado 3 con probabilidad 0.01, abandona la empresa con probabilidad 0.008 o continúa en el mismo grado al principio de la semana siguiente. Un trabajador de grado 3 al principio de la semana asciende al grado 4 con una probabilidad de 0.005, abandona la empresa con una probabilidad de 0.02, o continúa en el mismo grado al principio de la semana siguiente. Un trabajador que se encuentra en el grado 4 al principio de la semana deja la empresa con una probabilidad de 0.01 o continúa en el mismo grado al principio de la semana siguiente. Si un trabajador abandona la empresa, es sustituido instantáneamente por otro de grado 1. El movimiento de los trabajadores dentro de la empresa puede modelizarse utilizando una \\(CMTD\\).Supondremos que todos los ascensos de los trabajadores se deciden de manera independiente. Esto simplifica considerablemente nuestro modelo. En lugar de hacer un seguimiento de los 100 trabajadores, tenemos en cuenta un único trabajador, digamos el trabajador \\(k\\), donde \\(k = 1, 2,...,100\\). Pensamos en \\(k\\) como un ID de trabajador, y cuando este trabajador deja la empresa, se le asigna al nuevo sustituto. Sea \\(X_n^k\\) el grado en el que se encuentra el trabajador \\(k\\) al principio de la n-ésima semana. Ahora, si suponemos que los ascensos de los trabajadores se determinan independientemente del historial del trabajador (es decir, que el tiempo transcurrido en un grado determinado afecta las posibilidades de promoción), vemos que para \\(k = 1, 2,...,100\\) el conjunto \\(\\{X_n^k, n \\\\mathbb{N}\\}\\) es una \\(CMTD\\) con espacio de estados \\(S =\\{1, 2, 3, 4\\}\\).Para obtener la matriz de transiciones procedemos con un ejemplo. Supongamos que \\(X_n^k = 3\\) entonces:Si es promocionado (\\(X_{n+1}^k = 4\\)), tenemos que \\(Pr[X_{n+1}^k = 4 | X_n^k = 3] = 0.005.\\)Si deja la empresa, es reemplazado por un nuevo empleado de grado 1 (\\(X_{n+1}^k = 1\\)) de forma que \\(Pr[X_{n+1}^k = 1 | X_n^k = 3] = 0.02.\\)Si se mantiene en el mismo puesto, tenemos que \\(Pr[X_{n+1}^k = 3 | X_n^k = 3] = 0.975.\\)Procediendo de forma similar en el resto de situaciones tenemos la matriz de transición para cualquiera de los trabajores como:\\[P = \n\\begin{pmatrix}\n0.970 & 0.030 & 0 & 0\\\\\n0.008 & 0.982 & 0.010 & 0\\\\\n0.020 & 0 & 0.975 & 0.005\\\\\n0.010 & 0 & 0 & 0.990\n\\end{pmatrix}\\]Representamos continuación este sistema en forma de grafo en la Figura 2.5.\nFigura 2.5: Diagrama del sistema de planificación\n","code":"\n# Definimos estados\nestados <- c(\"1\", \"2\", \"3\", \"4\")\n# Matriz de transición \npmat <- matrix(data = c(0.9700, 0.0300, 0, 0, \n                        0.0080, 0.9820, 0.0100, 0,   \n                        0.0200, 0, 0.9750, 0.0050,\n                        0.0100, 0, 0, 0.9900), \n               byrow = TRUE, nrow = 4, \n               dimnames = list(estados, estados))\n# CMTD\nplanificacion <- new(\"markovchain\", states = estados, \n                 byrow = TRUE, transitionMatrix = pmat, \n                 name = \"planificacion\")\n# Verificamos los datos introducidos\nplanificacion## planificacion \n##  A  4 - dimensional discrete Markov Chain defined by the following states: \n##  1, 2, 3, 4 \n##  The transition matrix  (by rows)  is defined as follows: \n##       1     2     3     4\n## 1 0.970 0.030 0.000 0.000\n## 2 0.008 0.982 0.010 0.000\n## 3 0.020 0.000 0.975 0.005\n## 4 0.010 0.000 0.000 0.990\n# Diagrama\nplot(planificacion, vertex.color=\"steelblue\", \n     vertex.label.font = 2, \n     vertex.label.color = \"white\",\n     edge.label.size = 0.2,\n     edge.arrow.size=0.5, \n     vertex.shape = \"rectangle\",\n     vertex.size = 20)"},{"path":"cmtd.html","id":"mercadovalores","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3.6 Mercado de valores","text":"Las acciones ordinarias de la empresa Gadgets-R-Us se cotizan en el mercado de valores. El director financiero de Gadgets-R-Us compra y vende las acciones de su propia empresa para que el precio nunca baje de 2 dólares y nunca supera los 10 dólares. Para simplificar, suponemos que \\(X_n\\), es el precio de las acciones al final del día \\(n\\), y sólo toma valores enteros; es decir, el espacio de estados del proceso \\(\\{X_n, n \\\\mathbb{N}\\}\\) es \\(S = 2, 3,...,10\\). Si denominamos \\(I_{n+1}\\) al movimiento potencial del precio de las acciones en el día \\(n+1\\) en ausencia de cualquier intervención del director financiero, entonces tenemos que:Un análisis continuado de los datos del pasado sugieren que los movimientos potenciales \\(\\{I_n, n \\geq 1\\}\\) son una secuencia de variables iid con función de masa de probabilidad dada por:\\[Pr(I_n = k) = 0.2, \\quad k = -2, -1, 0, 1, 2.\\]Esto implica que \\(\\{X_n, n \\\\mathbb{N}\\}\\) es una \\(CMTD\\) con espacio de estados \\(S = \\{2, 3,...,10\\}\\), donde las probabilidadees de transición se pueden obtener de forma sencilla. modo de ejemplo presentamos los tres casos siguientes:\\[\\begin{array}{ll}\nPr[X_{n+1} = 2 | X_n = 3] & = Pr[X_n + I_{n+1} \\leq 2 | X_n = 3]\\\\\n& = Pr[I_{n+1} \\leq -1]\\\\\n& = 0.4\n\\end{array}\\]\\[\\begin{array}{ll}\nPr[X_{n+1} = 6 | X_n = 5] & = Pr[X_n + I_{n+1} = 6 | X_n = 3]\\\\\n& = Pr[I_{n+1} = 1]\\\\\n& = 0.2\n\\end{array}\\]\\[\\begin{array}{ll}\nPr[X_{n+1} = 10 | X_n = 10] & = Pr[X_n + I_{n+1} \\geq 10 | X_n = 10]\\\\\n& = Pr[I_{n+1} \\geq 0]\\\\\n& = 0.6\n\\end{array}\\]de forma que la matriz de transición del sistema viene dada por:\\[P = \n\\begin{pmatrix}\n0.6 & 0.2 & 0.2 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0.4 & 0.2 & 0.2 & 0.2 & 0 & 0 & 0 & 0 & 0\\\\\n0.2 & 0.2 & 0.2 & 0.2 & 0.2 & 0 & 0 & 0 & 0\\\\\n0 & 0.2 & 0.2 & 0.2 & 0.2 & 0.2 & 0 & 0 & 0\\\\\n0 & 0 & 0.2 & 0.2 & 0.2 & 0.2 & 0.2 & 0 & 0\\\\\n0 & 0 & 0 & 0.2 & 0.2 & 0.2 & 0.2 & 0.2 & 0\\\\\n0 & 0 & 0 & 0 & 0.2 & 0.2 & 0.2 & 0.2 & 0.2\\\\\n0 & 0 & 0 & 0 & 0 & 0.2 & 0.2 & 0.2 & 0.4\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0.2 & 0.2 & 0.6\n\\end{pmatrix}\\]Representamos continuación este sistema en forma de grafo en la Figura 2.6.\nFigura 2.6: Diagrama del sistema del Mercado de valores\n","code":"\n# Definimos estados\nestados <- c(\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\")\n# Matriz de transición \npmat <- matrix(data = c(0.6 , 0.2 , 0.2 , 0 , 0 , 0 , 0 , 0 , 0,\n                        0.4 , 0.2 , 0.2 , 0.2 , 0 , 0 , 0 , 0 , 0,\n                        0.2 , 0.2 , 0.2 , 0.2 , 0.2 , 0 , 0 , 0 , 0,\n                        0 , 0.2 , 0.2 , 0.2 , 0.2 , 0.2 , 0 , 0 , 0,\n                        0 , 0 , 0.2 , 0.2 , 0.2 , 0.2 , 0.2 , 0 , 0,\n                        0 , 0 , 0 , 0.2 , 0.2 , 0.2 , 0.2 , 0.2 , 0,\n                        0 , 0 , 0 , 0 , 0.2 , 0.2 , 0.2 , 0.2 , 0.2,\n                        0 , 0 , 0 , 0 , 0 , 0.2 , 0.2 , 0.2 , 0.4,\n                        0 , 0 , 0 , 0 , 0 , 0 , 0.2 , 0.2 , 0.6), \n               byrow = TRUE, nrow = 9, \n               dimnames = list(estados, estados))\n# CMTD\nmercado.valores <- new(\"markovchain\", states = estados, \n                 byrow = TRUE, transitionMatrix = pmat, \n                 name = \"Mercado de valores\")\n# Verificamos los datos introducidos\nmercado.valores## Mercado de valores \n##  A  9 - dimensional discrete Markov Chain defined by the following states: \n##  2, 3, 4, 5, 6, 7, 8, 9, 10 \n##  The transition matrix  (by rows)  is defined as follows: \n##      2   3   4   5   6   7   8   9  10\n## 2  0.6 0.2 0.2 0.0 0.0 0.0 0.0 0.0 0.0\n## 3  0.4 0.2 0.2 0.2 0.0 0.0 0.0 0.0 0.0\n## 4  0.2 0.2 0.2 0.2 0.2 0.0 0.0 0.0 0.0\n## 5  0.0 0.2 0.2 0.2 0.2 0.2 0.0 0.0 0.0\n## 6  0.0 0.0 0.2 0.2 0.2 0.2 0.2 0.0 0.0\n## 7  0.0 0.0 0.0 0.2 0.2 0.2 0.2 0.2 0.0\n## 8  0.0 0.0 0.0 0.0 0.2 0.2 0.2 0.2 0.2\n## 9  0.0 0.0 0.0 0.0 0.0 0.2 0.2 0.2 0.4\n## 10 0.0 0.0 0.0 0.0 0.0 0.0 0.2 0.2 0.6\n# Diagrama\nplot(mercado.valores, vertex.color=\"steelblue\", \n     vertex.label.font = 2, \n     vertex.label.color = \"white\",\n     edge.label.size = 0.2,\n     edge.arrow.size=0.5, \n     vertex.shape = \"rectangle\",\n     vertex.size = 20)"},{"path":"cmtd.html","id":"telecomunicaciones","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3.7 Telecomunicaciones","text":"La empresa Tel-Switch Corporation fabrica equipos de conmutación para redes de comunicación. Las redes de comunicación mueven los datos de un conmutador otro la velocidad del rayo en forma de paquetes, es decir, mediante cadenas de ceros y unos (llamadas bits). Los conmutadores Tel-manejan paquetes de datos de longitud constante, es decir, el mismo número de bits en cada paquete. nivel conceptual podemos pensar en el conmutador como un dispositivo de almacenamiento donde los paquetes llegan desde la red de usuarios según un proceso aleatorio, se almacenan en un buffer con capacidad para almacenar \\(K\\) paquetes y se eliminan del buffer uno uno según un protocolo preestablecido. Uno de los protocolos utilizados considera el tiempo dividido en intervalos de duración fija llamados “ranuras” (por ejemplo, un microsegundo), y consiste en que: si hay algún paquete en el buffer al principio de un intervalo o ranura, se elimina uno instantáneamente; si hay ningún paquete al principio de un intervalo, se elimina ningún paquete durante el intervalo, aunque lleguen más paquetes durante el mismo; por último, si un paquete llega durante una ranura y hay espacio para él, se descarta. Este proceso se puede modelar como una \\(CMTD\\).Sean:\\(A_n\\) el número de paquetes que llegan al conmutador durante la enésima ranura (algunos pueden ser descartados)\\(X_n\\) el número de paquetes en el buffer al final de la enésima ranura.Ahora, si \\(X_n = 0\\), entonces hay paquetes disponibles para la transmisión al principio de la ranura \\(n+1\\). Por lo tanto, todos los paquetes que llegan durante esa ranura, es decir, \\(A_{n+1}\\), están en el buffer al final de esa ranura mientras tenga capacidad, esto es, \\(A_{n+1} \\leq K\\); si \\(A_{n+1}>K\\), entonces la memoria intermedia está llena al final de la ranura \\(n+1\\), \\(X_{n+1}=K\\). Por lo tanto, en general \\(X_{n+1} = min(A_{n+1}, K)\\), cuando \\(X_n=0\\).Por otro lado, si hay algún paquete al final del instante \\(n\\), \\(X_n > 0\\), pasan al conumtador en la siguiente ranura \\(n+1\\), se elimina un paquete al principio de la misma y se añaden los paquetes que lleguen durante esa ranura, \\(A_{n+1}\\), con sujeción las limitaciones de capacidad.Combinando estos casos, obtenemos:Asumimos que \\(\\{A_n, n \\geq 1\\}\\) es una secuencia de variables iid con función de masa de probabilidad dada por:\\[Pr(A_n = k) = a_k, \\quad k \\geq 0.\\]Bajo esta condición \\(\\{X_n, n \\\\mathbb{N}\\}\\) es una \\(CMTD\\) con espacio de estados \\(S = \\{0, 1, 2,..., K\\}\\), cuyas probabilidades de transición vienen dadas continuación:Para \\(0 \\leq j < K\\):\\[\\begin{array}{ll}\nPr[X_{n+1} = j | X_n = 0] & = Pr[min(A_{n+1}, K) = j | X_n = 0]\\\\\n& = Pr[A_{n+1} = j]\\\\\n& = a_j\n\\end{array}\\]\\[\\begin{array}{ll}\nPr[X_{n+1} = K | X_n = 0] & = Pr[min(A_{n+1}, K) = K | X_n = 0]\\\\\n& = Pr[A_{n+1} \\geq K]\\\\\n& =\\sum_{k=K}^{\\infty} a_k =1-\\sum_{k=0}^{K-1} a_k\n\\end{array}\\]De igual forma, para \\(0 \\leq -1 \\leq j < K,\\)\\[\\begin{array}{ll}\nPr[X_{n+1} = j | X_n = ] & = Pr[min(X_n + A_{n+1} - 1, K) = j | X_n = ]\\\\\n& = Pr[A_{n+1} = j - + 1]\\\\\n& = a_{j-+1}\n\\end{array}\\]y para \\(1 \\leq \\leq K,\\)\\[\\begin{array}{ll}\nPr[X_{n+1} = K | X_n = ] & = Pr[min(X_n + A_{n+1} - 1, K) = K | X_n = ]\\\\\n& = Pr[A_{n+1} \\geq K - + 1]\\\\\n& = \\sum_{k=K-+1}^{\\infty} a_k=1-\\sum_{k=0}^{K-} a_k\n\\end{array}\\]Si consideramos:\\[b_j = \\sum_{k=j}^{\\infty} a_k\\] la matriz de transiciones de un paso la podemos escribir como:\\[P = \n\\begin{pmatrix}\na_0 & a_1 & ... & a_{K-1} & b_K\\\\\n0 & a_0 & ... & a_{K-2} & b_{K-1}\\\\\n...&...&...&...&...\\\\\n0 & 0 & ... & a_0 & b_1\n\\end{pmatrix}\\]","code":""},{"path":"cmtd.html","id":"inventario2","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.3.8 Inventario con desabastecimiento","text":"El gestor de un almacén desea analizar el comportamiento de uno de sus productos en función de la demanda del producto y de la capacidad del almacén.Consideramos como \\(Y_n\\) la variable aleatoria que describe la demanda del producto durante el n-ésimo periodo de tiempo, de forma que:\\[Pr[Y_n = k] = a_k, \\quad k=0, 1, 2,...  \\text{ con } \\sum_{k=0}^{\\infty} a_k =1\\]Denotamos por \\(X_n\\) la variable aleatoria que registra la cantidad de producto almacenado al finalizar el n-ésimo periodo de tiempo, \\(\\) el nivel mínimo de almacenaje del producto, y \\(B\\) el nivel máximo. La política de reposición es la siguiente:Si al finalizar un periodo el almacén tiene una cantidad de producto \\(X_n\\) menor o igual que \\(\\), entonces se reabastece hasta \\(B\\).Si al finalizar un periodo el almacén tiene una cantidad de producto mayor que \\(\\) y menor o igual \\(B\\), entonces se reabastece y espera hasta el instante de tiempo siguiente.En esta situación el proceso \\(\\{X_n, n \\\\mathbb{N}\\}\\) es un proceso estocástico de tiempo discreto\\[\\begin{array}{ll}\n\\text{ si } X_n \\leq & \\rightarrow X_{n+1} = B - Y_{n+1} \\\\\n\\text{ si } < X_n \\leq B & \\rightarrow X_{n+1} = X_n - Y_{n+1} \n\\end{array}\\] con espacio de estados \\(S = \\{B, B-1,..., 1, 0, -1, -2,...\\}\\), donde los valores negativos indican que la demanda supera la cantidad almacenada y será servida en instantes posteriores (demanda insatisfecha).Las probabilidades de transición vienen dadas por:si \\(\\leq \\)\\[\\begin{array}{ll}\nPr[X_{n+1} = j | X_{n} =]&= Pr[B - Y_{n+1} = j] \\\\\n&=Pr[Y_{n+1} = B-j]   \\\\\n& = \\begin{cases} \na_{B-j}, \\quad \\text{si } B \\geq j\\\\\n0,  \\qquad \\text{ si } B < j\n\\end{cases}\n\\end{array}\\]si \\(< \\leq B\\)\\[\\begin{array}{ll}\nPr[X_{n+1} = j | X_{n}=] & = Pr[- Y_{n+1} = j] \\\\\n&=Pr[Y_{n+1} = -j]   \\\\\n& =  \\begin{cases}\na_{-j}, \\quad \\text{ si } \\geq j\\\\\n 0, \\qquad \\text{ si } < j\n \\end{cases}\n\\end{array}\\]modo de ejemplo consideramos \\(= 0\\), \\(B = 2\\), con probabilidades para \\(Y_n\\) dadas por:\\[Pr[Y_n = 0] = 0.5; \\quad Pr[Y_n = 1] = 0.4; \\quad Pr[Y_n = 2] = 0.1,\\] entonces la matriz de transición, para el espacio de estados \\(S = \\{-1, 0, 1, 2\\}\\), viene dada por:\\[P = \n\\begin{pmatrix}\n0 & 0.1 & 0.4 & 0.5\\\\\n0 & 0.1 & 0.4 & 0.5\\\\\n0.1 & 0.4 & 0.5 & 0\\\\\n0 & 0.1 & 0.4 & 0.5\n\\end{pmatrix}\\]Representamos continuación este sistema en forma de grafo en la Figura 2.7.\nFigura 2.7: Diagrama del sistema del problema de inventario.\n","code":"\n# Definimos estados\nestados <- c(\"-1\", \"0\", \"1\", \"2\")\n# Matriz de transición \npmat <- matrix(data = c(0 , 0.1 , 0.4 , 0.5,\n                        0 , 0.1 , 0.4 , 0.5,\n                        0.1 , 0.4 , 0.5 , 0,\n                        0 , 0.1 , 0.4 , 0.5), \n               byrow = TRUE, nrow = 4, \n               dimnames = list(estados, estados))\n# CMTD\ninventario2 <- new(\"markovchain\", states = estados, \n                 byrow = TRUE, transitionMatrix = pmat, \n                 name = \"Inventario 2\")\n# Verificamos los datos introducidos\ninventario2## Inventario 2 \n##  A  4 - dimensional discrete Markov Chain defined by the following states: \n##  -1, 0, 1, 2 \n##  The transition matrix  (by rows)  is defined as follows: \n##     -1   0   1   2\n## -1 0.0 0.1 0.4 0.5\n## 0  0.0 0.1 0.4 0.5\n## 1  0.1 0.4 0.5 0.0\n## 2  0.0 0.1 0.4 0.5\n# Diagrama\nplot(inventario2, vertex.color=\"steelblue\", \n     vertex.label.font = 2, \n     vertex.label.color = \"white\",\n     edge.label.size = 0.2,\n     edge.arrow.size=0.5, \n     vertex.shape = \"rectangle\",\n     vertex.size = 20)"},{"path":"cmtd.html","id":"CaracCMTD","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.4 Caracterización de una CMTD","text":"En esta sección estudiamos las principales características de una \\(CMTD\\) través de la comunicación entre los diferentes estados de proceso, el número de visitas y los tiempos de ocupación de cada estado, los tiempos la primera visita, partiendo de un estado, e introducimos la utilización de costes para la evaluación de los sistemas.En todas las definiciones que presentamos continuación asumimos que tenemos una \\(CMTD\\) \\(\\{X_n, n \\\\mathbb{N}\\}\\) con espacio de estados \\(S\\) y matriz de transición de un paso \\(P\\).","code":""},{"path":"cmtd.html","id":"comunicación-entre-estados","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.4.1 Comunicación entre estados","text":"Comenzamos caracterizando los estados de una cadena en función de sus probabilidades de transición.Definición 2.5  Dados dos estados \\(, j\\) de \\(S\\), se dice que el estado \\(j\\) es accesible desde el estado \\(\\) si existe una transición \\(n\\) tal que \\(p_{ij}(n) > 0\\).Que el estado \\(j\\) sea accesible desde \\(\\) se denota habitualmente como \\(\\rightarrow j\\).Definición 2.6  Dados dos estados \\(, j\\) de \\(S\\), se dice que son comunicantes si \\(\\) es accesible desde \\(j\\), y \\(j\\) es accesible desde \\(\\), es decir, existen \\(n_1\\) y \\(n_2\\) tal que \\(p_{ij}(n_1) > 0\\) y \\(p_{ji}(n_2) > 0.\\)Que los estados \\(, j\\) sean comunicantes se denota habitualmente como \\(\\leftrightarrow j\\).Definición 2.7  Un subconjunto de estados \\(S_j \\subset S\\) se denomina clase comunicante del estado \\(j\\) si todos los estados de ese subconjunto son comunicantes con \\(j\\).\\[S_j \\subset S \\text{ es clase comunicante de } j \\text{ si } \\quad \\leftrightarrow j, \\qquad \\forall \\S_j.\\]Definición 2.8  Un estado \\(\\S\\) se denomina estado sin retorno cuando es viable volver dicho estado tras partir de él, esto es, para \\(n \\geq 1\\), \\(p_{ii}(n) = 0.\\)Definición 2.9  Un conjunto de estados \\(C \\subset S\\) se denomina cerrado cuando es posible pasar de un estado de \\(C\\) otro que esté en \\(C\\), esto es,\\[\\forall \\C, \\quad \\forall j \\notin C \\quad \\Rightarrow \\quad p_{ij}(n) = 0, \\quad n\\geq 1\\]\no lo que es lo mismo,\n\\[ \\sum_{j \\C} p_{ij}=1, \\quad \\forall \\C.\\]Esto implica que cuando accedamos un conjunto cerrado, será imposible salir de él y sólo será factible moverse dentro de él.Si el conjunto cerrado está compuesto por un único estado \\(\\) diremos que ese estado \\(\\) es absorbente. Eso implica que si se llega dicho estado, el proceso se queda estancado en él y ya es posible moverse otro estado.Definición 2.10  Una \\(CMTD\\) es irreducible cuando todos sus estados están comunicados entre sí. Un conjunto de estados en S se dice irreducible cuando contiene ningún subconjunto cerrado. Si la \\(CMTD\\) es irreducible, se llama reducible.Todos los estados dentro de un conjunto irreducible son del mismo tipo.Para caracterizar una CMTD mediante la librería markovchain es útil usar la función summary(object) donde ‘object’ identifica el proceso estudiar.Ejemplo 2.2  Queremos caracterizar el proceso presentado en el Ejemplo 2.1. Cargamos los datos y ejecutamos la sintaxis continuación.la vista del resultado, concluimos que este proceso es cerrado (todo su espacio de estados es cerrado). Todos sus estados son recurrentes y tiene estados transitorios (estos conceptos los veremos más adelante). tiene estados absorbentes y la cadena de Markov es irreducible (todos sus estados están comunicados).PRACTICA Caracterizar los procesos: Fiabilidad de máquinas,Metereología, Problema de inventario, Planificación de mano de obra, Mercado de valores e Inventario con desabastecimiento.Ejemplo 2.3  Veamos ahora cómo utilizar la simulación para responder diferentes preguntas de interés. En concreto, para el ejemplo en la sección Inventario con desabastecimiento (recordemos que se trataba de un almacén que se reabastecía cuando el inventario quedaba por debajo o igual un nivel mínimo de almacenaje, \\(=0\\), y con una política de reabastecimiento que dependía del nivel de almacenaje máximo \\(B=2\\)), planteamos estas preguntas:Durante las próximas 20 semanas, ¿en cuántas de ellas será preciso reabastecerse?Durante las próximas 20 semanas, ¿en cuántas de ellas será preciso reabastecerse?Durante las próximas 20 semanas, ¿cuál es la proporción de semanas en que la demanda ha sido satisfecha (por rebasar el stock)?Durante las próximas 20 semanas, ¿cuál es la proporción de semanas en que la demanda ha sido satisfecha (por rebasar el stock)?Para responder estas preguntas hay que considerar el proceso \\(\\{X_n, n \\geq 0\\}\\) y la variable \\(Y_n\\) que identifica la demanda en la semana \\(n\\). Planteamos el siguiente algoritmo de simulación.Algoritmo para simulación de inventarioPaso 1. Fijar el número de transiciones del proceso, \\(n\\), e inicializar \\(X_0 = 2\\) (máximo almacenaje).Repetir pasos 2 y 3 hasta alcanzar el número de transiciones deseadas.Paso 2. Generar \\(Y_i\\) con el método de la transformada inversa.Paso 2. Generar \\(Y_i\\) con el método de la transformada inversa.Paso 3. Actualizar el valor \\(X_i\\) y reabastecer si fuera necesario.Paso 3. Actualizar el valor \\(X_i\\) y reabastecer si fuera necesario.Paso 4. Devolver la secuencia \\(\\{X_i, Y_i; =1,\\ldots,n\\}\\) para estudiar la evolución del sistema y la demanda.Paso 4. Devolver la secuencia \\(\\{X_i, Y_i; =1,\\ldots,n\\}\\) para estudiar la evolución del sistema y la demanda.Desarrollemos pues, el algoritmo.La estimación del número de semanas que hay que reabastecerse viene dada por el número de simulaciones en las que el nivel de inventario es menor o igual al nivel mínimo de almacenamiento, \\(invent=X\\leq 0\\), es decirLa proporción de semanas en que la demanda ha sido satisfecha (por rebasar el stock) corresponde aquellas en las que la demanda ha superado al inventario,","code":"\n# Caracterización\nsummary(proceso)## Unnamed Markov chain  Markov chain that is composed by: \n## Closed classes: \n## a b c \n## Recurrent classes: \n## {a,b,c}\n## Transient classes: \n## NONE \n## The Markov chain is irreducible \n## The absorbing states are: NONE\n# Inicialización\nset.seed(12)\ntiempo <- 21 # valor inicial y 20 transiciones\ninvent <- c()  # vector con los valores de inventario\ndemanda <- c() # vector con los valores de demanda\nA <- 0\nB <- 2\n##### Configuración metodo transformada inversa ######\n# datos uniformes\nunif <- runif(tiempo-1)\n# Valores posibles para la demanda\nvalores <- c(0, 1, 2)\n# Probabilidades para la demanda\nprob <- c(0.5, 0.4, 0.1)\nprobacum <- cumsum(prob)  # probabilidades acumuladas\n# valor inicial del proceso\ninvent[1] <- 2\ndemanda[1] <- 0\ni<-2\nwhile (i <= tiempo)\n{\n  # simulamos demanda\n  demanda[i] <- valores[min(which(unif[i-1] <= probacum))] \n  # Actualizamos inventario\n  ifelse(invent[i-1] <= A, \n         invent[i] <- B - demanda[i], \n         invent[i] <- invent[i-1]-demanda[i])\n  # iteración siguiente\n  i<-i+1\n}\n# Devolvemos la secuencia de estados \ninventario2.sim=data.frame(invent,demanda)\nhead(inventario2.sim)##   invent demanda\n## 1      2       0\n## 2      2       0\n## 3      1       1\n## 4     -1       2\n## 5      2       0\n## 6      2       0\nsum(inventario2.sim$invent <= A)## [1] 3\nmean(inventario2.sim$invent <inventario2.sim$demanda)## [1] 0.1428571"},{"path":"cmtd.html","id":"tiemposocupa-sec","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.4.2 Tiempos de ocupación","text":"Definición 2.11  Sea \\(\\{X_n, n \\\\mathbb{N}\\}\\) una \\(CMTD\\) homogénea con espacio de estados \\(S = \\{1, 2,...,N\\}\\), matriz de probabilidades de transición de una paso \\(P\\), y distribución inicial \\(p(0)\\). Consideramos la variable aleatoria \\(N_j(n)\\) como el número de visitas al estado \\(j\\) en el periodo \\(\\{1, 2,...,n\\}\\) y definimos\\[m_{ij}(n) = E[N_j(n)|X_0 = ]\\]\ncomo el número esperado de visitas o tiempo de ocupación del estado \\(j\\) hasta el instante \\(n\\), partiendo del estado \\(\\).partir de las cantidades \\(m_{ij}(n)\\) se puede definir la matriz de tiempos de ocupación hasta un instante \\(n\\), \\(M(n)\\), que se puede calcular partir de la matriz de transición \\(P\\) como:\\[\\begin{equation}\nM(n) = \\sum_{r=0}^n P^r\n\\tag{2.7}\n\\end{equation}\\]Definición 2.12  Sea \\(\\{X_n, n \\\\mathbb{N}\\}\\) una \\(CMTD\\). Se define el número de visitas al estado \\(j\\) lo largo de la vida de la cadena como\n\\[N_j=\\sum_{n=0}^{\\infty} (X_n,j),\\]\ndonde \\((X_n,j)=1\\) si \\(X_n=j\\) y 0 en otro caso.Así, el número esperado de visitas al estado \\(j\\) lo largo de la vida de la cadena, partiendo del estado \\(\\), se define como\n\\[m_{ij} = E[N_j|X_0 = ].\\]Definición 2.13  Un estado \\(\\) se dice que es recurrente si es continuamente revisitado lo largo de la vida de la cadena, esto es, el número esperado de visitas al estado \\(\\) lo largo de la vida del proceso es infinito, \\(m_{ii}=E(N_i|X_0=)=\\infty\\). En otro caso, cuando sólo se accede un número finito de veces, se dice que es transitorio. Un estado transitorio sólo será accesible durante un cierto periodo de tiempo, tras el cual dicho estado ya será revisitado nunca más.Ejemplo 2.4  Volvemos sobre el Ejemplo 2.1 para calcular los tiempos de ocupación durante un periodo continuado de 10 transiciones. Para ello utilizamos la Ecuación (2.7) con \\(n=10\\).Podemos ver cómo el número esperado de visitas al estado \\(c\\) partiendo del estado \\(b\\) en las próximas 10 transiciones es casi de 7 (6.86). Sin embargo, si partimos del estado \\(b\\), en 10 transiciones sólo esperamos volver dicho estado 1 vez.Definamos una función para obtener la matriz de tiempos de ocupación (o número esperado de visitas) durante un periodo de duración de \\(n\\) unidades de tiempo.PRACTICA Obtener y caracterizar la matriz del número esperado de visitas en 20 transiciones para los procesos: Fiabilidad de máquinas,Metereología, Problema de inventario, Planificación de mano de obra y Mercado de valores.","code":"\n## Simulación de los tiempos de ocupación (número de visitas a un estado)\n# Número de estados del proceso\nnestat <- dim(proceso)\n# Estados\nnombres<- names(proceso)\n# Generamos la matriz de ocupaciones\nmocupa <- matrix(rep(0,nestat*nestat),\n                 nrow = nestat, dimnames = list(nombres, nombres))\n# Bucle de cálculo de los tiempos de ocupación\nP=proceso[1:nestat,1:nestat] # matriz de transición\nfor (i in 0:10)\n{\n   mocupa <- mocupa + P^i\n}\nmocupa##          a        b        c\n## a 1.250000 1.428569 1.999023\n## b 1.111111 1.000000 6.861894\n## c 2.219126 1.000000 1.817903\nmocupa.proceso <- function(sistema, n)\n{\n  # Número de estados del proceso\n  nestat <- dim(sistema)\n  # Estados\n  nombres<- names(sistema)\n  # Generamos la matriz de ocupaciones\n  mocupa <- matrix(rep(0, nestat*nestat),\n                 nrow = nestat, dimnames = list(nombres, nombres))\n  # Bucle de calculo de los tiempos de ocupación\n  P=sistema[1:nestat,1:nestat]\n  for (i in 0:n)\n   mocupa <- mocupa + P^i\n  \n  return(mocupa)\n}"},{"path":"cmtd.html","id":"análisis-de-costes","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.4.3 Análisis de costes","text":"Una aplicación muy habitual de los tiempos de ocupación es directa en los denominados modelos de costes, que describimos brevemente, y que pueden estar vinculados en situaciones específicas costes, beneficios, pérdidas, etc..Sea \\(X_n\\) el estado del sistema en el tiempo \\(n\\). Asumimos que \\(\\{X_n, n \\\\mathbb{N}\\}\\) es una \\(CMTD\\) con espacio de estados \\(S =\\{1, 2,...,N\\}\\), matriz de transición \\(P\\), y matriz de tiempos de ocupación \\(M(n)\\).En esta situación, hablamos de que cada visita cierto estado \\(\\) tiene un coste asociado \\(C()\\), y el coste esperado por visitar el estado \\(\\) lo largo de la vida del proceso viene dado por \\(c() = E[C()]\\). Definimos la matriz de costes esperados asociados los estados, como \\(c\\), de dimensión \\(N\\times 1\\), como:\n\\[c' = (c(1),c(2),\\ldots,c(N))\\]Así mismo, hablamos del coste \\(C(X_r)\\) en el que incurre el sistema en un instante concreto \\(r\\), y \\(\\sum_{r=0}^n C(X_r)\\) el coste acumulado desde el inicio del proceso hasta llegar al instante \\(n\\). Entonces el coste esperado total (CET) asociado al funcionamiento del sistema hasta llegar al instante \\(n\\) se calculará como \\(E\\left[\\sum_{r=0}^n C(X_r)\\right]\\).Definimos el coste esperado total (CET) hasta el instante \\(n\\) partiendo del estado \\(\\), \\(g(,n)\\), como:\n\\[g(,n) = E\\left[\\sum_{r=0}^n C(X_r)| X_0 = \\right]\\]y construimos la matriz de costes totales sobre un horizonte finito (CTHF) hasta el instante \\(n\\), \\(g(n)\\), de dimensión \\(N \\times 1\\), través de estos costes esperados partiendo de cualesquier estado \\(\\S\\), como\n\\[g(n)' = (g(1,n),g(2,n),\\ldots,g(N,n))\\]Definición 2.14  Si queremos calcular el coste esperado total sobre un horizonte finito hasta un instante \\(n\\), (CTHF), basta multiplicar la matriz de tiempos de ocupación hasta el instante \\(n\\), \\(M(n)\\), por la matriz de costes esperados asociados los estados del sistema, \\(c\\):\n\\[\\begin{equation}\ng(n) = M(n) \\cdot c\n\\tag{2.8}\n\\end{equation}\\]Ejemplo 2.5  Volvamos al proceso de inventario presentado en el Problema de inventario con espacio de estados \\(\\{2,3,4,5\\}\\). Supongamos que la empresa compra PCs por 1500 euros y los vende por 1750 euros. Además el coste de almacenamiento semanal es de 50 euros por cada unidad que está en la tienda al inicio de una semana. Queremos calcular los ingresos netos que la tienda espera obtener durante las próximas 10 semanas, suponiendo que comienza con cinco PCs en stock al inicio del periodo.En esta situación, si hay \\(\\) PCs al principio de la semana \\(n\\), el coste esperado de almacenamiento esa semana es \\(50i\\). Si \\(D_n\\) es la demanda durante la semana \\(n\\), el número esperado de PCs vendidos durante la semana \\(n\\) será \\(E[min(, D_n)]\\), por lo que los ingresos netos previstos para la semana \\(n\\) provendrán de los ingresos por ventas menos los gastos de almacenaje, esto es,\\[c() = (1750-1500)E[min(, D_n)] -50i, \\quad 2 \\leq \\leq 5\\]Necesitamos pues, obtener el valor de \\(E[min(, D_n)]\\), para cada valor de \\(\\). Veamos cómo hacerlo, tanto de forma teórica como mediante simulación. Denotemos por \\(Z_{,n} = min(, D_n),\\) para \\(=2, 3, 4, 5\\) de forma que:de esta forma tenemos que su valor esperado vendrá dado por:\\[E[Z_{,n}] = *Pr[\\leq D_n] + \\sum_{d=0}^{-1} d \\cdot Pr(D_n=d).\\]Recordando que \\(D_n\\sim Pois(3)\\) en el ejemplo original, para \\(=2\\) la expresión anterior da lugar :\\[\\begin{eqnarray*}\nE[Z_{2,n}] &= 2*Pr[D_n \\geq 2] + 0*Pr[D_n = 0] + 1*Pr[D_n =1] \\\\\n&= 2*0.8008+0.1494 = 1.751\n\\end{eqnarray*}\\]y por tanto:\\[c(2) =  250*1.751 -50*2 = 337.75\\]De forma análoga podemos obtener el resto de costes esperados por el hecho de tener \\(\\) PCs en la tienda,\\[c = \n\\begin{pmatrix}\n337.75 \\\\\n431.95 \\\\\n470.15 \\\\\n466.23 \n\\end{pmatrix}\\]de donde podemos calcular los ingresos netos totales esperados durante las próximas \\(n=10\\) semanas, sea cual sea el estado inicial del sistema, través de la matriz\n\\[g(10)=M(10) \\cdot c\\]\nque calculamos continuación:y que nos permite extraer los ingresos netos totales esperados asumiendo que el periodo inicia con \\(=5\\) PCs en tienda, esto es, como \\(g(5,10)=2325.006\\) euros.Los valores de \\(c\\) se pueden aproximar mediante simulación sin necesidad de calcularlos de forma teórica. continuación se presenta el código necesario para realizar la simulación. Concretamente definimos una función que depende del valor del estado inicial \\(\\).Aproximamos pues por simulación, los valores de la matriz \\(c\\) con \\(nsim=1.000.000\\) simulacionesComo se puede ver, la simulación funciona bastante bien para aproximar el vector \\(c\\); resolvamos pues los cálculos de \\(g(5,10)\\) con estos valores, que de nuevo aproximarán las cantidades que buscamos.Mientras que teóricamente obteníamos unos ingresos esperados de 2325€, con la simulación obtenemos una aproximación de 2324.53€.","code":"\nc=matrix(c(337.75,431.95,470.15,466.23), ncol=1)\nM10=mocupa.proceso(inventario,10)\ng=M10 %*% c\ng##           [,1]\n## 2 PCs 5282.121\n## 3 PCs 3459.052\n## 4 PCs 2536.941\n## 5 PCs 2325.006\nc.sim <- function(estado, nsim)\n{\n  # estado: estado inicial del sistema\n  # nsim: nº simulaciones para la aproximación\n  \n  # Fijamos semilla\n  set.seed(12)\n  # Simulamos valores del mínimo entre i y D_n\n  datos <- data.frame(rsim = rpois(nsim, 3), rdos <- rep(estado, nsim))\n  minimo <-apply(datos, 1 ,min) # Mínimo por filas\n  # Valor esperado min(i,D_n)\n  esperanza <- mean(minimo)\n  # coste\n  coste <- round(-50*estado+250*esperanza, 2)\n  return(coste)\n}\nnsim <- 1000000\nc.s=matrix(c(c.sim(2, nsim),c.sim(3, nsim),\n      c.sim(4, nsim),c.sim(5, nsim)),ncol=1)\nc.s##        [,1]\n## [1,] 337.66\n## [2,] 431.81\n## [3,] 470.04\n## [4,] 466.20\n# matriz M\nMmat <- mocupa.proceso(inventario, 10)\n# vector g\nbeneficio <- Mmat%*%c.s\nbeneficio##           [,1]\n## 2 PCs 5281.517\n## 3 PCs 3458.551\n## 4 PCs 2536.474\n## 5 PCs 2324.530"},{"path":"cmtd.html","id":"tiempos-de-primer-paso","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.4.4 Tiempos de primer paso","text":"Definición 2.15  Sea \\(\\{X_n, n \\\\mathbb{N}\\}\\) una \\(CMTD\\) homogénea con espacio de estados \\(S = \\{1, 2,...,N\\}\\). Se define el tiempo de primer paso o tiempo de primera visita al estado \\(j\\) partiendo del estado \\(\\), \\(T_{ij}\\), como el mínimo número de transiciones necesarias para alcanzar el estado \\(j\\) partiendo del estado inicial \\(\\), es decir:\\[T_{ij} = \\underset{n}{min}\\{n > 0, X_n = j | X_0 = \\}\\]En ocasiones interesará sin embargo el tiempo de primer paso de un estado un conjunto de estados \\(\\):\\[T_{iA} = \\underset{n}{min}\\{n > 0, X_n \\| X_0 = \\}.\\]Para obtener los tiempos esperados de recurrencia \\(f=(f_{11},...,f_{NN})\\) para el espacio de estados \\(S=\\{1,...,N\\}\\), utilizamos la función meanRecurrenceTime(proceso) de la librería markovchain.Podemos obtener la distribución de probabilidad asociada al tiempo de primer paso del estado \\(j\\) desde el estado \\(\\) en \\(n\\) transiciones, \\(f_{ij}(n)\\), con la función firstPassageMultiple(proceso,state=,set=j,n=n).Para obtener los tiempos esperados de primer paso por un estado \\(j\\) desde cualquier estado de \\(S\\), podemos utilizar la función meanFirstPassageTime(proceso,destination=j) de la librería markovchain. Si queremos calcular la matriz de tiempos esperados para llegar cualquier estado desde cualquier estado, basta utilizar meanFirstPassageTime(proceso).En caso de que podamos utilizar la función meanFirstPassageTime para el cálculo del tiempo de primer paso, podemos utilizar la propiedad que pasamos describir.Definición 2.16  Sea \\(\\{X_n, n \\\\mathbb{N}\\}\\) una \\(CMTD\\) con espacio de estados \\(S = \\{1, 2,...,N\\}\\). Si estamos interesados en obtener el tiempo esperado de primer paso para el estado \\(j\\) desde cualquier estado \\(\\), dado por:\\[v_{ij} = E(T_{ij}), \\quad \\text{ con } T_{ij} = \\underset{n}{min}\\{n > 0, X_n = j | X_0 = \\}\\]$\ny construimos la matriz de dimensión \\((N-1) \\times 1\\) \\(\\mathbf{v_j'}=(v_{1j},...,v_{j-1,j},v_{j+1,j},...,v_{Nj})\\)\nbasta con resolver el sistema:\\[[\\mathbf{} - P_{-j}]\\mathbf{v_j} = \\mathbf{1}\\]donde\\(P_{-j}\\) es la matriz de transición eliminando la fila y columna del estado \\(j\\),\\(\\mathbf{1}\\) es un vector de unos, de dimensión \\(N-1\\),\\(\\mathbf{}\\) es una matriz diagonal de las mismas dimensiones que \\(P_{-N}\\).Esta ecuación se puede generalizar para obtener los tiempos esperados de primer paso desde un estado \\(\\) hasta cualquier subconjunto de estados \\(S_c \\subset S\\).Función para obtener los tiempos esperados de primer pasoComo alternativa la función definida en markovchain, programamos continuación una función genérica para poder obtener los tiempos esperados de primer paso, dependiente de dos parámetros:proceso: \\(CMTD\\) que describe el sistema estudioestado: estado o conjunto de estados que se desean alcanzar, partiendo desde cualquier estado inicial que está en este conjunto.Definición 2.17  Sea \\(\\{X_n, n \\\\mathbb{N}\\}\\) una \\(CMTD\\) homogénea con espacio de estados \\(S = \\{1, 2,...,N\\}\\). Se definen las probabilidades de primera visita o primer paso del estado \\(\\) al \\(j\\) en \\(n\\) transiciones, con \\(f_{ij}(n)\\),\\[\\begin{eqnarray*}\nf_{ij}(n) &=& Pr[X_n = j, X_{n-1} \\neq j,\\ldots, X_1 \\neq j | \\quad X_0 = ] \\\\ \n&=& Pr(T_{ij}=n), \\quad n \\geq 0\n\\end{eqnarray*}\\]donde por convenio \\(f_{ij}(0) = 0.\\)Definición 2.18  Sea \\(\\{X_n, n \\\\mathbb{N}\\}\\) una \\(CMTD\\) homogénea con espacio de estados \\(S = \\{1, 2,...,N\\}\\). Sea \\(m_{ij}\\) el número esperado de visitas al estado \\(j\\) cuando se parte del estado \\(\\), y \\(f_{ij}=Pr(T_{ij}<\\infty)\\) la probabilidad de alcanzar el estado \\(j\\) partiendo del estado \\(\\). Entonces se cumple la relación:\n\\[ m_{ij}=\\begin{cases}\n\\frac{1}{1-f_{jj}}, \\quad \\text{ si } =j \\\\\n\\frac{f_{ij}}{1-f_{jj}}, \\quad \\text{ si } \\neq j\n\\end{cases}\\]Definición 2.19  Si \\(T_{ii}\\) denota el tiempo del primer retorno, o tiempo de recurrencia al estado \\(\\), entonces se dice que el estado \\(\\) es recurrente si \\(f_{ii}=Pr(T_{ii}<\\infty)=1\\), es decir, si el sistema se inicia en él, pueda volver él. Es transitorio si \\(f_{ii}<1\\).Ejemplo 2.6  Analizamos los tiempos de primer paso, tiempos de recurrencia y probabilidades de primer paso sobre el proceso presentado en el Ejemplo 2.1. Estamos interesados en saber cuándo alcanzaremos el estado “b” partiendo desde cualquier estado en el momento inicial.Comenzamos calculando los tiempos de primer paso utilizando las dos funciones consideradas, la propia y la de markovchain.Podemos ver que ambas funciones proporcionan el mismo resultado. Si comenzamos en el estado “” tardaremos en promedio seis transiciones para alcanzar por primera vez el estado “b,” mientras que si empezamos en el estado “c” tardaremos 8 transiciones en alcanzar el estado “b.”Si deseamos la matriz del valor esperado del primer paso en cualquier estado basta con ejecutarObtenemos ahora el tiempo de primer paso (utilizando la función programada) y la probabilidad de primer paso de pasar del estado \\(b\\) cualquiera de los estados \\(\\) o \\(c\\) en 10 transiciones (\\(= \\{, c\\}\\))Se espera poder pasar de \\(b\\) \\(\\) en una transición (lógico puesto que es el conjunto complementario \\(b\\) en el conjunto de estados), mientras que la probabilidad de pasar del estado \\(b\\) al conjunto \\(\\) en dos transiciones es de \\(0.55\\) y tan solo de \\(0.0008\\) en 10 transiciones.En cuanto los tiempos de recurrencia, tenemos:Podemos ver que una vez hemos pasado por el estado “b” tardamos 9 transiciones en volver él. Calculamos ahora la probabilidad de recurrencia en 10 transiciones.Si iniciamos el proceso en el estado “b” la probabilidad de volver dicho estado es muy baja en cualquiera de las 10 primeras transiciones. La probabilidad de volver en 3 transiciones es de 0.15, pero de volver en 10 transiciones es de 0.046.¿Qué implicaciones prácticas tienen los análisis realizados en el proceso estudiado?Ejemplo 2.7  Consideramos el proceso que ya vimos sobre Fiabilidad de máquinas. Supongamos que en el instante inicial (dia 0) las dos máquinas están “,” y que deseamos calcular el tiempo esperado hasta que las dos máquinas estén “” por primera vez.Si \\(Y_n\\) es el proceso que representa el número de máquinas que están “,” con espacio de estados \\(S = \\{0, 1, 2\\}\\), estamos interesados en calcular el tiempo esperado para llegar \\(Y_n = 0\\) (dos máquinas “”) partiendo de \\(Y_0 = 2\\) (dos máquinas “”). Utilizamos la función propia estableciendo el estado objetivo.El tiempo esperado para que las dos máquinas estén en estado “” comenzando con ambas en el estado “” es 2451.5, que expresado en años será \\(2451.5/365 = 6.71\\) años.Ejemplo 2.8  Consideramos el proceso ya presentado sobre Planificación de mano de obra. Deseamos el tiempo medio de permanencia en la empresa para un empleado recién reclutado. Recordemos que un nuevo empleado siempre empieza en el nivel “1.” Definamos un proceso \\(Y_n\\) que representa el nivel de un empleado novel en la semana n-ésima, proceso que puede tomar los valores \\(S = \\{0, 1, 2, 3, 4\\}\\), donde \\(Y_n=0\\) significa que deja la empresa en n semanas después de empezar. En esta situación el proceso \\(\\{Y_n, n \\\\mathbb{N}\\}\\) es una \\(CMTD\\) con espacio de estados \\(S = \\{0, 1, 2, 3, 4\\}\\) y matriz de probabilidades de transición calculadas partir de las probabilidades que se daban en el desarrollo de Planificación de mano de obra y teniendo en cuenta que si está fuera de la empresa, la semana siguiente también lo estará:\\[P = \n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 \\\\\n0.02 & 0.98 & 0.03 & 0 & 0\\\\\n0.008 & 0 & 0.982 & 0.01 & 0\\\\\n0.02 & 0 & 0 & 0.975 & 0.005\\\\\n0.01 & 0 & 0 & 0 & 0.99\n\\end{pmatrix}\\]Creamos la estructura del sistema:En este caso el estado “0” es absorbente (cuando es despedido, ya vuelve), y el resto de estados son transitorios. Al tener un estado absorbente, es irreducible y se puede aplicar la función meanFirstPassageTime() para calcular los tiempos de primer paso esperados. Usamos pues, la función que hemos programado:Puesto que el nuevo empleado comienza siempre en el nivel “1,” el tiempo esperado para que abandone la empresa es de 73.33 semanas (el proceso se mide en semanas), lo que equivale 1.4 años (\\(73.33/52\\)).","code":"\n# Función para obtener el tiempo esperado de primer paso por \"estado\"\n# (equivalente a meanFirstPassageTime de markovchain)\ntiempo.pp <- function(proceso, estado)\n{\n  # estados del proceso\n  estados <- states(proceso)\n  numestados <- length(estados)\n  # posición de los estados deseados\n  lestat <- length(estado)\n  pos <- which(estados %in% estado)\n  # matriz P_N\n  P_N <- proceso[-pos,-pos]\n  # vector de unos\n  vector.1 <- matrix(rep(1, numestados-lestat), ncol=1)\n  # sistema de ecuaciones\n  sistema <- diag(numestados-lestat) - P_N\n  # solución del sistema\n  solucion <- solve(sistema, vector.1)\n  return(solucion)\n}\n# Tiempo de primer paso partiendo del estado \"b\"\n# libreria\nmeanFirstPassageTime(proceso, \"b\")##        a        c \n## 6.363636 8.181818\n# definida por nosotros\ntiempo.pp(proceso, \"b\")##       [,1]\n## a 6.363636\n## c 8.181818\nmeanFirstPassageTime(proceso)##          a        b        c\n## a 0.000000 6.363636 1.688312\n## b 2.636364 0.000000 1.168831\n## c 1.818182 8.181818 0.000000\n# Tiempo esperado e primer paso de \"b\" a \"A\"\ntiempo.pp(proceso,c(\"a\",\"c\"))##      [,1]\n## [1,]    1\n# Probabilidad de primer paso de \"b\" a \"A\"\nfirstPassageMultiple(proceso, \"b\", c(\"a\",\"c\"), 10)##             set\n## 1  1.0000000000\n## 2  0.5450000000\n## 3  0.2597500000\n## 4  0.1091375000\n## 5  0.0479968750\n## 6  0.0211430938\n## 7  0.0093898422\n## 8  0.0041868540\n## 9  0.0018726328\n## 10 0.0008392372\n# Tiempo de recurrencia\nmeanRecurrenceTime(proceso)##        a        b        c \n## 2.700000 9.000000 1.928571\n# Probabilidad de recurrencia en 10 pasos\nfirstPassageMultiple(proceso, \"b\", \"b\", 10)##           set\n## 1  0.00000000\n## 2  0.03000000\n## 3  0.15450000\n## 4  0.10597500\n## 5  0.09746625\n## 6  0.08295844\n## 7  0.07195424\n## 8  0.06211757\n## 9  0.05368795\n## 10 0.04638892\n# Tiempo de primer paso para acabar en el estado \"0\"\ntiempo.pp(fiabilidad, \"0\")##       [,1]\n## 1 2450.990\n## 2 2451.485\n# Definimos estados\nestados <- c(\"0\", \"1\", \"2\", \"3\", \"4\")\n# Matriz de transición \npmat <- matrix(data = c(1, 0, 0, 0, 0,  \n                        0.02, 0.95, 0.03, 0, 0, \n                        0.008, 0, 0.982, 0.01, 0,   \n                        0.02, 0, 0, 0.975, 0.005,\n                        0.01, 0, 0, 0, 0.99), \n               byrow = TRUE, nrow = 5, \n               dimnames = list(estados, estados))\n# CMTD\nplanificacion2 <- new(\"markovchain\", states = estados, \n                 byrow = TRUE, transitionMatrix = pmat, name = \"planificacion\")\n# Verificamos los datos introducidos\nplanificacion2## planificacion \n##  A  5 - dimensional discrete Markov Chain defined by the following states: \n##  0, 1, 2, 3, 4 \n##  The transition matrix  (by rows)  is defined as follows: \n##       0    1     2     3     4\n## 0 1.000 0.00 0.000 0.000 0.000\n## 1 0.020 0.95 0.030 0.000 0.000\n## 2 0.008 0.00 0.982 0.010 0.000\n## 3 0.020 0.00 0.000 0.975 0.005\n## 4 0.010 0.00 0.000 0.000 0.990\n# y describimos el sistema\nsummary(planificacion2)## planificacion  Markov chain that is composed by: \n## Closed classes: \n## 0 \n## Recurrent classes: \n## {0}\n## Transient classes: \n## {1},{2},{3},{4}\n## The Markov chain is not irreducible \n## The absorbing states are: 0\n# Tiempo esperado para llegar a estado 0\ntiempo.pp(planificacion2, \"0\")##        [,1]\n## 1  73.33333\n## 2  88.88889\n## 3  60.00000\n## 4 100.00000"},{"path":"cmtd.html","id":"AsinCMTD","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.5 Comportamiento a largo plazo","text":"En está sección estamos interesados en estudiar el comportamiento largo plazo o asintótico de una \\(CMTD\\), es decir, el comportamiento cuando \\(n \\rightarrow \\infty\\). La primera pregunta más obvia es si la distribución de \\(X_n\\) se aproxima algún límite finito cuando \\(n\\) tiende infinito.Si existe la distribución largo plazo de un proceso CMTD \\(\\{X_n, n \\\\mathbb{N}\\}\\), con espacio de estados \\(S =\\{1, 2,..., N\\}\\) y matriz de probabilidades de transición \\(P\\), la denominamos distribución límite o distribución en estado estacionario, y la denotamos por:\\[\\pi = [\\pi_1, \\pi_2,...,\\pi_N]\\] donde\\[\\pi_j = \\underset{n \\rightarrow \\infty}{lim} Pr[X_n = j], \\quad j \\S\\]La siguiente pregunta de interés, cuando dicha distribución existe, es si es única.\nEsta pregunta tiene sentido porque es razonable pensar que el límite pueda depender del estado inicial, o de la distribución inicial de la CMTD.La última pregunta se refiere la práctica: si hay una única distribución límite, ¿cómo podemos calcularla? Pues bien, aunque responder las dos primeras preguntas pueda ser más complejo, la respuesta esta pregunta es fácil, puesto que si esta distribución límite exite, entonces satisface la siguiente propiedad.Si existe la distribución límite de un proceso CMTD \\(\\{X_n, n \\\\mathbb{N}\\}\\), con espacio de estados \\(S =\\{1, 2,..., N\\}\\) y matriz de probabilidades de transición \\(P\\), entonces las probabilidades \\(\\pi_j\\) satisfacen la siguiente ecuación:\n\\[\\pi_j = \\sum_{=1}^N \\pi_i p_{ij}, \\quad \\forall j \\S,\\]\ndonde \\(p_{ij}\\) son las probabilidades de transición (en la matriz \\(P\\)). Esta propiedad en formato matricial da lugar la ecuación de balance o del estado estacionario, que viene dada por:\n\\[\\begin{equation}\n\\pi = \\pi*P, \\qquad \\text{ con } \n\\tag{2.9}\n\\end{equation}\\]\njunto con la restricción de normalización\n\\[\\sum_{j=1}^N \\pi_j = 1.\\]La función steadyStates() de la librería markovchain nos devuelve la distribución estacionaria de una \\(CMTD\\).Ejemplo 2.9  Analizamos el sistema presentado en el Ejemplo 2.1 para obtener la distribución estacionaria:Obtenemos de esta forma las probabilidades asintóticas de estar en cada uno de los estados. Vemos pues, que la larga lo más probable es que nos encontremos en el estado ‘c,’ y lo menos probable es estar en el estado ‘b.’Podemos encontrar procesos CMTD en los que existe distribución límite, pero aun así podemos resolver las ecuaciones de balance, junto con la restricción de normalización (Ecuación (2.9)). Supongamos que tenemos una distribución inicial de la CMTD dada por \\(\\{\\pi^*, \\S\\}\\). Si también la distribución de \\(X_1, \\ldots, X_n\\) permanece invariante para todos los \\(n\\), decimos que la distribución inicial es una distribución estacionaria. Definámoslo continuación.Definición 2.20  Una distribución de probabilidad\n\\[\\pi^* = [\\pi_1^*, \\pi_2^*,...,\\pi_N^*]\\]\nse dice que es estacionaria si\\[\\begin{eqnarray*}\nPr[X_0 = ] = \\pi_i^*,  1 \\leq \\leq N &\\Rightarrow& \\\\\n&\\Rightarrow& Pr[X_n = ] = \\pi_i^*, 1 \\leq \\leq N, \\text{ y } n \\geq 0.\n\\end{eqnarray*}\\]Las preguntas que previamente planteamos sobre la distribución límite (es decir, la existencia, la unicidad y el método de cálculo) pueden formularse también sobre la distribución estacionaria. Respondámoslas.Definición 2.21  La distribución \\(\\pi^* = [\\pi_1^*, \\pi_2^*,...,\\pi_N^*]\\) es una distribución estacionaria para la CMTD \\(\\{X_n, n \\\\mathbb{N}\\}\\), con espacio de estados \\(S =\\{1, 2,..., N\\}\\) y matriz de probabilidades de transición \\(P\\), si y solo si se cumple que:\\[\\pi^* = \\pi^* P, \\qquad \\text{ con } \\sum_{j=1}^N \\pi_j^* = 1, \\quad \\forall j \\S.\\]Por tanto, la distribución límite, cuando existe, es una distribución estacionaria. En caso de que tengamos más de una distribución límite (pues puede depender del estado inicial), por la Definición 2.21, cualquiera de dichas distribuciones límite será una distribución estacionaria.Veamos continuación una propiedad interesante, respecto estacionariedad, de la distribución del ratio de ocupación, esto es, de la proporción de tiempo que el proceso permanece en cada estado.Si existe la distribución de ocupación del proceso \\(\\{X_n, n \\\\mathbb{N}\\}\\) con espacio de estados \\(S =\\{1, 2,..., N\\}\\), dada por\n\\[\\hat{\\pi}_j=lim_{n \\rightarrow \\infty} \\frac{m_{ij}(n)}{n+1}, \\qquad \\text{ con } m_{ij}(n)=E[N_j(n)|X_0=]\\]\nentonces satisface las ecuaciones de balance sujetas la restricción de normalización, esto es,\n\\[\\hat{\\pi}_j = \\sum_{=1}^N \\hat{\\pi}_i p_{ij}, \\quad \\forall j \\S, \\qquad \\text{ y } \\sum_{j=1}^N \\hat{\\pi}_j=1.\\]Tenemos pues, que toda distribución que cumpla las ecuaciones de balance junto con las restricciones de normalización, será una distribución límte, también estacionaria o será la distribución de ocupación. Las preguntas relativas estas ecuaciones son: ¿siempre habrá una solución? ¿Será única? ¿Cuándo dicha solución se podrá interpretar como una distribución límite, estacionaria o de ocupación? Intentemos dar respuesta estas preguntas introduciendo algún concepto más referido los procesos \\(CMTD\\).Definición 2.22  Una \\(CMTD\\) \\(\\{X_n, n \\\\mathbb{N}\\}\\) con espacio de estados \\(S\\) se dice que es irreducible si para cada pareja de estados \\(\\) y \\(j\\) en \\(S\\), existe algún instante de tiempo \\(k>0\\) en el que es posible llegar \\(j\\) desde \\(\\), esto es,\\[Pr[X_k = j | X_0 = ] >0.\\]Una \\(CMTD\\) que es irreducible se denomina reducible.Podemos estudiar esta característica del proceso mediante un análisis descriptivo del mismo, con la función summary() de la librería markovchain, como ya vimos en el Ejemplo 2.2.La utilidad del concepto de irreducibilidad se justifica con los resultados que presentamos continuación, referidos la unicidad de la distribución estacionaria.Definición 2.23  Una CMTD de espacios finitos que sea irreducible tiene una única distribución estacionaria, es decir, sólo hay una solución normalizada de la ecuación de balance.Además, una CMTD de espacios finitos que sea irreducible tiene una única distribución de ocupación y es igual la distribución estacionaria.Introducimos ahora el concepto de periodicidad, que nos ayudará decidir cuando exista la distribución límite.Definición 2.24  Sea la \\(CMTD\\) \\(\\{X_n, n \\\\mathbb{N}\\}\\) con espacio de estados \\(S =\\{1, 2,..., N\\}\\) y \\(d\\) el entero más grande tal que para cualquier estado \\(\\S\\)\\[\\text{si } Pr[X_n = | X_0 = ] >0 \\Rightarrow n \\text{ es  múltiplo de } d,\\]Se dice entonces que dicha \\(CMTD\\) es periódica con periodo \\(d\\) si \\(d>1\\), y aperiódica si \\(d = 1\\).Así, una CMTD con periodo \\(d\\) puede volver su estado inicial sólo en los instantes \\(d, 2d, 3d, ...\\). En consecuencia, en las CMTD irreducibles es suficiente encontrar el periodo \\(d\\) para cualquier estado \\(\\S\\), puesto que será el mismo para todos los estados, con lo que encontrar el periodo en CMTD irreducibles será sencillo.Podemos estudiar la periocidad de un sistema mediante la función period() de la librería markovchain.En particular, si \\(p_{ii}>0\\) para cualquier \\(\\S\\) de una CMTD irreducible, entonces \\(d=1\\) y la CMTD será aperiódica.El resultado más relevante es que si tenemos una \\(CMTD\\) que es irreducible y aperiódica, entonces tiene una única distribución límite, que es la solución de la ecuación de balance y de normalización (Ecuación (2.9)).Además, esta será la distribución estacionaria de la CMTD y también la distribución de ocupación.La distribución límite/estacionaria de una CMTD reducible es única y depende del estado inicial de la cadena.Definición 2.25  Si \\(\\) es un estado recurrente y existe la distribución estacionaria, entonces el valor esperado del tiempo de recurrencia es el inverso de probabilidad de \\(\\) según la distribución estacionaria, es decir,\\[E[T_{jj}|X_0=j] = 1/\\pi_j.\\]Tenemos un resultado adicional sobre el comportamiento de los costes en el estado estacionario.Definición 2.26  Si \\(c()\\) es el coste esperado en el que incurrimos cuando visitamos el estado \\(\\S\\), de una CMTD irreducible con distribución de ocupación \\(\\pi\\), entonces el coste esperado por unidad largo plazo (en el estado estacionario) viene dado por:\n\\[g= \\sum_{j\\S} \\pi_j \\ c(j).\\]Ejemplo 2.10  Para el proceso descrito en la sección Telecomunicaciones, en el que los paquetes de datos que se generan en el instante (ranura) \\(n\\), \\(A_n \\sim Po(1)\\), se almacenaban en un buffer de capacidad \\(K=7\\), que se van eliminando conforme cierta estrategia. Interesados en el proceso \\(\\{X_n, n\\geq 0\\}\\) que describe el número de paquetes en el buffer al final de la n-ésima ranura, con espacio de estados \\(S=\\{0, 1,..., 7\\}\\) y matriz de probabilidades de transición:\\[P = \n\\begin{pmatrix}\n0.3679 & 0.3679 & 0.1839 & 0.0613 & 0.0153 & 0.0031 & 0.0005 & 0.0001\\\\\n0.3679 & 0.3679 & 0.1839 & 0.0613 & 0.0153 & 0.0031 & 0.0005 & 0.0001\\\\\n0.0 & 0.3679 & 0.3679 & 0.1839 & 0.0613 & 0.0153 & 0.0031 & 0.0006\\\\\n0.0 & 0.0 & 0.3679 & 0.3679 & 0.1839 & 0.0613 & 0.0153 & 0.0037\\\\\n0.0 & 0.0 & 0.0& 0.3679 & 0.3679 & 0.1839 & 0.0613 & 0.0190\\\\\n0.0 & 0.0 & 0.0& 0.0& 0.3679 & 0.3679 & 0.1839 & 0.0803\\\\\n0.0 & 0.0 & 0.0& 0.0& 0.0& 0.3679 & 0.3679 & 0.2642\\\\\n0.0 & 0.0 & 0.0& 0.0& 0.0& 0.0& 0.3679 & 0.6321\\\\\n\\end{pmatrix}\\]En esta situación estamos interesados en analizar las siguientes características del estado estacionario del proceso \\(X_n\\):Periodo del proceso.Fracción de tiempo en que el buffer estará lleno.Número esperado de paquetes que esperan en el buffer.Definamos la estructura del proceso para la librería markovchain, y pidamos la distribución estacionaria.Tenemos que la CMTD es irreducible, luego por los resultados teóricos tiene una única distribución estacionaria, que coincidirá con la distribución límite y con la distribución de los tiempos de ocupación.Que el buffer esté lleno significa que nos encontramos en el estado “7,” y al ser la distribución estacionaria la del tiempo de ocupación, tenemos que la fracción de tiempo en que el buffer está lleno es del 13.64%.El número esperado de paquetes en el buffer en el estado estacionario es un valor esperado calculado con la distribución límite/estacionaria, que al ser discreta se calcula fácilmente partir de las distribución estacionaria obtenida, esto es,Por lo tanto, largo plazo se espera que el buffer esté un poco más de la mitad de su capacidad.Ejemplo 2.11  Consideramos el proceso de Planificación de mano de obra, donde suponemos que la empresa tiene 70 empleados cuyo nivel cambia lo largo del tiempo. Supongamos que los gastos de nómina semanales por persona son de 400 dólares para el grado 1, 600 dólares para el grado 2, 800 dólares para grado 3, y $1000 para el grado 4. Estamos interesados en calcular los gastos semanales promedio por empleado.Aplicando el resultado en la Definición 2.26, comprobemos que el proceso es irreducible y procedamos aplicar la fórmula correspondiente, si es el caso.Por tanto, los gastos semanales promedio por trabajador son de 618.20 dólares, lo que multiplicado por el número de empleados (70) supone 43274 dólares.","code":"\n# Distribución estacionaria\nsteadyStates(proceso)##              a         b         c\n## [1,] 0.3703704 0.1111111 0.5185185\n# Estructura del proceso\n# Definimos estados\nestados <- as.character(0:7)\n# Matriz de transición \npmat <- matrix(data = c(0.3679, 0.3679, 0.1839, 0.0613, 0.0153, \n                        0.0031, 0.0005, 0.0001,\n0.3679, 0.3679, 0.1839, 0.0613, 0.0153, 0.0031, 0.0005, 0.0001,\n0.0, 0.3679, 0.3679, 0.1839, 0.0613, 0.0153, 0.0031, 0.0006,\n0.0, 0.0, 0.3679, 0.3679, 0.1839, 0.0613, 0.0153, 0.0037,\n0.0, 0.0, 0.0, 0.3679, 0.3679, 0.1839, 0.0613, 0.0190,\n0.0, 0.0, 0.0, 0.0, 0.3679, 0.3679, 0.1839, 0.0803,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.3679, 0.3679, 0.2642,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3679, 0.6321), \n               byrow = TRUE, nrow = 8, \n               dimnames = list(estados, estados))\n# CMTD\nteleco <- new(\"markovchain\", states = estados, \n                 byrow = TRUE, transitionMatrix = pmat, \n              name = \"Telecomunicaciones\")\n# Revisamos si la CMTD es irreducible\nsummary(teleco)## Telecomunicaciones  Markov chain that is composed by: \n## Closed classes: \n## 0 1 2 3 4 5 6 7 \n## Recurrent classes: \n## {0,1,2,3,4,5,6,7}\n## Transient classes: \n## NONE \n## The Markov chain is irreducible \n## The absorbing states are: NONE\n# Periodo del sistema\nperiod(teleco)## [1] 1\n# Distribución estacionaria\nsteadyStates(teleco)##               0         1         2         3         4         5         6         7\n## [1,] 0.06820411 0.1171835 0.1331324 0.1360701 0.1363485 0.1363554 0.1363497 0.1363562\nestados <- 0:7\ndistribucion <- steadyStates(teleco)\n# Valor esperado\nsum(estados*distribucion)## [1] 3.791421\n# ¿el proceso es irreducible?\nsummary(planificacion)## planificacion  Markov chain that is composed by: \n## Closed classes: \n## 1 2 3 4 \n## Recurrent classes: \n## {1,2,3,4}\n## Transient classes: \n## NONE \n## The Markov chain is irreducible \n## The absorbing states are: NONE\n# Vector de costes\ncostes <- c(400, 600, 800, 1000)\n# distribución estado estacionario\ndistribucion <- steadyStates(planificacion)\n# gastos esperados por semana\ncat(\"\\n Gastos semanales:\",sum(distribucion*costes))## \n##  Gastos semanales: 618.1818"},{"path":"cmtd.html","id":"estudio-de-caso","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.6 Estudio de caso","text":"Veamos por último, una aplicación completa del análisis de una CMTD.Sabemos que en cada idioma las frecuencias de transición entre vocales y consonantes son diferentes. partir de análisis recurrentes con textos de dos idiomas hemos identificado las probabilidades de transición entre vocales y consonantes en cada uno, estados=(vocal,consonante), y que vienen dadas continuación.\\[p1=\\left(\\begin{matrix}\n0.51 & 0.49 \\\\\n0.90 & 0.10\n\\end{matrix}\n\\right), \\qquad \np2=\\left(\\begin{matrix}\n0.25 & 0.75 \\\\\n0.30 & 0.70\n\\end{matrix}\n\\right)\\]Definimos primero los procesos para la librería markovchain partir de las probabilidades de transición.Verificamos que todos sus estados son recurrentes y la cadena es irreducible.Planteamos ahora una serie de preguntas responder.En cada idioma, ¿cuál es la probabilidad de que si un texto empieza por vocal, el siguiente carácter sea consonante?Calculamos pues, la distribución de los estados del sistema partiendo de una vocal, manualmente y con la función transitionProbability() o con conditionalDistribution(), que nos da la distribución condicional partiendo de un estado:Resulta que en el idioma1 la probabilidad de que si un texto empieza por vocal el siguiente carácter sea consonante es de 0.49 y en el idioma2 de 0.75.En cada idioma, ¿cuál es la probabilidad de que si un texto empieza por vocal, tras contar 10 caracteres más, encontremos una consonante?Utilizamos el resultado que se mostró en la Ecuación (2.5) para calcular la matriz de transición de \\(n\\) pasos.Las probabilidades ahora se reducen drásticamente, y en el idioma1 resulta de 0.0008, y en el idioma2 de 0.0563.¿Cuántos caracteres habremos de leer por término medio en un texto (en cada idioma) hasta encontrar la primera vocal?Nos están preguntando por el tiempo medio de primer paso. Resolvemos con la función meanFirstPassageTime().Tenemos así que el número medio de caracteres que esperamos encontrar en un texto hasta que aparezca por primera vez una vocal en el idioma 1 (partiendo de una consonante) es de 1.1, y en el idioma2 de 3.3 (tres veces más).partir de una consonante, ¿cuántos caracteres, por término medio, tardamos en encontrar otra consonante en cada idioma?Nos están pidiendo el tiempo medio de recurrencia, que calculamos con la función meanRecurrenceTime().Así, en el idioma1, desde la última consonante tendremos aproximadamente 3 caracteres (2.84) hasta encontrar otra consonante, mientras que en el idioma2 sólo 1.4 por término medio.¿Qué proporción de vocales y consonantes hay en cada idioma?Recurrimos la distribución estacionaria, que nos da la probabilidad estacionaria para cada uno de los estados posibles. La calculamos con la función steadyStates().Así pues, tenemos que en el idioma1 el 65% de los caracteres en un texto son vocales, mientras que en el idioma2 sólo un 29%, y la supremacía es de las consonantes, con un 71.4%.Simula un texto de 1000 caracteres para cada idioma, empezando por una vocal y estima con esas simulaciones las probabilidades de transición. Compara los resultados con las matrices iniciales.Para simular una CMTD recurrimos la función rmarkovchain().Para estimar las probabilidades de transición con ellas vamos seguir dos procedimientos: el artesanal través de una función que construiremos nosotros para calcular las frecuencias de salto entre vocales y consonantes, y con una función en la librería markovchain que específicamente nos proporciona esa estimación, y que es markovchainFit().Construyamos en primer lugar una función que nos proporcione las frecuencias de salto entre vocales y consonantes, través de las cuales vamos estimar las probabilidades de transición, con el fin de comprender bien cómo funcionaría la estimación más simple.Y utilizamos esta función para estimar las probabilidades de transición:Por cada 100 caracteres en un texto de cada idioma, ¿cuántos son vocales?Nos están preguntando por los tiempos de ocupación de las vocales en 100 transiciones.\nAplicamos la Ecuación (2.7) para calcular la matriz de ocupación tras 100 transiciones, y la función que definimos en la Sección Tiempos de ocupación. Para ello hemos de definir como CMTD ambos procesos, con la librería markovchain.Así pues, en el idioma 1, si el texto arranca en una vocal\n## Ejercicios {#ejer-u2}","code":"\nestados=c(\"vocal\",\"consonante\")\n# matriz de transición idioma1\np1=matrix(c(0.51,0.49,0.9,0.1),byrow = TRUE,ncol=2,dimnames=list(estados,estados))\n# proceso 1: idioma1\nidioma1=new(\"markovchain\",states=colnames(p1),byrow=TRUE,transitionMatrix=p1,name=\"idioma1\")\n# matriz de transición idioma2\np2=matrix(c(0.25,0.75,0.3,0.7),byrow = TRUE,ncol=2,dimnames=list(estados,estados))\n# proceso 2: idioma2\nidioma2=new(\"markovchain\",states=colnames(p2),byrow=TRUE,transitionMatrix=p2,name=\"idioma2\")\n\n# y lo mostramos en formato data.frame\nas(idioma1,\"data.frame\")##           t0         t1 prob\n## 1      vocal      vocal 0.51\n## 2      vocal consonante 0.49\n## 3 consonante      vocal 0.90\n## 4 consonante consonante 0.10\nas(idioma2,\"data.frame\")##           t0         t1 prob\n## 1      vocal      vocal 0.25\n## 2      vocal consonante 0.75\n## 3 consonante      vocal 0.30\n## 4 consonante consonante 0.70\ncat(\"Descripción idioma1\\n\")## Descripción idioma1\nsummary(idioma1)## idioma1  Markov chain that is composed by: \n## Closed classes: \n## vocal consonante \n## Recurrent classes: \n## {vocal,consonante}\n## Transient classes: \n## NONE \n## The Markov chain is irreducible \n## The absorbing states are: NONE\ncat(\"\\n Descripción idioma2\\n\")## \n##  Descripción idioma2\nsummary(idioma2)## idioma2  Markov chain that is composed by: \n## Closed classes: \n## vocal consonante \n## Recurrent classes: \n## {vocal,consonante}\n## Transient classes: \n## NONE \n## The Markov chain is irreducible \n## The absorbing states are: NONE\n#determinamos el estado inicial\nini=c(1,0)\n# y manualmente evaluamos los productos\nfinal1=ini %*% p1; final1##      vocal consonante\n## [1,]  0.51       0.49\nfinal2=ini %*% p2; final2##      vocal consonante\n## [1,]  0.25       0.75\n# o extraemos la distribución condicional partiendo del estado inicial \"vocal\":\nconditionalDistribution(idioma1,\"vocal\")##      vocal consonante \n##       0.51       0.49\nconditionalDistribution(idioma2,\"vocal\")##      vocal consonante \n##       0.25       0.75\n# o usamos la función de la librería markovchain\ntransitionProbability(idioma1,t0=\"vocal\",t1=\"consonante\")## [1] 0.49\ntransitionProbability(idioma2,t0=\"vocal\",t1=\"consonante\")## [1] 0.75\nini = c(1,0)\nfinal1.10 = ini %*% p1^10; final1.10##            vocal   consonante\n## [1,] 0.001190424 0.0007979227\nfinal2.10 = ini %*% p2^10; final2.10##             vocal consonante\n## [1,] 9.536743e-07 0.05631351\nmeanFirstPassageTime(idioma1)##               vocal consonante\n## vocal      0.000000   2.040816\n## consonante 1.111111   0.000000\nmeanFirstPassageTime(idioma1,\"vocal\")## consonante \n##   1.111111\nmeanFirstPassageTime(idioma2)##               vocal consonante\n## vocal      0.000000   1.333333\n## consonante 3.333333   0.000000\nmeanFirstPassageTime(idioma2,\"vocal\")## consonante \n##   3.333333\nmeanRecurrenceTime(idioma1)##      vocal consonante \n##   1.544444   2.836735\nmeanRecurrenceTime(idioma2)##      vocal consonante \n##        3.5        1.4\nsteadyStates(idioma1)##         vocal consonante\n## [1,] 0.647482   0.352518\nsteadyStates(idioma2)##          vocal consonante\n## [1,] 0.2857143  0.7142857\nset.seed(12)\nn=1000\nidioma1.sim=rmarkovchain(n,idioma1,t0=\"vocal\",include.t0=TRUE)\nidioma2.sim=rmarkovchain(n,idioma2,t0=\"vocal\",include.t0=TRUE)\nprobtransi.texto=function(texto){\n # calcula frecuencias de salto vocal/consonante en un texto\n  # el input (texto) es una sucesión de vocales/consonantes\nn=length(texto)\nn.estados=2\nestados=c(\"vocal\",\"consonante\")\n# definimos la matriz de probs. transición\npmat=matrix(0,ncol=n.estados,nrow=n.estados,dimnames=list(estados,estados))\nfor(i in 1:(n-1)){\n  if(texto[i]==\"vocal\" & texto[i+1]==\"vocal\")\n    pmat[1,1]=pmat[1,1]+1\n  else if (texto[i]==\"vocal\" & texto[i+1]==\"consonante\")\n    pmat[1,2]=pmat[1,2]+1  \n  else if (texto[i]==\"consonante\" & texto[i+1]==\"vocal\")\n    pmat[2,1]=pmat[2,1]+1\n  else if (texto[i]==\"consonante\" & texto[i+1]==\"consonante\")\n    pmat[2,2]=pmat[2,2]+1\n}\n# una vez tenemos las frecuencias de salto, las convertimos en probabilidades\n# las probabilidades en cada fila han de sumar 1\npmat[1,]=pmat[1,]/sum(pmat[1,])\npmat[2,]=pmat[2,]/sum(pmat[2,])\nreturn(pmat)\n}\nprobtransi.texto(idioma1.sim)##                vocal consonante\n## vocal      0.5215385  0.4784615\n## consonante 0.8885714  0.1114286\nprobtransi.texto(idioma2.sim)##                vocal consonante\n## vocal      0.2461538  0.7538462\n## consonante 0.2648649  0.7351351\ncat(\"\\n Estimación de p1 \\n\")## \n##  Estimación de p1\nmarkovchainFit(idioma1.sim,byrow=TRUE);p1## $estimate\n## MLE Fit \n##  A  2 - dimensional discrete Markov Chain defined by the following states: \n##  consonante, vocal \n##  The transition matrix  (by rows)  is defined as follows: \n##            consonante     vocal\n## consonante  0.1114286 0.8885714\n## vocal       0.4784615 0.5215385\n## \n## \n## $standardError\n##            consonante      vocal\n## consonante 0.01784285 0.05038626\n## vocal      0.02713106 0.02832608\n## \n## $confidenceLevel\n## [1] 0.95\n## \n## $lowerEndpointMatrix\n##            consonante     vocal\n## consonante 0.07645722 0.7898161\n## vocal      0.42528562 0.4660204\n## \n## $upperEndpointMatrix\n##            consonante     vocal\n## consonante  0.1463999 0.9873267\n## vocal       0.5316375 0.5770566\n## \n## $logLikelihood\n## [1] -572.2645##            vocal consonante\n## vocal       0.51       0.49\n## consonante  0.90       0.10\ncat(\"\\n Estimación de p2 \\n\")## \n##  Estimación de p2\nmarkovchainFit(idioma2.sim,byrow=TRUE);p2## $estimate\n## MLE Fit \n##  A  2 - dimensional discrete Markov Chain defined by the following states: \n##  consonante, vocal \n##  The transition matrix  (by rows)  is defined as follows: \n##            consonante     vocal\n## consonante  0.7351351 0.2648649\n## vocal       0.7538462 0.2461538\n## \n## \n## $standardError\n##            consonante      vocal\n## consonante 0.03151866 0.01891892\n## vocal      0.05384615 0.03076923\n## \n## $confidenceLevel\n## [1] 0.95\n## \n## $lowerEndpointMatrix\n##            consonante     vocal\n## consonante  0.6733597 0.2277845\n## vocal       0.6483096 0.1858472\n## \n## $upperEndpointMatrix\n##            consonante     vocal\n## consonante  0.7969106 0.3019453\n## vocal       0.8593827 0.3064604\n## \n## $logLikelihood\n## [1] -572.8805##            vocal consonante\n## vocal       0.25       0.75\n## consonante  0.30       0.70\nidioma1=new(\"markovchain\",states=colnames(p1),byrow=TRUE,transitionMatrix=p1,name=\"idioma1\")\nidioma2=new(\"markovchain\",states=colnames(p2),byrow=TRUE,transitionMatrix=p2,name=\"idioma2\")\n# número de transiciones (caracteres)\nn=100\nmocupa.proceso(idioma1,100)##               vocal consonante\n## vocal      2.040816   1.960784\n## consonante 9.999761   1.111111\nmocupa.proceso(idioma2,100)##               vocal consonante\n## vocal      1.333333   4.000000\n## consonante 1.428571   3.333333"},{"path":"cmtd.html","id":"básicos-1","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.6.1 Básicos","text":"Ejercicio B2.1. Para el proceso Meteorologia se desea conocer cuál es el tiempo estimado para tener un día lluvioso si hoy tenemos un día soleado.Ejercicio B2.2. Para el proceso Mercado de valores se desea conocer cuál es el tiempo estimado en conseguir que las acciones alcancen los valores \\(8, 9, 10\\) partiendo de un valor inicial de \\(5\\).Ejercicio B2.3. Consideramos el proceso Mercado de valores. Supongamos que el gerente financiero ha comprado 100 acciones 5 dólares, y está interesado en conocer cuál es el beneficio neto esperado de su inversión en 5 días.Ejercicio B2.4. En una boutique de café se cambian semanalmente los escaparates, promocionando tres tipos de café , B y C en función de la demanda que registran. Según ello, la promoción de los tres tipos cambia de una semana otra de acuerdo la siguiente matriz de transición:\\[P = \n\\begin{pmatrix}\n0.1 & 0.3 & 0.4\\\\\n0.1 & 0.5 & 0.4\\\\\n0.3 & 0.2 & 0.5\\\\\n\\end{pmatrix}\\]Si en la semana 1 se expone el tipo en el escaparate, ¿cuál es la probabilidad de que en la semana 10 se esté promocionando cualquiera de las tres marcas?Ejercicio B2.5. Consideramos el proceso descrito en la sección Telecomunicaciones. Asumimos que en el estado inicial el buffer está lleno y deseamos conocer el número esperado de paquetes en el buffer en los instantes \\(n =1, 2, 5\\) y \\(10\\), asumiendo que el tamaño del buffer es 10 y que el número de paquetes que llegan en un instante es una variable aleatoria \\(Bi(5, 0.2).\\)Ejercicio B2.6. Consideramos el proceso descrito en la sección Planificación de mano de obra. Supongamos que la empresa tiene 100 empleados en la semana 1, distribuidos como sigue: 50 en el nivel 1, 25 en el grado 2, 15 en el grado 3, y 10 en el grado 4. Si cada empleado tiene un comportamiento independiente respecto del resto ¿cuál es el número esperado de empleados en cada grado al principio de la semana 4?Ejercicio B2.7. Consideramos el proceso descrito en la sección Problema de inventario. Estamos interesados en conocer cuál es la proporción de semanas en que el inventario estará lleno durante el proximo año, si empezamos con un inventario de 5 PCs?Ejercicio B2.8. La secuencia de consonantes y vocales en el lenguaje humano se puede modelizar mediante una \\(CMTD\\) dado que después de una vocal siempre le sigue una consonante con probabilidad 0.49 y una vocal con probabilidad 0.51. Después de una consonante hay otra consonante con probabilidad 0.1. Codificamos un texto completo con una secuencia de ceros (vocal) y unos (consonantes). Obtén la matriz de transición para este proceso. Si el texto comienza con una consonante, ¿qué tipo de elemento será el que aparezca en la quinta posición de la secuencia? ¿Qué porcentaje de vocales y consonantes encontraremos en un texto de 2000 letras?Ejercicio B2.9 Considera el proceso descrito en la sección Fiabilidad de máquinas, con dos máquinas. Supón que ambas máquinas están operativas al principio del día 0. Calcula la probabilidad de que el número de máquinas operativas al principio de los próximos tres días sea 2, 1 y 2, en ese orden.Ejercicio B2.10. Calcula la matriz de ocupación \\(M(10)\\), la distribución límite y la estacionaria, para un proceso CMTD con matriz de transición dada por:\n\\[P=\\begin{pmatrix}\n0.1 & 0.3 & 0.2 & 0.4 \\\\\n0.1 & 0.3 & 0.4 & 0.2 \\\\\n0.3 & 0.1 & 0.1 & 0.5 \\\\\n0.15 & 0.25 & 0.35 & 0.25 \n\\end{pmatrix}\\]","code":""},{"path":"cmtd.html","id":"avanzados-1","chapter":"Unidad 2 Cadenas de Markov de Tiempo Discreto","heading":"2.6.2 Avanzados","text":"Ejercicio A2.1. Los artículos llegan un taller mecánico de forma determinista un ritmo de uno por minuto. Cada artículo se comprueba antes de cargarlo en la máquina. Un artículo es adecuado con probabilidad \\(p\\) y defectuoso con una probabilidad \\(1-p\\). Si un artículo es defectuoso, se descarta; en caso contrario, se carga en la máquina. La máquina tarda exactamente 1 minuto en procesar el artículo, tras lo cual está lista para procesar el siguiente. Consideramos la variable aleatoria \\(X_n\\) que toma el valor \\(0\\) si la máquina está inactiva al principio del n-ésimo minuto y 1 si está iniciando el proceso.Obtén la matriz de transición de este proceso.Si \\(p = 0.98\\), ¿cuál es la proporción de tiempo en que la máquina está cargando un artículo durante las próximas ocho horas?¿Cuántas horas tendrán que pasar para que la máquina descarte un artículo cuando el primero se descarta?Supongamos ahora que la máquina puede procesar dos artículos simultáneamente. Sin embargo, tarda 2 minutos en completar el procesamiento. Delante de la máquina hay un contenedor en el que se pueden almacenar dos artículos defectuosos. En cuanto hay dos artículos en la bandeja, se cargan en la máquina y ésta empieza procesarlos.Obtén la matriz de transición de este proceso.¿Cuál es la proporción de tiempo en que la máquina carga artículos durante las próximas ocho horas?¿Cuántas horas tendrán que pasar para que la máquina descarte dos artículos cuando los dos primeros son defectuosos?Ejercicio A2.2. Un vendedor vive en la ciudad “” y es responsable de la venta de su producto en las ciudades “,” “b” y ‘c.’ Cada semana tiene que visitar una ciudad diferente. Cuando está en su ciudad natal, le da igual la ciudad que visite continuación, así que lanza una moneda y si sale cara va “b” y si sale cruz va “c.” Sin embargo, después de pasar una semana fuera de casa tiene una ligera preferencia por volver casa, así que cuando está en las ciudades ‘b’ o ‘c’ lanza dos monedas. Si salen dos caras, se va la otra ciudad; de lo contrario va ‘.’ Las sucesivas ciudades que visita forman una cadena de Markov con un espacio de estados \\(S = \\{, b, c\\}\\) en la que la variable aleatoria \\(X_n\\) es igual ‘,’ ‘b’ o ‘c’ según su ubicación durante la semana \\(n\\). Obtén la matriz de transición de este proceso.Empezando en su ciudad natal, ¿en qué ciudad se encontrará dentro de seis semanas?¿Cuál es la proporción de tiempo en que el vendedor se encontrará fuera de casa durante los próximos seis meses?Si inicialmente está en la ciudad ‘,’ ¿cuántas semanas tendrán que pasar para que visite la ciudad ‘c?’Si el vendedor obtiene un beneficio de 1200 euros cuando pasa una semana en la ciudad ‘,’ de 1200 euros cuando está en ‘b,’ y de 1250 cuando está en ‘c,’ ¿cuál será el beneficio esperado después de 12 semanas si comienza en su ciudad natal?¿Cuál será el beneficio esperado después de 12 semanas si desconocemos la ciudad de partida pero sabemos que hay una probabilidad de 0.5 que sea ‘,’ 0.3 de que sea ‘b,’ y 0.2 de que sea ‘c?’Ejercicio A2.3. Se lleva cabo un análisis de mercado para conocer las preferencias de compras de coches en formato “renting,” según el cual cada año se renueva el coche cada cliente del servicio en el mes de enero. La empresa está interesada en conocer si los clientes cambian el estilo de vehículo entre las tres opciones posibles (“sedan,” “station wagon,” y “convertible”) de un año al siguiente. Para estudiar este proceso se toman los datos de cambio de vehículo del último mes de enero:Este sistema se puede modelizar según una \\(CMTD\\) con espacio de estados \\(S = \\{s, w, c\\}\\).Obtén la matriz de transición asociada este proceso.¿Cuál es la probabilidad de que un cliente mantenga el mismo tipo de vehículo dentro de tres años? ¿y de cinco?¿Cuál es el tiempo esperado de permanencia con el mismo tipo de vehículo en los próximos 10 años?¿Cuál es el tiempo esperado hasta el primer cambio para cualquiera de los tipos considerados?Si un “sedan” proporciona un beneficio anual de 1200 euros, el “station wagon” de 1500, y el “convertible” de 2500 euros, ¿cuál es el beneficio promedio esperado para un año? ¿y para 5 años?Ejercicio A2.4. Un proceso de fabricación consiste en dos etapas consecutivas mediante el esquema siguiente:En la etapa 1, el 20% de las piezas son devueltas para su reelaboración, el 10% son desechadas, y el 70% restante pasan la etapa 2.En la etapa 2, el 5% de las piezas deben ser devueltas la etapa 1, el 10% deben ser reelaboradas, el 5% son desechadas, y el 80% restantes se consideran adecuadas para la venta.Considerando todos los estados del proceso (e1 = etapa 1; e2 = etapa 2; d = desechado; v = venta) construye la matriz de transición correspondiente este proceso.La estructura de costes del proceso viene dada por:El coste del material que va entrar entra en la etapa 1 es de 150 euros.Cada parte que es procesada en la etapa 1 incurre en un coste de 200 euros.Cada parte que es procesada en la etapa 2 incurre en un coste de 300 euros.Cada parte que es rechazada en el etapa 1 pero si es rechazada en l etapa 2 incurre en un coste de 850 euros.El material que es desechado debe someterse un proceso de eliminación especial con u coste de 50 euros por parte.El sistema es capaz de tratar suficiente material para generar 100 partes al cabo de un día (aptas para la venta o desechadas).Plantea un algoritmo de simulación que permita responder cuál es el coste medio del proceso de fabricación para los próximos 15 días. ¿Y la variabilidad estimada de dicho coste?Si la empresa quiere asegurar un beneficio neto del 5%, ¿qué precio debe vender las piezas aptas para asegurar dicho beneficio de acuerdo al coste medio estimado del proceso? ¿Cuál sería el rango de venta teniendo en cuenta las fluctuaciones del coste medio?Ejercicio A2.5. Se lanza un misil al que se le envía una secuencia de señales de corrección de rumbo cuando es necesario. Supongamos que el sistema tiene cuatro estados que se etiquetan como sigue:Estado 0: en rumbo, sin necesidad de correcciones.Estado 1: correcciones mínimas.Estado 2: correcciones mayores.Estado 3: desviación controlable que hace necesaria la autodestrucción del mísil.Sea \\(X_n\\) que representa el estado del sistema después de la n-ésima corrección, de forma que si el mísil está en curso en el instante \\(n\\) se mantendrá en curso durante todo el vuelo; si necesita una corrección mímima, entonces con probabilidad 0.5 será necesaria ninguna corrección posterior, con probabilidad 0.25 será necesaria una nueva corrección menor, y con probabilidad 0.25 será necesaria una corrección mayor. Si en el instante \\(n\\) necesitamos una corrección mayor, con probabilidad 0.5 necesitaremos una corrección menor continuación, con probabilidad 0.25 necesitaremos otra corrección mayor, y con probabilidad 0.25 deberemos abortar la misión.¿Cuál es la matriz de transición para este proceso?Si un mísil necesita una corrección menor al inicio del lanzamiento, ¿cuál será su situación después de 3 correcciones?El mísil gasta 50000 libras de combustible en el lanzamiento, 1000 libras cuando una corrección menor es necesaria, y 5000 cuando una corrección mayor es necesaria. Simula el proceso para tratar de responder estas preguntas:¿Cuál será el consumo medio de combustible después de 4 correcciones?¿Y si lanzamos 6 cohetes la vez?Ejercicio A2.6. Al comienzo de cada semana, el estado de una máquina se determina midiendo la cantidad de corriente eléctrica que utiliza. En función de su lectura de amperaje, la máquina se clasifica en uno de los cuatro estados siguientes: bajo, medio, alto, fallido. Una máquina en estado bajo tiene una probabilidad de 0.05, 0.03 y 0.02 de estar en el estado medio, alto o fallido, respectivamente, al comienzo de la siguiente semana. Una máquina en estado medio tiene una probabilidad de 0.09 y 0.06 de estar en estado alta o fallida, respectivamente, al inicio de la siguiente semana; puede, por sí sola, pasar al estado bajo. Una máquina en estado alto tiene una probabilidad de 0.1 de estar en el estado fallido al comienzo de la siguiente semana; puede, por sí misma, pasar al estado bajo o medio. Si una máquina se encuentra en estado de fallo al comienzo de la semana, se inicia inmediatamente la reparación de la máquina para que (con probabilidad 1) esté en el estado bajo al comienzo de la semana siguiente.Modeliza este proceso como una \\(CMTD\\) y obtén la correspondiente matriz de transición.Si una máquina nueva siempre comienza en el estado bajo, ¿cuál es la probabilidad de que la máquina esté en estado de fallo tras tres semanas?¿Cuál es la probabilidad de que una máquina nueva tenga al menos un fallo dentro de tres semanas?En promedio, ¿cuántas semanas al año estará trabajando la máquina?Cada semana que la máquina está en estado bajo, se obtiene un beneficio de 1.000 dólares; cada semana que la máquina está en el estado medio, se obtiene un beneficio de 500 dólares; cada semana que la máquina está en estado alto, se obtiene un beneficio de 400 dólares; y la semana en la que se fija un fallo, se incurre en un coste de 700 dólares.¿Cuál es el beneficio semanal medio largo plazo obtenido por la máquina?Se ha sugerido cambiar la política de mantenimiento de la máquina. Si al comienzo de una semana la máquina está en el estado alto, la máquina se deja fuera de servicio y es reparada para que al inicio de la siguiente semana vuelva estar en el estado bajo. Cuando se realiza una reparación se incurre en un coste de 600 euros.¿Merece la pena esta nueva política de mantenimiento?Ejercicio A2.7. Nos interesa el traslado de planta de los pacientes dentro de un hospital. efectos de nuestro análisis, consideraremos que el hospital tiene tres tipos diferentes de plantas: habitaciones de “cuidados generales,” habitaciones de “cuidados especiales” y “cuidados intensivos.” Basándonos en datos anteriores, el 60% de los pacientes que llegan, ingresan inicialmente en la categoría de “cuidados generales,” el 30% en la de “cuidados especiales” y el 10% en la de “cuidados intensivos.” Un paciente de “cuidados generales” tiene un 55% de posibilidades de ser dado de alta sano al día siguiente, un 30% de permanecer en la planta de “cuidados generales,” y un 15% de ser trasladado la planta de “cuidados especiales.” Un paciente de “cuidados especiales” tiene un 10% de posibilidades de ser dado de alta al día siguiente, un 20% de ser trasladado “cuidados generales,” un 15% de pasar “cuidados intensivos.” Un paciente de “cuidados intensivos” nunca es dado de alta, hasta que muestra mejoría. Las probabilidades de que el paciente sea trasladado “cuidados generales,” “cuidados especiales” o que permanezca en “cuidados intensivos” son del 5%, el 30% o el 55%, respectivamente.Modeliza este sistema como una \\(CMTD\\) y obtén la correspondiente matriz de transición.¿Cuál es la probabilidad de que un paciente ingresado en la sala de cuidados intensivos salga sano del hospital?¿Cuál es el número esperado de días que un paciente, ingresado en cuidados intensivos pasará en la UCI?¿Cuál es la duración prevista de la estancia de un paciente ingresado en el hospital como paciente de cuidados generales?Durante un día normal, ingresan en el hospital 100 pacientes. ¿Cuál es el número medio de pacientes en la UCI?Ejercicio A2.8. La fabricación de un determinado tipo de placa electrónica consta de cuatro pasos: preparación, montaje, inserción y soldadura. Después de la etapa de montaje, el 5% de las piezas deben ser retiradas; después de la etapa de inserción, el 20% de las piezas son retiradas; y después de la etapa de soldadura, el 30% de las piezas deben ser devueltas la inserción y el 10% debe desecharse. Suponemos que cuando una pieza se devuelve una etapa de procesamiento, es tratada como cualquier otra pieza que entra en esa etapa.Modeliza este sistema como una \\(CMTD\\) y obtén la correspondiente matriz de transición.Si un lote de 100 placas comienza este proceso de fabricación, ¿cuántas se espera que acaben desechadas?¿Con cuántas placas deberíamos empezar si el objetivo es que el número esperado de placas que terminen siendo aceptadas sea igual 100?¿Con cuántas placas deberíamos empezar si queremos estar seguros al 90% de que terminamos con un lote de 100 placas?Cada vez que una placa pasa por una etapa de procesamiento, los costes directos de mano de obra y material son de 10 euros para la preparación, 15 euros para el montaje, 25 euros para la inserción y 20 euros para la soldadura. La materia prima cuesta 8 euros, y una placa desechada devuelve 2 euros. La tasa media de gastos generales es de 1.000.000 de euros al año, lo que incluye valores de recuperación de capital. El ritmo de procesamiento medio es de 5.000 placas por semana.Queremos fijar un precio por placa para que los ingresos previstos sean un 25% superiores los costes previstos. ¿En qué valor debemos fijar el precio?Ejercicio A2.9. Dentro de un área de mercado determinada hay dos marcas de jabón que la mayoría de la gente utiliza, el “superjabón” y el “jabón barato,” y el mercado actual se divide por igual entre las dos marcas. Una empresa está pensando en introducir una tercera marca llamada “jabón extra limpio,” y ha realizado algunos estudios iniciales sobre las condiciones del mercado. Sus estimaciones de las pautas de compra semanales son las siguientes: si un cliente compra superjabón esta semana, hay un 75% de posibilidades de que la próxima semana vuelva comprarlo, un 10% de probabilidad de que use el jabón extra limpio y un 15% de probabilidad de que use el jabón barato. Si un cliente compra el jabón extra limpio esta semana, hay un 50% de probabilidades de que cambie, y si lo hace, siempre será al superjabón. Si un cliente compra jabón barato esta semana, es igual de probable que la próxima semana el cliente compre cualquiera de las tres marcas.Asumiendo que se cumplen las condiciones de Markov, ¿cuál es la mariz de transición para este proceso?¿Cuál es la cuota de mercado largo plazo del nuevo jabón?¿Cuál será la cuota de mercado del nuevo jabón dos semanas después de su introducción?El mercado consta de aproximadamente un millón de clientes cada semana. Cada compra de superjabón produce un beneficio de 15 céntimos; una compra de jabón barato produce un beneficio de 10 céntimos; y una compra del extra limpio produce un beneficio de 25 céntimos. Supongamos que el mercado se encuentra en estado estacionario con la misma distribución entre los dos productos ya comercializados. La campaña publicitaria inicial para introducir la nueva marca fue de 100.000 dólares.¿Cuántas semanas pasarán hasta que se recuperen los 100.000 dólares de los ingresos añadidos del nuevo producto?La empresa considera que con estas tres marcas, una campaña publicitaria de 30.000 dólares por semana aumentará el mercado total semanal en un cuarto de millón de clientes? ¿Merece la pena la campaña? (Utiliza un criterio de media largo plazo).Ejercicio A2.10. Considera una \\(CMTD\\) con espacio de estados \\(S=\\{, b, c\\}\\) y con matriz de transición:\\[P = \n\\begin{pmatrix}\n0.3 & 0.5 & 0.2\\\\\n0.1 & 0.2 & 0.7\\\\\n0.8 & 0.0 & 0.2\\\\\n\\end{pmatrix}\\]Cada visita al ‘estado ’ produce un beneficio de 5 dólares, cada visita al ‘estado b’ produce un beneficio de 10 dólares, y cada visita al ‘estado c’ produce un beneficio de 12 dólares.Escribir un algoritmo que simule la cadena de Markov para poder estimar el beneficio esperado por paso, asumiendo que la cadena siempre comienza en el ‘estado .’Realizar 10 repeticiones del proceso con 25 pasos en cada una y obtener el valor medio del beneficio y rango para las 10 réplicas.Realizar 10 repeticiones con 1000 pasos en cada una y obtener el valor medio del beneficio y rango para las 10 réplicas.Comparar las estimaciones y los rangos de los dos escenarios propuestos.","code":""},{"path":"poissonprocess.html","id":"poissonprocess","chapter":"Unidad 3 Proceso de Poisson","heading":"Unidad 3 Proceso de Poisson","text":"En esta unidad se presentan se presentan los Procesos de Poisson que son la base de muchos de los sistemas de Cadenas de Markov de Tiempo Continuo que estudiaremos con más detalle más adelante. Este tipo de procesos estocásticos se utilizan para modelizar el número de ocurrencias de un evento en un periodo de tiempo determinado y nos sirven para modelizar\nsituaciones bastante comunes como las llegadas de clientes una cola, el número de fallos que se producen en una cadena de producción, el número de reclamaciones que recibe una compañía de seguros, el número de accidentes de tráfico en una carretera, el número de pedidos en un sistema de inventarios,…Veamos continuación un ejemplo sencillo de utilización de este tipo de procesos.Ejemplo 3.1  Estamos interesados en estudiar la dinámica de la llegada de llamadas telefónicas un centro de llamadas. Para describir este proceso consideremos una colección de variables aleatorias \\(\\{N_t; t ≥ 0\\}\\), donde cada variable aleatoria \\(N_t\\), para un \\(t\\) dado, denota el número acumulado de llamadas que llegan al centro hasta el momento \\(t\\). Como estas llamadas registran un recuento, el espacio de estado es el conjunto de números naturales con el cero, \\(S= \\{0,1,2,...\\}\\). En otras palabras, la llegada de llamadas telefónicas puede modelarse como un proceso estocástico de tiempos (parámetros) continuos con un espacio de estados contable.","code":""},{"path":"poissonprocess.html","id":"definición-y-propiedades","chapter":"Unidad 3 Proceso de Poisson","heading":"3.1 Definición y propiedades","text":"Definición 3.1  Sea un proceso estocástico de parámetro continuo \\(\\{N_t; t \\geq 0\\}\\) con \\(N_0 = 0\\) y espacio de estados el de los enteros negativos, \\(S=\\{0,1,2,...\\}\\). Dicho proceso se denomina Proceso de Poisson (PP) de tasa \\(\\lambda\\) si:\\(P(N_t = k) = e^{\\lambda t}(\\lambda t)^k/k!\\) para \\(k=\\{0,1,2,...\\}, t \\geq 0\\), esto es, \\(N_t \\sim Po(\\lambda)\\).El evento \\(\\{N_{s+u} - N_s = \\}\\) es independiente del evento \\(\\{N_t = j\\}\\) si \\(t<s\\) (propiedad e Markov).La probabilidad \\(P(N_{s+u} - N_s = )\\) sólo depende del valor de \\(u\\), y \\(N_{s+u} - N_s \\sim P(\\lambda u)\\).La primera condición de la definición es la característica que define el proceso de Poisson y es la razón del nombre del proceso, ya que establece que el proceso se distribuye según una distribución de Poisson. La segunda condición indica que un proceso de Poisson tiene incrementos independientes. En otras palabras, lo que ocurre en un periodo de tiempo es independiente de lo que ocurre en otro, siempre que se solapen los dos periodos. La tercera condición implica que un proceso de Poisson tiene incrementos estacionarios, es decir, lo que sucede en un periodo de tiempo sólo depende de la amplitud de dicho periodo, y de cuándo empezó.Usando la definición de una variable aleatoria Poisson, es claro que\\[E(N_t) = \\lambda t\\]de forma que \\(\\lambda\\) proporciona la tasa media de llegadas por unidad de tiempo para un proceso de llegadas que está descrito por un PP con tasa \\(\\lambda\\).Ejemplo 3.2  Supongamos que \\(N(t)\\) representa el número de operaciones que se realizan en un quirófano de un hospital durante un intervalo de tiempo de amplitud \\(t\\), y que \\(\\{N(t), t\\geq0\\}\\) es un PP de tasa 24 operaciones por día.¿Cuál es el número medio de operaciones que se realizan en un turno de 8 horas?Puesto que un turno de 8 horas representa \\(8/24=1/3\\) de un día, y \\(N(t)\\sim Po(24)\\), tendremos que \\(N(1/3)\\sim Po(24/3)\\), luego se esperan en torno \\(24/3=8\\) operaciones por turno.¿Cuál es la probabilidad de que haya operaciones entre las 12 de la noche y la 1 de la madrugada?Igual que antes, el número de operaciones que se realizan en una franja de una hora tendrá una distribución \\(N(1/24) \\sim Po(24/24)\\), luego la probabilidad de que haya operaciones en esa franja será de¿Cuál es la probabilidad de que haya tres operaciones entre las 8 .m. y las 12 del mediodía, y 4 operaciones entre las 12 del mediodía y las 5 p.m.?Si asumimos que \\(t=0\\) se corresponde con las 8,.m., las 12 del mediodía han transcurrido 4 horas, y hasta las 5 p.m. han transcurrido 9 horas. La probabilidad que nos piden se refiere una probabilidad conjunta de dos franjas horarias que se solapan, por lo que se trata de sucesos independientes y la probabilidad conjunta es el producto de las probabilidades individuales:\n\\[Pr[N(4/24)-N(0)=3, N(9/24)-N(4/24)=4]=Pr[N(4/24)-N(0)=3] \\cdot Pr[N(9/24)-N(4/24)=4] \\]\nahora por la estacionariedad de los incrementos, tendremos que esa probabilidad la podemos escribir como\n\\[Pr[N(4/24)=3]\\cdot Pr[N(5/24)=4]\\]\ncon las distribuciones \\(Po(24 \\cdot 4/24)\\) y \\(Po(24 \\cdot 5/24)\\).Debido las propiedades de incrementos independientes y estacionariedad de un proceso de Poisson, la distribución de los tiempos entre llegadas puede determinarse fácilmente.Sea \\(T_n\\) una v.. que identifica el tiempo que transcurre entre dos llegadas consecutivas \\(n\\) y \\(n-1\\). La probabilidad de que se produzca ninguna llegada en un intervalo de tiempo de amplitud \\(t\\), implica que \\(T_n>t\\) y viene dada por:\\[Pr(T_n > t)=Pr(N_t = 0) = e^{\\lambda t}.\\]\nPor lo tanto, \\(P(T_n \\leq 0) = 1 - P(T_n > 0) = 1 - e^{-\\lambda t}\\) para \\(t ≥ 0\\), que es la función de distribución Exponencial.Concluimos pues, que si las llegadas un sistema se producen según un PP de tasa \\(\\lambda\\), entonces los tiempos entre llegadas responden una distribución exponencial de parámetro \\(\\lambda\\).Definición 3.2  Para un PP con tasa \\(\\lambda\\), la distribución del tiempo entre dos llegadas consecutivas es exponencial de media \\(1/\\lambda\\).Si \\(\\{N_t; t \\geq 0\\}\\) es un PP que describe el número de llegadas que acontecen durante un periodo de tiempo de amplitud \\(t \\geq 0\\), entonces los tiempos entre llegadas consecutivas \\(n-1\\) y \\(n\\), \\(\\{T_n, n\\geq 1\\}\\), constituyen una secuencia de variables aleatorias iid (independientes e idénticamente distribuidas) \\(Exp(\\lambda)\\).Lo contrario también es cierto, es decir, un proceso de llegadas con tiempos entre llegadas que son exponenciales, es un PP.Propiedad. Si \\(S_n\\) denota el tiempo que transcurre hasta la n-ésima llegada en un PP de tasa \\(\\lambda\\), entonces \\(S_n\\) se distribuye según una distribución Erlang \\(Erl(n,\\lambda)\\), con función de densidad dada por:\\[f(s) = \\frac{\\lambda(\\lambda s)^{k-1}e^{-\\lambda s}}{(k-1)!}, \\quad \\text{para } s \\geq 0\\]\nEsta propiedad es consecuencia de que la distribución Erlang \\(Erl(n,\\lambda)\\) surge de la suma de \\(n\\) v.. iid \\(Exp(\\lambda)\\).","code":"\n# probabilidad de que no haya operaciones en 1 hora\n# distribución Po(1)\nlambda=24\nfranja=1/24\nppois(0,lambda*franja)## [1] 0.3678794\n(ppois(3,4)-ppois(2,4))*(ppois(4,5)-ppois(3,5))## [1] 0.0342805"},{"path":"poissonprocess.html","id":"extensiones_pp","chapter":"Unidad 3 Proceso de Poisson","heading":"3.2 Extensiones","text":"","code":""},{"path":"poissonprocess.html","id":"superposicion_pp","chapter":"Unidad 3 Proceso de Poisson","heading":"3.2.1 Superposición","text":"Ejemplo 3.3  Consideremos una autovía que tiene dos puntos de acceso y B y sólo uno C de salida. Asumimos que los coches acceden la autovía por el punto según un PP con tasa de 8 vehículos por minuto, y también los que acceden por el punto B según un PP con tasa de 6 vehículos por minuto. Queremos estudiar cómo se producen las salidas de la autovía.Definición 3.3  Sean \\(\\{N_t; t \\geq 0\\}\\) y \\(\\{M_t; t \\geq 0\\}\\) dos PP independientes con tasas \\(\\lambda_1\\) y \\(\\lambda_2\\) respectivamente. Entonces el proceso \\(\\{Y_t = N_t + M_t, t \\geq 0\\}\\) es un PP con tasa \\(\\lambda_1 + \\lambda_2\\), que se obtiene de la superposición de los dos PP.La solución al Ejemplo 3.3 para el proceso de salidas de la autovía viene dada por la superposición de los dos procesos de entradas, \\(C=+B\\), de modo que responderá un PP de tasa \\(14=8+6\\).","code":""},{"path":"poissonprocess.html","id":"adelgazamiento_pp","chapter":"Unidad 3 Proceso de Poisson","heading":"3.2.2 Adelgazamiento con mixtura","text":"Ejemplo 3.4  Consideramos el tráfico que llega una bifurcación, que sigue un PP con una tasa de 2 coches por minuto. Además, hay un 30% de posibilidades de que los coches giren la izquierda y un 70% de que giren la derecha. Queremos estudiar el proceso que describe el número de coches que giran la izquierda y de los que giran la derecha.Definición 3.4  Sea \\(\\{N_t; t \\geq 0\\}\\) un PP con tasa \\(\\lambda\\) y sea \\(\\{X1,X2,...\\}\\) una secuencia de variables aleatorias iid Bernoulli \\(Ber(p)\\), independientes del proceso de Poisson. Sea \\(M = \\{M_t ;t \\geq 0 \\}\\) un nuevo proceso que registra las llegadas de \\(\\{N_t; t \\geq 0\\}\\) con probabilidad \\(p\\), esto es, si \\(X_n=1\\) la llegada n-ésima se registra, y si \\(X_n=0\\) se registra. Entonces el proceso \\(\\{M_t; t \\geq 0\\}\\) resultante, que supone un “adelgazamiento” o encogimiento del proceso original \\(N_t\\), es un PP con tasa \\(\\lambda p\\).Aplicando este resultado al Ejemplo 3.4, y suponiendo que todos los coches actúan de forma independiente, el flujo de giros por la bifurcación de la izquierda forma un PP con una tasa de \\(0.6=0.3\\cdot 2\\) por minuto, y el flujo de giros por la bifurcación de la derecha forma un PP con una tasa de \\(1.4=0.7\\cdot 2\\) coches por minuto.","code":""},{"path":"poissonprocess.html","id":"composicion_pp","chapter":"Unidad 3 Proceso de Poisson","heading":"3.2.3 Composición","text":"En un PP los eventos o llegadas suceden de uno en uno. En otras ocasiones, las llegadas o eventos se producen por lotes y los tamaños de los lotes forman una secuencia de variables aleatorias positivas independientes e idénticamente distribuidas. Un ejemplo lo tenemos en la llegada de clientes un restaurante, que se realiza normalmente en grupos de tamaño variable. Si definimos por \\(N_t\\) el número total de llegadas en el periodo \\((0,t]\\), este se puede modelizar como un PP, pero sí como un “PP compuesto.”Ejemplo 3.5  Consideramos la llegada de pasajeros una estación de tren. Los pasajeros llegan la estación de tren en coche. Los coches llegan la estación según un PP de media 5 coches por hora, \\(N_t \\sim Po(5)\\), donde \\(N_t\\) representa el número de coches que han llegado en \\((0,t]\\).Por otro lado, en cada coche pueden llegar 1, 2 o hasta 3 pasajeros. El número de pasajeros que llegan en el n-ésimo coche se denota con la v.. \\(X_n\\), donde \\(P(X_n = 1) = 0.5\\), \\(P(X_n = 2) = 0.3\\), y \\(P(X_n = 3) = 0.2\\) para cualquier \\(n>0\\).Estamos interesados en saber cuántos pasajeros en total llegan la estación en coche.Definición 3.5  Sea \\(\\{N_t; t \\geq 0\\}\\) un PP de tasa \\(\\lambda\\), que representa el proceso de llegada por lotes un sistema, y sea \\(\\{X_1, X_2,...\\}\\) una secuencia de variables aleatorias ..d., y también independientes de \\(N_t\\), tales que \\(X_n\\) representa el tamaño del lote que llega en n-ésimo lugar. El proceso \\(\\{Y_t; t \\geq 0\\}\\) que acumula el número total de llegadas en \\((0,t]\\) y viene definido por la suma de las llegadas en los \\(N_t\\) lotes que han llegado en dicho periodo, esto es,\\[\\begin{equation} \nY_t = \\sum_{k=1}^{N_t} X_k, \\qquad N_t=1,2,...; \\quad t\\geq 0\n\\tag{3.1}\n\\end{equation}\\]se denomina Proceso de Poisson compuesto (PPC).La respuesta la cuestión planteada en el Ejemplo 3.5 se obtiene de plantear que el número total de pasajeros que llegan la estación, denotado por \\(\\{Y_t; t > 0 \\}\\) será un PP compuesto, definido por:\n\\[Y_t=\\sum_{=1}^{N_t} X_i.\\]\n:::Sea \\(\\{Y_t; t \\geq 0\\}\\) un PPC expresado según la Ecuación (3.1), que proviene de un PP de llegadas/eventos que se producen en lotes, \\(\\{N_t; t \\geq 0\\}\\) de tasa \\(\\lambda\\) y se conforma partir de la suma de las v.. \\(\\{X_i, =1,...,N_t\\}\\) independientes de \\(N_t\\), que representan el tamaño de los lotes, y que se distribuyen iid con media \\(\\mu=E(X_i)\\) y varianza \\(\\sigma^2=Var(X_i)\\). Entonces la esperanza y varianza del número total de llegadas/eventos (totales) para cada valor de \\(t \\geq 0\\) se obtiene como:\\[E(Y_t) = \\mu \\lambda t\\]\n\\[V(Y_t) = (\\sigma^2+\\mu^2) \\lambda t\\]\nLa varianza de \\(Y_t\\) se obtiene pues, del momento de orden 2 de \\(X_n\\), \\(E(X_n^2)=Var(X_n)+E(X_n)^2\\).Continuando con el Ejemplo 3.5), calculemos el número esperado de pasajeros (y su error) que llegarán la estación en un periodo de 8 horas. Para ello habremos de calcular en primer lugar la media y varianza del número de viajeros por coche (tamaño del lote):Así, el número medio de pasajeros por coche será 1.8 y 4 su momento de orden 2. El número (total) esperado de pasajeros en 8 horas lo calcularemos multiplicando por la tasa de llegadas de coches, \\(\\lambda\\):Por lo tanto, esperamos que lleguen la estación en 8 horas alrededor de 72 pasajeros, con un error de 12.65.","code":"\np=c(0.5,0.2,0.3)\nx=c(1,2,3)\n# valor esperado\nmu=as.numeric(p%*%x);mu## [1] 1.8\n# momento de orden 2\nm2=as.numeric(p%*%(x^2));m2## [1] 4\nlambda=5\nt=8\n# valor esperado\ney=lambda*mu*t\n# varianza\nvy=m2*lambda*t\ncat(\"E(Y_8)=\",ey,\", V(Y_8)=\",vy)## E(Y_8)= 72 , V(Y_8)= 160"},{"path":"poissonprocess.html","id":"pp_noestacionarios","chapter":"Unidad 3 Proceso de Poisson","heading":"3.2.4 PP no estacionarios","text":"Muchos procesos físicos que primera vista parecen candidatos ser modelados como un proceso de Poisson, fallan debido la suposición de estacionariedad. Por ejemplo, consideremos el análisis de tráfico: estamos interesados en modelar los tiempos de llegada de los coches una intersección. En la mayoría de los lugares es poco probable que la tasa media de llegada de coches las 2p.m. sea la misma que las 2a.m., lo que significa que el proceso es estacionario y, por lo tanto, el supuesto de estacionariedad exigido los procesos de PP se cumple.Definición 3.6  Sea \\(\\{N_t; t \\geq 0\\}\\) un proceso estocástico de parámetro contínuo con \\(N_0 = 0\\). Si asumimos que existe un función continua \\(m()\\) definida con la integral de la tasa del proceso \\(\\lambda()\\),\\[m(t) = \\int_0^t \\lambda(s)ds, \\quad \\text{ para } t \\geq 0\\]entonces el proceso \\(N_t\\) se dice que es un PP estacionario si:\\(P(N_t = k) = e^{-m(t)}(m(t)^k)/k!\\) para \\(k, t \\geq 0\\),El evento \\(\\{N_{s+u} - N_s = \\}\\) es independiente del evento \\(\\{N_t = j\\}\\) si \\(t<s\\).Estos procesos se denominan también PP homogéneos.Ejemplo 3.6  Un banco ha decidido aumentar la capacidad de su ventanilla, y desea modelar dicho proceso. Un primer paso en la modelización de la ventanilla es analizar el proceso de llegada. Las ventanillas abren las 7:30 de la mañana durante los días laborables. Se ha determinado que el proceso de llegada es un PP estacionario en el que la tasa media de llegadas aumenta lentamente de forma lineal de 10 clientes por hora 12 durante los primeros 60 minutos. Así, tenemos una función de tasa definida (en horas como unidad de tiempo) por:\\[\\lambda(t) = 10 + 2t, t \\[0,1]\\]La integral de la tasa del proceso \\(\\lambda(t)\\) es:\\[m(t) = \\int_0^t (10+2s)ds = 10t + t^2, \\quad \\text{ para } t \\leq 1.\\]De esta forma el número esperado de llegadas al banco desde las 8.00 las 8.30 (dado que abre las 7:30) viene dado por:\\[E(N_1 - N_{0.5}) = m(1) - m(0.5)\\]y es de 5.75.","code":"\nm=function(t){10*t+t^2}\nm(1)-m(0.5)## [1] 5.75"},{"path":"poissonprocess.html","id":"simulación","chapter":"Unidad 3 Proceso de Poisson","heading":"3.3 Simulación","text":"Para simular procesos de Poisson vamos utilizar la propiedad que relaciona el número de llegadas con el tiempo entre llegadas consecutivas en la Definición 3.2. Planteemos el algoritmo de simulaciónAlgoritmo de simulación de un Proceso de Poisson de tasa \\(\\lambda\\).Fijar condiciones de simulación (número de eventos o tiempo máximo de simulación).Simular tiempos entre eventos consecutivos \\(t \\sim Exp(\\lambda)\\).Para cada tiempo \\(t\\) acumular el tiempo total transcurrido.Para cada tiempo \\(t\\) acumular el número de eventosDevolver el número de eventos, los tiempos entre eventos y el tiempo total transcurrido con cada evento.Y programamos continuación una función genérica que nos permitirá simular un proceso de Poisson en función de un número prefijado de eventos o llegadas o de un tiempo máximo de duración.Ejemplo 3.7  Consideremos la situación del hospital planteada en el Ejemplo 3.2, donde el número de operaciones que se realizan en un quirófano es un \\(PP(\\lambda)\\), con tasa de intervenciones por día \\(\\lambda=24\\). Queremos estimar por simulación las cuestiones que se proponían en aquel ejemplo:Número esperado de operaciones durante 8 horas.Probabilidad de que haya intervenciones en un periodo de 1 hora.Probabilidad de que haya 3 operaciones entre las 8am y 12pm y 4 entre las 12pm y 5pm.Simulamos una vez el funcionamiento del quirófano controlando el número de operaciones realizar o el tiempo de funcionamientoY continuación calculamos las cantidades solicitadas.Número esperado de operaciones durante 8 horas.Para calcular el número esperado de operaciones que se realizan durante 8 horas tendremos que simular el proceso durante 8 horas varias veces (nsim), y calcular (y guardar) en cada simulación, el número de operaciones que se realizan. El número esperado de operaciones lo obtendremos con el promedio de estas cantidades, y con ellas también una estimación del error.Probabilidad de que haya intervenciones en un periodo de 1 hora.Simularemos nsim veces el proceso durante 1 hora y guardamos el número de operaciones realizadas. Calculamos la probabilidad con el conteo de casos favorables dados por las simulaciones en las que se produce ninguna operación.Probabilidad de que haya 3 operaciones entre las 8am y 12pm y 4 entre las 12pm y 5pm.Simulamos el proceso empezando las 8am y acabando las 5pm, esto es, durante un total de 9 horas. Contabilizamos cuántas operaciones hay en las 4 primeras horas (franja 1) y cuántas en las 5 siguientes (franja 2). Contamos los casos favorables al suceso que se plantea.La simulación para extensiones del PP se deriva de las definiciones dadas en la Sección Extensiones.","code":"\nsimula.pp=function(lambda,neventos=NULL,tmax=NULL){\n  # se lanza la simulación hasta conseguir neventos o hasta un instante tmax\n  if(is.null(tmax) & is.null(neventos)){\n    return(cat(\"Introduce neventos o tmax\"))\n  }\n  else if(is.null(tmax)){\n    t=rexp(neventos,lambda)\n  }\n  else if(is.null(neventos)){\n    t=c()\n    tt=0\n    i=1\n    t[1]=rexp(1,lambda)\n    # si la primera llegada se produce después de tmax, contabilizamos 0 eventos\n    if(t[1]>tmax)\n      return(data.frame(eventos=0,t=0,ttotal=0))\n    # en otro caso, continuamos hasta llegar a tmax\n    else{\n    while(tt<=tmax){\n      i=i+1\n      t[i]=rexp(1,lambda)\n      tt=tt+t[i]\n        }\n    # se seleccionan sólo los eventos que se produjeron antes de tmax\n    t=t[cumsum(t)<=tmax]\n  }}\nreturn(data.frame(eventos=1:length(t),t,ttotal=cumsum(t)))\n}\nsimulacion=simula.pp(lambda=24,neventos=200)\nhead(simulacion)##   eventos           t      ttotal\n## 1       1 0.008396741 0.008396741\n## 2       2 0.068498412 0.076895153\n## 3       3 0.215637900 0.292533053\n## 4       4 0.035509007 0.328042059\n## 5       5 0.019406832 0.347448892\n## 6       6 0.022710126 0.370159018\nsimulacion=simula.pp(lambda=24,tmax=2)\nhead(simulacion)##   eventos           t     ttotal\n## 1       1 0.058025341 0.05802534\n## 2       2 0.001355536 0.05938088\n## 3       3 0.020513519 0.07989440\n## 4       4 0.001007941 0.08090234\n## 5       5 0.047494149 0.12839649\n## 6       6 0.039658236 0.16805472\nnsim=5000\ntmax=8/24\nlambda=24\nset.seed(123)\nnoperaciones=c()\n# simulamos nsim veces el proceso durante 8 horas\nfor(i in 1:nsim){\nsimulacion=simula.pp(lambda=lambda,tmax=tmax);simulacion\n# número de operaciones realizadas\nnoperaciones[i]=max(simulacion$eventos)\n}\nm=mean(noperaciones)\ns=sd(noperaciones)\n# calculamos la media y el error\ncat(\"E(operaciones en 8 horas)=\",round(m,2), \", Error=\",round(s,2))## E(operaciones en 8 horas)= 7.97 , Error= 2.83\ncat(\"\\n IC(operaciones en 8 horas)=[\",round(m-qnorm(0.975)*s,2),\n    \",\",round(m+qnorm(0.975)*s,2),\"]\")## \n##  IC(operaciones en 8 horas)=[ 2.43 , 13.5 ]\nnsim=5000\ntmax=1/24\nlambda=24\nset.seed(123)\nnoperaciones=c()\n# simulamos nsim veces el proceso durante tmax horas\nfor(i in 1:nsim){\nsimulacion=simula.pp(lambda=lambda,tmax=tmax)\n# no se ha realizado ninguna operación\nnoperaciones[i]=max(simulacion$eventos)\n}\nfavorables=(noperaciones==0)*1\np=mean(favorables)\ns=sqrt(sum((favorables-p)^2)/(nsim^2))\n# calculamos la media y el error\ncat(\"Pr(sin operaciones en 1 hora)=\",p, \", Error=\",s)## Pr(sin operaciones en 1 hora)= 0.3688 , Error= 0.006823292\ncat(\"\\n IC(Pr(sin operaciones en 1 hora))=[\",round(p-qnorm(0.975)*s,3), \",\",round(p+qnorm(0.975)*s,3),\"]\")## \n##  IC(Pr(sin operaciones en 1 hora))=[ 0.355 , 0.382 ]\nnsim=5000\ntmax=9/24\nlambda=24\nset.seed(123)\n# vectores para guardar el número de operaciones en cada franja\nnoper1=noper2=c()\n# simulamos nsim veces el proceso durante tmax horas\nfor(i in 1:nsim){\nsimulacion=simula.pp(lambda=lambda,tmax=tmax)\n# contamos el número de operaciones en cada franja\nnoper1[i]=sum(simulacion$ttotal<=4/24)\nnoper2[i]=sum(simulacion$ttotal>4/24)\n}\n# identificamos las cadenas en las que se dan simultaneamente ambos sucesos\nfavorables=((noper1==3)&(noper2==4))*1\np=mean(favorables)\ns=sqrt(sum((favorables-p)^2)/(nsim^2))\n# calculamos la media y el error\ncat(\"Pr(suceso)=\",p, \", Error=\",s)## Pr(suceso)= 0.032 , Error= 0.002489016\ncat(\"\\n IC(Pr(ssuceso))=[\",round(p-qnorm(0.975)*s,3), \",\",round(p+qnorm(0.975)*s,3),\"]\")## \n##  IC(Pr(ssuceso))=[ 0.027 , 0.037 ]"},{"path":"poissonprocess.html","id":"ejer-u3","chapter":"Unidad 3 Proceso de Poisson","heading":"3.4 Ejercicios","text":"","code":""},{"path":"poissonprocess.html","id":"básicos-2","chapter":"Unidad 3 Proceso de Poisson","heading":"3.4.1 Básicos","text":"Ejercicio B3.1. En una tienda de animales entran clientes razón de 8 por hora.¿Cuál es la probabilidad de que lleguen al menos 4 clientes durante los próximos 30 minutos?¿Cuál es la probabilidad de que en las 8 horas en que permanece abierta la tienda entren al menos 70 clientes?Ejercicio B3.2. En una estación de bomberos el tiempo entre llamadas por avisos sigue una distribución exponencial con una media de 32 minutos.Acaba de llegar una llamada. ¿Cuál es la probabilidad de que la próxima llamada se produzca en menos de media hora?¿Cuál es la probabilidad de que se produzcan exactamente dos llamadas durante la próxima hora?Ejercicio B3.3. Una empresa que controla la seguridad de una ciudad ha observado que los intentos de entrar en domicilios ajenos para robar (para los que tienen contratada la seguridad con ellos) ocurren con un PP de tasa 2.2 por día. El sistema opera 24 horas al día.¿Cuál es la probabilidad de que mañana se produzcan 4 intentos de robo?¿Cuál es la probabilidad de que se produzca ningún intento de robo durante la noche (entre las 12 de la noche y las 8 de la mañana)?Si ahora es medianoche y el último intento de robo se produjo las 10:30pm, ¿cuál es la probabilidad de que el siguiente intento ocurra antes de las 5:30am?Ejercicio B3.4. En el caso de la empresa de seguridad del Ejercicio B3.3 resulta que además se sabe que el 10% de los intentos de entrar en la casa resultan en robo efectivo.¿Cuál es la probabilidad de que se produzcan 3 intentos de robo que acaben en robo?Ahora mismo son las 6am del lunes. El último intento de robo que acabó en robo ocurrió medianoche. ¿Cuál es la probabilidad de que se hayan producido robos durante dicho periodo?Ejercicio B3.5. En una máquina hay dos tipos comunes de fallos críticos: en la componente electrónica o en la B. Si cualquiera de estas componentes falla, la máquina se para. La componente falla conforme un PP con tasa 1.1 fallos por turno (la fábrica trabaja 24/7 en turnos de 8 horas). La componente B falla según un PP con tasa 1.2 fallos por día.¿Cuál es la probabiliadd de que se produzcan exactamente 5 fallos de la máquina durante un día?¿Cuál es la probabilidad de que la máquina se pare más de una vez durante el siguiente turno?Ahora mismo es mediodía y el último fallo se produjo hace 4 horas. ¿Cuál es la probabilidad de que el próximo parón se produzca antes de las 6pm?Simula los parones de la máquina, mostrando qué componente falla en cada ocasión y asumiendo que el tiempo de reparación es despreciable y la máquina continua trabajando inmediatamente. Estima la probabilidad de que la máquina se pare más de 1 vez durante un turno.Simula los parones de la máquina, mostrando qué componente falla en cada ocasión y asumiendo que el tiempo de reparación de cada componente se distribuye uniforme entre 5 y 60 minutos. Estima la probabilidad de que la máquina se pare más de 1 vez durante un turno.Ejercicio B3.6. Los clientes entran en una tienda según un PP con tasa 5 clientes por hora. La probabilidad de que un cliente se vaya sin comprar es 0.20. Si el cliente compra, lo que se gasta se puede aproximar con una distribución Gamma con parámetro de escala 100€ y de forma 2.5.Da la media y la desviación típica del dinero que consigue la tienda por las compras de los clientes que entran en una hora.Calcula lo mismo para una franja de 10 horas.Estima la probabilidad de que la máquina se pare más de 1 vez durante un turno.Ejercicio B3.7. En el caso de la empresa de seguridad del Ejercicio B3.3 resulta que se ha estudiado mejor y el número de intentos de robo sigue un PP cuya tasa depende de la franja horaria. Entre las 6am y las 8am la tasa es de 0.3, entre las 8pm-medianoche de 0.6, de medianoche las 4am la tasa es 1 y de las 4am las 6am la tasa es 0.3. Contesta las mismas preguntas que se formularon en el Ejercicio B3.3.Ejercicio B3.8. Se envía una nave espacial Júpiter para tomar fotos de las lunas y enviarlas la Tierra. Hay tres sistemas críticos involucrados: la cámara, la batería y la antena de transmisión. Estos tres sistemas fallan independientemente entre sí. La vida esperada de la batería es de 6 años, la de la cámera es 12 años y la de la antena de 10 años. Asume que todos los tiempos de vida son v.. exponenciales La nave alcanzará Júpiter después de 3 años desde que arranca la misión. ¿Cuál es la probabilidad de que la misión resulte exitosa?Ejercicio B3.8. En una maternidad los partos simples se dan con probabilidad, 0.9, los de mellizos o gemelos con probabilidad 0.08 y los de trillizos con probabilidad 0.02. El número de partos sigue un PP con tasa 10 por día.Calcula el número esperado de nacimientos lo largo de un día.¿Cuál es la probabilidad de que se dé al menos un parto de gemelos o mellizos?Suponiendo que durante un día han nacido unos gemelos, ¿cuál es el número de partos que se han dado?Ejercicio B3.9. El número de coches que visitan un parque nacional sigue un PP con tasa 15 por hora. Cada coche tiene k ocupantes con probabilidad \\(p_k\\), donde\n\\[p_1=0.2, \\quad, p_2=0.3, \\quad p_3=0.3, \\quad p_4=0.1, \\quad p_5=0.5, \\quad p_6=0.05.\\]Calcula la media y la varianza del número de visitantes del parque durante un periodo de 10 horas.Si el coste de la entrada de cada coche es de 4€, con un recargo de 1€ por ocupante, calcula la media y la varianza del dinero que consigue el parque durante 10 horas.","code":""},{"path":"poissonprocess.html","id":"avanzados-2","chapter":"Unidad 3 Proceso de Poisson","heading":"3.4.2 Avanzados","text":"Ejercicio A3.1 Programa un algoritmo de simulación para la superposición de PP definida en la Sección Superposición y resuelve con simulación el Ejemplo @ref(ex_pp002).Ejercicio A3.2 Programa un algoritmo de simulación para la mixtura de PP definida en la Sección Adelgazamiento con mixtura y resuelve con simulación el Ejemplo @ref(ex_pp003).Ejercicio A3.3 Programa un algoritmo de simulación para la composición de PP definida en la Sección Composición y resuelve con simulación el Ejemplo @ref(ex_pp004).Ejercicio A3.4 Programa un algoritmo de simulación para PP estacionarios, definidos en la Sección PP estacionarios y resuelve con simulación el Ejemplo @ref(ex_pp005).Ejercicio A3.5 Un servicio de venta telefónica recibe llamadas conforme un PP. Simula el proceso y calcula el volumen esperado (en términos de euros) de las ventas que se realizan durante un intervalo de 15 minutos desde las 12 del mediodía hasta las 12:15pm bajo las diversas condiciones que se proponen continuación, asumiendo que todos los días son probabilísticamente iguales.El PP de llegadas ees estacionario con tasa de 50 llamadas por hora. Además, sólo la mitad de las llamadas acaban en compras, el 30% de las llamadas acaban con una compra de 100€ y el 20% con compras de 200€.Como la mayoría de la gente tiende llamar en su descanso para almorzar, la tasa de llegadas se incrementa lentamente partir de mediodía; entre las 12 y las 12:05 la tasa es de 40 llamadas, entre las 12:05pm y las 12:10pm, la tasa es de 45 llamadas por hora, y desde las 12:10pm hasta las 12:50pm la tasa es de 50 llamadas. Las probabilidades y compras son similares las del apartado 1.La tasa de llamadas se aproxima con una función lineal que da 40 llamadas por hora al mediodía y 50 las 12:15pm. La tasa es constante durante los siguientes 30 minutos. Las probabilidades y compras sin similares las del apartado 1.","code":""},{"path":"bibliografía.html","id":"bibliografía","chapter":"Bibliografía","heading":"Bibliografía","text":"","code":""}]
